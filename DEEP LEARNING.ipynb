{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Verkehrszeichen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made by [Sharkbyteprojects](https://github.com/sharkbyteprojects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need\n",
    "- Keras\n",
    "- SKLEARN\n",
    "- numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "inputs=Input(shape=(4,))\n",
    "fc=Dense(3)(inputs)\n",
    "from keras.models import Model\n",
    "model=Model(input=inputs,output=fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zeige infos Ã¼ber Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and add new Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "             loss=\"categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])\n",
    "predictionss=Dense(8,activation=\"softmax\")(fc)\n",
    "predictions=Dense(3,activation=\"softmax\")(predictionss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test of Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "az=model.predict(np.array([[5.1,5.3,1.4,0.2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recompile and Retry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 15        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 74\n",
      "Trainable params: 74\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Model(input=inputs,output=predictions)\n",
    "model.compile(optimizer=\"adam\",\n",
    "             loss=\"categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "aza=model.predict(np.array([[5.1,5.3,1.4,0.2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris =datasets.load_iris()\n",
    "X=np.array(iris.data)\n",
    "y=np.array(iris.target)\n",
    "X.shape, y.shape\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y=to_categorical(y,3)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "complete prepare for train, start train:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84 samples, validate on 36 samples\n",
      "Epoch 1/500\n",
      "84/84 [==============================] - 4s 48ms/step - loss: 1.1820 - accuracy: 0.3333 - val_loss: 1.1752 - val_accuracy: 0.3333\n",
      "Epoch 2/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 1.1767 - accuracy: 0.3333 - val_loss: 1.1705 - val_accuracy: 0.3333\n",
      "Epoch 3/500\n",
      "84/84 [==============================] - 0s 453us/step - loss: 1.1718 - accuracy: 0.3333 - val_loss: 1.1655 - val_accuracy: 0.3333\n",
      "Epoch 4/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 1.1664 - accuracy: 0.3333 - val_loss: 1.1604 - val_accuracy: 0.3333\n",
      "Epoch 5/500\n",
      "84/84 [==============================] - 0s 583us/step - loss: 1.1609 - accuracy: 0.3333 - val_loss: 1.1553 - val_accuracy: 0.3333\n",
      "Epoch 6/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 1.1553 - accuracy: 0.3333 - val_loss: 1.1503 - val_accuracy: 0.3333\n",
      "Epoch 7/500\n",
      "84/84 [==============================] - 0s 750us/step - loss: 1.1503 - accuracy: 0.3333 - val_loss: 1.1453 - val_accuracy: 0.3333\n",
      "Epoch 8/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 1.1450 - accuracy: 0.3333 - val_loss: 1.1401 - val_accuracy: 0.3333\n",
      "Epoch 9/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 1.1391 - accuracy: 0.3333 - val_loss: 1.1350 - val_accuracy: 0.3333\n",
      "Epoch 10/500\n",
      "84/84 [==============================] - 0s 714us/step - loss: 1.1339 - accuracy: 0.3333 - val_loss: 1.1299 - val_accuracy: 0.3333\n",
      "Epoch 11/500\n",
      "84/84 [==============================] - 0s 512us/step - loss: 1.1287 - accuracy: 0.3333 - val_loss: 1.1248 - val_accuracy: 0.3333\n",
      "Epoch 12/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 1.1232 - accuracy: 0.3333 - val_loss: 1.1200 - val_accuracy: 0.3333\n",
      "Epoch 13/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 1.1178 - accuracy: 0.3333 - val_loss: 1.1150 - val_accuracy: 0.3333\n",
      "Epoch 14/500\n",
      "84/84 [==============================] - 0s 667us/step - loss: 1.1125 - accuracy: 0.3333 - val_loss: 1.1099 - val_accuracy: 0.3333\n",
      "Epoch 15/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 1.1067 - accuracy: 0.3333 - val_loss: 1.1049 - val_accuracy: 0.3333\n",
      "Epoch 16/500\n",
      "84/84 [==============================] - 0s 667us/step - loss: 1.1014 - accuracy: 0.3333 - val_loss: 1.0997 - val_accuracy: 0.3333\n",
      "Epoch 17/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 1.0961 - accuracy: 0.3333 - val_loss: 1.0946 - val_accuracy: 0.3333\n",
      "Epoch 18/500\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 1.0908 - accuracy: 0.3333 - val_loss: 1.0893 - val_accuracy: 0.3333\n",
      "Epoch 19/500\n",
      "84/84 [==============================] - 0s 643us/step - loss: 1.0851 - accuracy: 0.3333 - val_loss: 1.0842 - val_accuracy: 0.3333\n",
      "Epoch 20/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 1.0794 - accuracy: 0.3333 - val_loss: 1.0791 - val_accuracy: 0.3333\n",
      "Epoch 21/500\n",
      "84/84 [==============================] - 0s 834us/step - loss: 1.0740 - accuracy: 0.3333 - val_loss: 1.0742 - val_accuracy: 0.3333\n",
      "Epoch 22/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 1.0695 - accuracy: 0.3333 - val_loss: 1.0694 - val_accuracy: 0.3333\n",
      "Epoch 23/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 1.0641 - accuracy: 0.3333 - val_loss: 1.0648 - val_accuracy: 0.3333\n",
      "Epoch 24/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 1.0591 - accuracy: 0.3452 - val_loss: 1.0603 - val_accuracy: 0.3611\n",
      "Epoch 25/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 1.0543 - accuracy: 0.4524 - val_loss: 1.0558 - val_accuracy: 0.5000\n",
      "Epoch 26/500\n",
      "84/84 [==============================] - 0s 679us/step - loss: 1.0490 - accuracy: 0.6310 - val_loss: 1.0516 - val_accuracy: 0.6111\n",
      "Epoch 27/500\n",
      "84/84 [==============================] - 0s 857us/step - loss: 1.0446 - accuracy: 0.6786 - val_loss: 1.0473 - val_accuracy: 0.6389\n",
      "Epoch 28/500\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 1.0397 - accuracy: 0.6786 - val_loss: 1.0432 - val_accuracy: 0.6389\n",
      "Epoch 29/500\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 1.0351 - accuracy: 0.6786 - val_loss: 1.0391 - val_accuracy: 0.6389\n",
      "Epoch 30/500\n",
      "84/84 [==============================] - 0s 667us/step - loss: 1.0310 - accuracy: 0.6786 - val_loss: 1.0351 - val_accuracy: 0.6389\n",
      "Epoch 31/500\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 1.0269 - accuracy: 0.6786 - val_loss: 1.0311 - val_accuracy: 0.6389\n",
      "Epoch 32/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 1.0224 - accuracy: 0.6786 - val_loss: 1.0272 - val_accuracy: 0.6389\n",
      "Epoch 33/500\n",
      "84/84 [==============================] - 0s 750us/step - loss: 1.0185 - accuracy: 0.6786 - val_loss: 1.0234 - val_accuracy: 0.6389\n",
      "Epoch 34/500\n",
      "84/84 [==============================] - 0s 714us/step - loss: 1.0145 - accuracy: 0.6786 - val_loss: 1.0196 - val_accuracy: 0.6389\n",
      "Epoch 35/500\n",
      "84/84 [==============================] - 0s 976us/step - loss: 1.0103 - accuracy: 0.6786 - val_loss: 1.0158 - val_accuracy: 0.6389\n",
      "Epoch 36/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 1.0068 - accuracy: 0.6786 - val_loss: 1.0121 - val_accuracy: 0.6389\n",
      "Epoch 37/500\n",
      "84/84 [==============================] - 0s 762us/step - loss: 1.0024 - accuracy: 0.6786 - val_loss: 1.0085 - val_accuracy: 0.6389\n",
      "Epoch 38/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.9989 - accuracy: 0.6786 - val_loss: 1.0048 - val_accuracy: 0.6389\n",
      "Epoch 39/500\n",
      "84/84 [==============================] - 0s 679us/step - loss: 0.9949 - accuracy: 0.6786 - val_loss: 1.0011 - val_accuracy: 0.6389\n",
      "Epoch 40/500\n",
      "84/84 [==============================] - 0s 691us/step - loss: 0.9911 - accuracy: 0.6786 - val_loss: 0.9974 - val_accuracy: 0.6389\n",
      "Epoch 41/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.9868 - accuracy: 0.6786 - val_loss: 0.9936 - val_accuracy: 0.6389\n",
      "Epoch 42/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.9832 - accuracy: 0.6786 - val_loss: 0.9898 - val_accuracy: 0.6389\n",
      "Epoch 43/500\n",
      "84/84 [==============================] - 0s 453us/step - loss: 0.9788 - accuracy: 0.6786 - val_loss: 0.9862 - val_accuracy: 0.6389\n",
      "Epoch 44/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.9750 - accuracy: 0.6786 - val_loss: 0.9824 - val_accuracy: 0.6389\n",
      "Epoch 45/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.9708 - accuracy: 0.6786 - val_loss: 0.9786 - val_accuracy: 0.6389\n",
      "Epoch 46/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.9667 - accuracy: 0.6786 - val_loss: 0.9748 - val_accuracy: 0.6667\n",
      "Epoch 47/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.9625 - accuracy: 0.6905 - val_loss: 0.9708 - val_accuracy: 0.6944\n",
      "Epoch 48/500\n",
      "84/84 [==============================] - 0s 834us/step - loss: 0.9585 - accuracy: 0.6905 - val_loss: 0.9669 - val_accuracy: 0.6944\n",
      "Epoch 49/500\n",
      "84/84 [==============================] - 0s 452us/step - loss: 0.9541 - accuracy: 0.6905 - val_loss: 0.9629 - val_accuracy: 0.6944\n",
      "Epoch 50/500\n",
      "84/84 [==============================] - 0s 607us/step - loss: 0.9499 - accuracy: 0.7143 - val_loss: 0.9589 - val_accuracy: 0.7222\n",
      "Epoch 51/500\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.9455 - accuracy: 0.7262 - val_loss: 0.9548 - val_accuracy: 0.7222\n",
      "Epoch 52/500\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.9413 - accuracy: 0.7381 - val_loss: 0.9507 - val_accuracy: 0.7778\n",
      "Epoch 53/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 0.9370 - accuracy: 0.7500 - val_loss: 0.9465 - val_accuracy: 0.7778\n",
      "Epoch 54/500\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.9328 - accuracy: 0.7619 - val_loss: 0.9424 - val_accuracy: 0.7778\n",
      "Epoch 55/500\n",
      "84/84 [==============================] - 0s 655us/step - loss: 0.9282 - accuracy: 0.7738 - val_loss: 0.9382 - val_accuracy: 0.8056\n",
      "Epoch 56/500\n",
      "84/84 [==============================] - 0s 869us/step - loss: 0.9238 - accuracy: 0.7738 - val_loss: 0.9341 - val_accuracy: 0.8333\n",
      "Epoch 57/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.9195 - accuracy: 0.7857 - val_loss: 0.9299 - val_accuracy: 0.8333\n",
      "Epoch 58/500\n",
      "84/84 [==============================] - 0s 691us/step - loss: 0.9150 - accuracy: 0.7857 - val_loss: 0.9258 - val_accuracy: 0.8333\n",
      "Epoch 59/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.9108 - accuracy: 0.7857 - val_loss: 0.9217 - val_accuracy: 0.8333\n",
      "Epoch 60/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.9064 - accuracy: 0.7857 - val_loss: 0.9175 - val_accuracy: 0.8333\n",
      "Epoch 61/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.9019 - accuracy: 0.8095 - val_loss: 0.9133 - val_accuracy: 0.8333\n",
      "Epoch 62/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.8975 - accuracy: 0.8214 - val_loss: 0.9090 - val_accuracy: 0.8333\n",
      "Epoch 63/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.8930 - accuracy: 0.8214 - val_loss: 0.9048 - val_accuracy: 0.8333\n",
      "Epoch 64/500\n",
      "84/84 [==============================] - 0s 738us/step - loss: 0.8887 - accuracy: 0.8214 - val_loss: 0.9005 - val_accuracy: 0.8333\n",
      "Epoch 65/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.8842 - accuracy: 0.8333 - val_loss: 0.8962 - val_accuracy: 0.8333\n",
      "Epoch 66/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.8798 - accuracy: 0.8333 - val_loss: 0.8919 - val_accuracy: 0.8611\n",
      "Epoch 67/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.8755 - accuracy: 0.8333 - val_loss: 0.8877 - val_accuracy: 0.8611\n",
      "Epoch 68/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.8710 - accuracy: 0.8333 - val_loss: 0.8834 - val_accuracy: 0.8611\n",
      "Epoch 69/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.8667 - accuracy: 0.8333 - val_loss: 0.8792 - val_accuracy: 0.8611\n",
      "Epoch 70/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.8622 - accuracy: 0.8333 - val_loss: 0.8749 - val_accuracy: 0.8889\n",
      "Epoch 71/500\n",
      "84/84 [==============================] - 0s 738us/step - loss: 0.8579 - accuracy: 0.8452 - val_loss: 0.8707 - val_accuracy: 0.8889\n",
      "Epoch 72/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.8535 - accuracy: 0.8452 - val_loss: 0.8665 - val_accuracy: 0.8889\n",
      "Epoch 73/500\n",
      "84/84 [==============================] - 0s 667us/step - loss: 0.8491 - accuracy: 0.8571 - val_loss: 0.8622 - val_accuracy: 0.8889\n",
      "Epoch 74/500\n",
      "84/84 [==============================] - 0s 714us/step - loss: 0.8449 - accuracy: 0.8571 - val_loss: 0.8580 - val_accuracy: 0.8889\n",
      "Epoch 75/500\n",
      "84/84 [==============================] - 0s 536us/step - loss: 0.8405 - accuracy: 0.8571 - val_loss: 0.8537 - val_accuracy: 0.8889\n",
      "Epoch 76/500\n",
      "84/84 [==============================] - 0s 583us/step - loss: 0.8362 - accuracy: 0.8810 - val_loss: 0.8495 - val_accuracy: 0.8889\n",
      "Epoch 77/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.8318 - accuracy: 0.8810 - val_loss: 0.8453 - val_accuracy: 0.8889\n",
      "Epoch 78/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.8275 - accuracy: 0.8810 - val_loss: 0.8412 - val_accuracy: 0.8889\n",
      "Epoch 79/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.8233 - accuracy: 0.8810 - val_loss: 0.8370 - val_accuracy: 0.8889\n",
      "Epoch 80/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.8190 - accuracy: 0.8929 - val_loss: 0.8329 - val_accuracy: 0.8889\n",
      "Epoch 81/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.8149 - accuracy: 0.9048 - val_loss: 0.8288 - val_accuracy: 0.9167\n",
      "Epoch 82/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.8106 - accuracy: 0.8929 - val_loss: 0.8248 - val_accuracy: 0.9167\n",
      "Epoch 83/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.8064 - accuracy: 0.8929 - val_loss: 0.8208 - val_accuracy: 0.9167\n",
      "Epoch 84/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.8025 - accuracy: 0.8929 - val_loss: 0.8168 - val_accuracy: 0.9167\n",
      "Epoch 85/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.7982 - accuracy: 0.8929 - val_loss: 0.8128 - val_accuracy: 0.9167\n",
      "Epoch 86/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.7945 - accuracy: 0.9167 - val_loss: 0.8088 - val_accuracy: 0.9167\n",
      "Epoch 87/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.7902 - accuracy: 0.9167 - val_loss: 0.8049 - val_accuracy: 0.9167\n",
      "Epoch 88/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.7863 - accuracy: 0.9286 - val_loss: 0.8011 - val_accuracy: 0.9444\n",
      "Epoch 89/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.7824 - accuracy: 0.9286 - val_loss: 0.7973 - val_accuracy: 0.9722\n",
      "Epoch 90/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.7785 - accuracy: 0.9286 - val_loss: 0.7936 - val_accuracy: 0.9722\n",
      "Epoch 91/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.7751 - accuracy: 0.87 - 0s 369us/step - loss: 0.7747 - accuracy: 0.9286 - val_loss: 0.7899 - val_accuracy: 0.9722\n",
      "Epoch 92/500\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7709 - accuracy: 0.9286 - val_loss: 0.7863 - val_accuracy: 0.9722\n",
      "Epoch 93/500\n",
      "84/84 [==============================] - 0s 512us/step - loss: 0.7672 - accuracy: 0.9286 - val_loss: 0.7828 - val_accuracy: 0.9722\n",
      "Epoch 94/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.7634 - accuracy: 0.9286 - val_loss: 0.7793 - val_accuracy: 0.9722\n",
      "Epoch 95/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.7599 - accuracy: 0.9405 - val_loss: 0.7758 - val_accuracy: 0.9722\n",
      "Epoch 96/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.7562 - accuracy: 0.9405 - val_loss: 0.7724 - val_accuracy: 0.9722\n",
      "Epoch 97/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.7527 - accuracy: 0.9405 - val_loss: 0.7690 - val_accuracy: 0.9722\n",
      "Epoch 98/500\n",
      "84/84 [==============================] - 0s 679us/step - loss: 0.7492 - accuracy: 0.9405 - val_loss: 0.7657 - val_accuracy: 0.9722\n",
      "Epoch 99/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.7458 - accuracy: 0.9286 - val_loss: 0.7625 - val_accuracy: 0.9722\n",
      "Epoch 100/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.7424 - accuracy: 0.9286 - val_loss: 0.7593 - val_accuracy: 0.9722\n",
      "Epoch 101/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.7391 - accuracy: 0.9167 - val_loss: 0.7562 - val_accuracy: 0.9722\n",
      "Epoch 102/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.7359 - accuracy: 0.9167 - val_loss: 0.7531 - val_accuracy: 0.9722\n",
      "Epoch 103/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.7327 - accuracy: 0.9167 - val_loss: 0.7501 - val_accuracy: 0.9722\n",
      "Epoch 104/500\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7296 - accuracy: 0.9167 - val_loss: 0.7471 - val_accuracy: 0.9722\n",
      "Epoch 105/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.7265 - accuracy: 0.9286 - val_loss: 0.7442 - val_accuracy: 0.9722\n",
      "Epoch 106/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.7235 - accuracy: 0.9048 - val_loss: 0.7414 - val_accuracy: 0.9722\n",
      "Epoch 107/500\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.7205 - accuracy: 0.9048 - val_loss: 0.7386 - val_accuracy: 0.9722\n",
      "Epoch 108/500\n",
      "84/84 [==============================] - 0s 464us/step - loss: 0.7177 - accuracy: 0.9048 - val_loss: 0.7359 - val_accuracy: 0.9722\n",
      "Epoch 109/500\n",
      "84/84 [==============================] - 0s 452us/step - loss: 0.7148 - accuracy: 0.9048 - val_loss: 0.7332 - val_accuracy: 0.9722\n",
      "Epoch 110/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.7120 - accuracy: 0.9048 - val_loss: 0.7306 - val_accuracy: 0.9722\n",
      "Epoch 111/500\n",
      "84/84 [==============================] - 0s 619us/step - loss: 0.7093 - accuracy: 0.9048 - val_loss: 0.7280 - val_accuracy: 0.9444\n",
      "Epoch 112/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.7067 - accuracy: 0.9048 - val_loss: 0.7256 - val_accuracy: 0.9167\n",
      "Epoch 113/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.7040 - accuracy: 0.8810 - val_loss: 0.7231 - val_accuracy: 0.9167\n",
      "Epoch 114/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.7015 - accuracy: 0.8810 - val_loss: 0.7207 - val_accuracy: 0.9167\n",
      "Epoch 115/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.6990 - accuracy: 0.8690 - val_loss: 0.7184 - val_accuracy: 0.9167\n",
      "Epoch 116/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.6966 - accuracy: 0.8690 - val_loss: 0.7161 - val_accuracy: 0.9167\n",
      "Epoch 117/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.6941 - accuracy: 0.8690 - val_loss: 0.7139 - val_accuracy: 0.9167\n",
      "Epoch 118/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.6918 - accuracy: 0.8690 - val_loss: 0.7117 - val_accuracy: 0.9167\n",
      "Epoch 119/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.6895 - accuracy: 0.8690 - val_loss: 0.7095 - val_accuracy: 0.8889\n",
      "Epoch 120/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.6873 - accuracy: 0.8571 - val_loss: 0.7074 - val_accuracy: 0.8889\n",
      "Epoch 121/500\n",
      "84/84 [==============================] - 0s 584us/step - loss: 0.6850 - accuracy: 0.8571 - val_loss: 0.7054 - val_accuracy: 0.8889\n",
      "Epoch 122/500\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6828 - accuracy: 0.8452 - val_loss: 0.7034 - val_accuracy: 0.8611\n",
      "Epoch 123/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.6808 - accuracy: 0.8452 - val_loss: 0.7015 - val_accuracy: 0.8611\n",
      "Epoch 124/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.6787 - accuracy: 0.8333 - val_loss: 0.6996 - val_accuracy: 0.8611\n",
      "Epoch 125/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.6768 - accuracy: 0.8333 - val_loss: 0.6977 - val_accuracy: 0.8611\n",
      "Epoch 126/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.6747 - accuracy: 0.8333 - val_loss: 0.6958 - val_accuracy: 0.8611\n",
      "Epoch 127/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.6728 - accuracy: 0.8333 - val_loss: 0.6940 - val_accuracy: 0.8611\n",
      "Epoch 128/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.6709 - accuracy: 0.8333 - val_loss: 0.6923 - val_accuracy: 0.8611\n",
      "Epoch 129/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.6690 - accuracy: 0.8333 - val_loss: 0.6905 - val_accuracy: 0.8611\n",
      "Epoch 130/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.6672 - accuracy: 0.8214 - val_loss: 0.6888 - val_accuracy: 0.8611\n",
      "Epoch 131/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.6654 - accuracy: 0.8214 - val_loss: 0.6871 - val_accuracy: 0.8611\n",
      "Epoch 132/500\n",
      "84/84 [==============================] - 0s 595us/step - loss: 0.6636 - accuracy: 0.8214 - val_loss: 0.6855 - val_accuracy: 0.8611\n",
      "Epoch 133/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6620 - accuracy: 0.7976 - val_loss: 0.6838 - val_accuracy: 0.8333\n",
      "Epoch 134/500\n",
      "84/84 [==============================] - 0s 703us/step - loss: 0.6603 - accuracy: 0.7976 - val_loss: 0.6822 - val_accuracy: 0.8333\n",
      "Epoch 135/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.6586 - accuracy: 0.7976 - val_loss: 0.6807 - val_accuracy: 0.8333\n",
      "Epoch 136/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 0.6569 - accuracy: 0.7857 - val_loss: 0.6792 - val_accuracy: 0.8333\n",
      "Epoch 137/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.6554 - accuracy: 0.7857 - val_loss: 0.6777 - val_accuracy: 0.8333\n",
      "Epoch 138/500\n",
      "84/84 [==============================] - 0s 512us/step - loss: 0.6538 - accuracy: 0.7857 - val_loss: 0.6762 - val_accuracy: 0.8056\n",
      "Epoch 139/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.6522 - accuracy: 0.7857 - val_loss: 0.6747 - val_accuracy: 0.8056\n",
      "Epoch 140/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.6508 - accuracy: 0.7857 - val_loss: 0.6733 - val_accuracy: 0.8056\n",
      "Epoch 141/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.6492 - accuracy: 0.7857 - val_loss: 0.6719 - val_accuracy: 0.8056\n",
      "Epoch 142/500\n",
      "84/84 [==============================] - 0s 619us/step - loss: 0.6478 - accuracy: 0.7857 - val_loss: 0.6705 - val_accuracy: 0.7778\n",
      "Epoch 143/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.6463 - accuracy: 0.7738 - val_loss: 0.6692 - val_accuracy: 0.7500\n",
      "Epoch 144/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.6450 - accuracy: 0.7619 - val_loss: 0.6678 - val_accuracy: 0.7500\n",
      "Epoch 145/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.6014 - accuracy: 0.81 - 0s 417us/step - loss: 0.6436 - accuracy: 0.7619 - val_loss: 0.6665 - val_accuracy: 0.7222\n",
      "Epoch 146/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.6422 - accuracy: 0.7619 - val_loss: 0.6652 - val_accuracy: 0.7222\n",
      "Epoch 147/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.6408 - accuracy: 0.7619 - val_loss: 0.6640 - val_accuracy: 0.7222\n",
      "Epoch 148/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.6395 - accuracy: 0.7619 - val_loss: 0.6627 - val_accuracy: 0.7222\n",
      "Epoch 149/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.6413 - accuracy: 0.78 - 0s 381us/step - loss: 0.6382 - accuracy: 0.7619 - val_loss: 0.6615 - val_accuracy: 0.7222\n",
      "Epoch 150/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.6369 - accuracy: 0.7619 - val_loss: 0.6603 - val_accuracy: 0.7222\n",
      "Epoch 151/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.6357 - accuracy: 0.7619 - val_loss: 0.6591 - val_accuracy: 0.7222\n",
      "Epoch 152/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.6344 - accuracy: 0.7500 - val_loss: 0.6579 - val_accuracy: 0.7222\n",
      "Epoch 153/500\n",
      "84/84 [==============================] - 0s 512us/step - loss: 0.6332 - accuracy: 0.7500 - val_loss: 0.6568 - val_accuracy: 0.7222\n",
      "Epoch 154/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.6320 - accuracy: 0.7500 - val_loss: 0.6557 - val_accuracy: 0.7222\n",
      "Epoch 155/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.6309 - accuracy: 0.7500 - val_loss: 0.6546 - val_accuracy: 0.7222\n",
      "Epoch 156/500\n",
      "84/84 [==============================] - 0s 536us/step - loss: 0.6296 - accuracy: 0.7500 - val_loss: 0.6534 - val_accuracy: 0.7222\n",
      "Epoch 157/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.6285 - accuracy: 0.7500 - val_loss: 0.6523 - val_accuracy: 0.7222\n",
      "Epoch 158/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.6274 - accuracy: 0.7500 - val_loss: 0.6512 - val_accuracy: 0.7222\n",
      "Epoch 159/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 0.6262 - accuracy: 0.7500 - val_loss: 0.6502 - val_accuracy: 0.7222\n",
      "Epoch 160/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.6251 - accuracy: 0.7500 - val_loss: 0.6491 - val_accuracy: 0.7222\n",
      "Epoch 161/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.6240 - accuracy: 0.7500 - val_loss: 0.6481 - val_accuracy: 0.7222\n",
      "Epoch 162/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.6230 - accuracy: 0.7500 - val_loss: 0.6471 - val_accuracy: 0.7222\n",
      "Epoch 163/500\n",
      "84/84 [==============================] - 0s 619us/step - loss: 0.6219 - accuracy: 0.7500 - val_loss: 0.6461 - val_accuracy: 0.7222\n",
      "Epoch 164/500\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6208 - accuracy: 0.7500 - val_loss: 0.6451 - val_accuracy: 0.7222\n",
      "Epoch 165/500\n",
      "84/84 [==============================] - 0s 560us/step - loss: 0.6198 - accuracy: 0.7500 - val_loss: 0.6441 - val_accuracy: 0.7222\n",
      "Epoch 166/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.6187 - accuracy: 0.7500 - val_loss: 0.6431 - val_accuracy: 0.7222\n",
      "Epoch 167/500\n",
      "84/84 [==============================] - 0s 715us/step - loss: 0.6178 - accuracy: 0.7500 - val_loss: 0.6422 - val_accuracy: 0.7222\n",
      "Epoch 168/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.6168 - accuracy: 0.7500 - val_loss: 0.6412 - val_accuracy: 0.7222\n",
      "Epoch 169/500\n",
      "84/84 [==============================] - 0s 453us/step - loss: 0.6157 - accuracy: 0.7500 - val_loss: 0.6403 - val_accuracy: 0.7222\n",
      "Epoch 170/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.6148 - accuracy: 0.7500 - val_loss: 0.6393 - val_accuracy: 0.7222\n",
      "Epoch 171/500\n",
      "84/84 [==============================] - 0s 667us/step - loss: 0.6139 - accuracy: 0.7500 - val_loss: 0.6384 - val_accuracy: 0.7222\n",
      "Epoch 172/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.6129 - accuracy: 0.7500 - val_loss: 0.6375 - val_accuracy: 0.7222\n",
      "Epoch 173/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.6119 - accuracy: 0.7500 - val_loss: 0.6366 - val_accuracy: 0.7222\n",
      "Epoch 174/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.6110 - accuracy: 0.7500 - val_loss: 0.6357 - val_accuracy: 0.7222\n",
      "Epoch 175/500\n",
      "84/84 [==============================] - 0s 726us/step - loss: 0.6101 - accuracy: 0.7500 - val_loss: 0.6348 - val_accuracy: 0.7222\n",
      "Epoch 176/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.6092 - accuracy: 0.7500 - val_loss: 0.6339 - val_accuracy: 0.7222\n",
      "Epoch 177/500\n",
      "84/84 [==============================] - 0s 464us/step - loss: 0.6082 - accuracy: 0.7500 - val_loss: 0.6331 - val_accuracy: 0.7222\n",
      "Epoch 178/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.6074 - accuracy: 0.7500 - val_loss: 0.6323 - val_accuracy: 0.7222\n",
      "Epoch 179/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.6065 - accuracy: 0.7500 - val_loss: 0.6314 - val_accuracy: 0.7222\n",
      "Epoch 180/500\n",
      "84/84 [==============================] - 0s 453us/step - loss: 0.6056 - accuracy: 0.7500 - val_loss: 0.6306 - val_accuracy: 0.7222\n",
      "Epoch 181/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.6047 - accuracy: 0.7500 - val_loss: 0.6298 - val_accuracy: 0.7222\n",
      "Epoch 182/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.6039 - accuracy: 0.7500 - val_loss: 0.6289 - val_accuracy: 0.7222\n",
      "Epoch 183/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.6030 - accuracy: 0.7500 - val_loss: 0.6281 - val_accuracy: 0.7222\n",
      "Epoch 184/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.6022 - accuracy: 0.7500 - val_loss: 0.6273 - val_accuracy: 0.7222\n",
      "Epoch 185/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.6013 - accuracy: 0.7500 - val_loss: 0.6265 - val_accuracy: 0.7222\n",
      "Epoch 186/500\n",
      "84/84 [==============================] - 0s 703us/step - loss: 0.6005 - accuracy: 0.7500 - val_loss: 0.6258 - val_accuracy: 0.7222\n",
      "Epoch 187/500\n",
      "84/84 [==============================] - 0s 667us/step - loss: 0.5997 - accuracy: 0.7500 - val_loss: 0.6250 - val_accuracy: 0.7222\n",
      "Epoch 188/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.5989 - accuracy: 0.7500 - val_loss: 0.6243 - val_accuracy: 0.7222\n",
      "Epoch 189/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5981 - accuracy: 0.7381 - val_loss: 0.6235 - val_accuracy: 0.7222\n",
      "Epoch 190/500\n",
      "84/84 [==============================] - 0s 595us/step - loss: 0.5973 - accuracy: 0.7381 - val_loss: 0.6228 - val_accuracy: 0.7222\n",
      "Epoch 191/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.5966 - accuracy: 0.7381 - val_loss: 0.6220 - val_accuracy: 0.7222\n",
      "Epoch 192/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5958 - accuracy: 0.7381 - val_loss: 0.6213 - val_accuracy: 0.7222\n",
      "Epoch 193/500\n",
      "84/84 [==============================] - 0s 893us/step - loss: 0.5951 - accuracy: 0.7381 - val_loss: 0.6206 - val_accuracy: 0.7222\n",
      "Epoch 194/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5943 - accuracy: 0.7381 - val_loss: 0.6198 - val_accuracy: 0.7222\n",
      "Epoch 195/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5935 - accuracy: 0.7381 - val_loss: 0.6191 - val_accuracy: 0.7222\n",
      "Epoch 196/500\n",
      "84/84 [==============================] - 0s 738us/step - loss: 0.5928 - accuracy: 0.7381 - val_loss: 0.6184 - val_accuracy: 0.7222\n",
      "Epoch 197/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5921 - accuracy: 0.7381 - val_loss: 0.6177 - val_accuracy: 0.7222\n",
      "Epoch 198/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.5913 - accuracy: 0.7381 - val_loss: 0.6170 - val_accuracy: 0.7222\n",
      "Epoch 199/500\n",
      "84/84 [==============================] - 0s 917us/step - loss: 0.5906 - accuracy: 0.7381 - val_loss: 0.6163 - val_accuracy: 0.7222\n",
      "Epoch 200/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5899 - accuracy: 0.7381 - val_loss: 0.6156 - val_accuracy: 0.7222\n",
      "Epoch 201/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.5892 - accuracy: 0.7381 - val_loss: 0.6149 - val_accuracy: 0.7222\n",
      "Epoch 202/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.5885 - accuracy: 0.7381 - val_loss: 0.6143 - val_accuracy: 0.7222\n",
      "Epoch 203/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 0.5878 - accuracy: 0.7381 - val_loss: 0.6136 - val_accuracy: 0.7222\n",
      "Epoch 204/500\n",
      "84/84 [==============================] - 0s 560us/step - loss: 0.5871 - accuracy: 0.7381 - val_loss: 0.6130 - val_accuracy: 0.7222\n",
      "Epoch 205/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.5864 - accuracy: 0.7381 - val_loss: 0.6123 - val_accuracy: 0.7222\n",
      "Epoch 206/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 0.5857 - accuracy: 0.7381 - val_loss: 0.6116 - val_accuracy: 0.7222\n",
      "Epoch 207/500\n",
      "84/84 [==============================] - 0s 453us/step - loss: 0.5851 - accuracy: 0.7381 - val_loss: 0.6110 - val_accuracy: 0.7222\n",
      "Epoch 208/500\n",
      "84/84 [==============================] - 0s 607us/step - loss: 0.5844 - accuracy: 0.7381 - val_loss: 0.6103 - val_accuracy: 0.7222\n",
      "Epoch 209/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5837 - accuracy: 0.7381 - val_loss: 0.6097 - val_accuracy: 0.7222\n",
      "Epoch 210/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.5832 - accuracy: 0.7381 - val_loss: 0.6091 - val_accuracy: 0.7222\n",
      "Epoch 211/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.5824 - accuracy: 0.7500 - val_loss: 0.6084 - val_accuracy: 0.7222\n",
      "Epoch 212/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5818 - accuracy: 0.7381 - val_loss: 0.6078 - val_accuracy: 0.7222\n",
      "Epoch 213/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.5811 - accuracy: 0.7381 - val_loss: 0.6073 - val_accuracy: 0.7222\n",
      "Epoch 214/500\n",
      "84/84 [==============================] - 0s 738us/step - loss: 0.5806 - accuracy: 0.7381 - val_loss: 0.6067 - val_accuracy: 0.7222\n",
      "Epoch 215/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.5799 - accuracy: 0.7381 - val_loss: 0.6061 - val_accuracy: 0.7222\n",
      "Epoch 216/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5792 - accuracy: 0.7381 - val_loss: 0.6055 - val_accuracy: 0.7222\n",
      "Epoch 217/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5786 - accuracy: 0.7381 - val_loss: 0.6048 - val_accuracy: 0.7222\n",
      "Epoch 218/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5780 - accuracy: 0.7381 - val_loss: 0.6042 - val_accuracy: 0.7222\n",
      "Epoch 219/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.5774 - accuracy: 0.7381 - val_loss: 0.6036 - val_accuracy: 0.7222\n",
      "Epoch 220/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5768 - accuracy: 0.7500 - val_loss: 0.6030 - val_accuracy: 0.7222\n",
      "Epoch 221/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.5762 - accuracy: 0.7500 - val_loss: 0.6024 - val_accuracy: 0.7222\n",
      "Epoch 222/500\n",
      "84/84 [==============================] - 0s 631us/step - loss: 0.5756 - accuracy: 0.7500 - val_loss: 0.6018 - val_accuracy: 0.7222\n",
      "Epoch 223/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5750 - accuracy: 0.7500 - val_loss: 0.6012 - val_accuracy: 0.7222\n",
      "Epoch 224/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.5744 - accuracy: 0.7500 - val_loss: 0.6006 - val_accuracy: 0.7222\n",
      "Epoch 225/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.5739 - accuracy: 0.7500 - val_loss: 0.6001 - val_accuracy: 0.7222\n",
      "Epoch 226/500\n",
      "84/84 [==============================] - 0s 560us/step - loss: 0.5733 - accuracy: 0.7500 - val_loss: 0.5995 - val_accuracy: 0.7222\n",
      "Epoch 227/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.5727 - accuracy: 0.7500 - val_loss: 0.5990 - val_accuracy: 0.7222\n",
      "Epoch 228/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5722 - accuracy: 0.7500 - val_loss: 0.5984 - val_accuracy: 0.7222\n",
      "Epoch 229/500\n",
      "84/84 [==============================] - 0s 714us/step - loss: 0.5716 - accuracy: 0.7500 - val_loss: 0.5979 - val_accuracy: 0.7222\n",
      "Epoch 230/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.5898 - accuracy: 0.75 - 0s 286us/step - loss: 0.5710 - accuracy: 0.7500 - val_loss: 0.5973 - val_accuracy: 0.7222\n",
      "Epoch 231/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5705 - accuracy: 0.7500 - val_loss: 0.5967 - val_accuracy: 0.7222\n",
      "Epoch 232/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5699 - accuracy: 0.7500 - val_loss: 0.5962 - val_accuracy: 0.7222\n",
      "Epoch 233/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5694 - accuracy: 0.7500 - val_loss: 0.5957 - val_accuracy: 0.7222\n",
      "Epoch 234/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5688 - accuracy: 0.7500 - val_loss: 0.5951 - val_accuracy: 0.7222\n",
      "Epoch 235/500\n",
      "84/84 [==============================] - 0s 464us/step - loss: 0.5683 - accuracy: 0.7500 - val_loss: 0.5946 - val_accuracy: 0.7222\n",
      "Epoch 236/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5677 - accuracy: 0.7500 - val_loss: 0.5941 - val_accuracy: 0.7222\n",
      "Epoch 237/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5672 - accuracy: 0.7500 - val_loss: 0.5935 - val_accuracy: 0.7222\n",
      "Epoch 238/500\n",
      "84/84 [==============================] - 0s 512us/step - loss: 0.5667 - accuracy: 0.7500 - val_loss: 0.5930 - val_accuracy: 0.7222\n",
      "Epoch 239/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.5661 - accuracy: 0.7500 - val_loss: 0.5925 - val_accuracy: 0.7222\n",
      "Epoch 240/500\n",
      "84/84 [==============================] - 0s 583us/step - loss: 0.5656 - accuracy: 0.7500 - val_loss: 0.5920 - val_accuracy: 0.7222\n",
      "Epoch 241/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5651 - accuracy: 0.7500 - val_loss: 0.5915 - val_accuracy: 0.7222\n",
      "Epoch 242/500\n",
      "84/84 [==============================] - 0s 583us/step - loss: 0.5646 - accuracy: 0.7500 - val_loss: 0.5910 - val_accuracy: 0.7222\n",
      "Epoch 243/500\n",
      "84/84 [==============================] - 0s 774us/step - loss: 0.5641 - accuracy: 0.7500 - val_loss: 0.5905 - val_accuracy: 0.7222\n",
      "Epoch 244/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.5635 - accuracy: 0.7500 - val_loss: 0.5900 - val_accuracy: 0.7222\n",
      "Epoch 245/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.5630 - accuracy: 0.7500 - val_loss: 0.5895 - val_accuracy: 0.7222\n",
      "Epoch 246/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5625 - accuracy: 0.7500 - val_loss: 0.5891 - val_accuracy: 0.7222\n",
      "Epoch 247/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.5620 - accuracy: 0.7500 - val_loss: 0.5886 - val_accuracy: 0.7222\n",
      "Epoch 248/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5616 - accuracy: 0.7500 - val_loss: 0.5881 - val_accuracy: 0.7222\n",
      "Epoch 249/500\n",
      "84/84 [==============================] - 0s 762us/step - loss: 0.5610 - accuracy: 0.7500 - val_loss: 0.5877 - val_accuracy: 0.7222\n",
      "Epoch 250/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5606 - accuracy: 0.7500 - val_loss: 0.5872 - val_accuracy: 0.7222\n",
      "Epoch 251/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5601 - accuracy: 0.7500 - val_loss: 0.5867 - val_accuracy: 0.7222\n",
      "Epoch 252/500\n",
      "84/84 [==============================] - 0s 226us/step - loss: 0.5597 - accuracy: 0.7500 - val_loss: 0.5863 - val_accuracy: 0.7222\n",
      "Epoch 253/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5591 - accuracy: 0.7500 - val_loss: 0.5858 - val_accuracy: 0.7222\n",
      "Epoch 254/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5587 - accuracy: 0.7500 - val_loss: 0.5854 - val_accuracy: 0.7222\n",
      "Epoch 255/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5582 - accuracy: 0.7500 - val_loss: 0.5849 - val_accuracy: 0.7222\n",
      "Epoch 256/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.5573 - accuracy: 0.75 - 0s 333us/step - loss: 0.5577 - accuracy: 0.7500 - val_loss: 0.5844 - val_accuracy: 0.7222\n",
      "Epoch 257/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5572 - accuracy: 0.7500 - val_loss: 0.5840 - val_accuracy: 0.7222\n",
      "Epoch 258/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5568 - accuracy: 0.7500 - val_loss: 0.5835 - val_accuracy: 0.7222\n",
      "Epoch 259/500\n",
      "84/84 [==============================] - 0s 464us/step - loss: 0.5563 - accuracy: 0.7500 - val_loss: 0.5830 - val_accuracy: 0.7222\n",
      "Epoch 260/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5559 - accuracy: 0.7619 - val_loss: 0.5826 - val_accuracy: 0.7222\n",
      "Epoch 261/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5554 - accuracy: 0.7619 - val_loss: 0.5821 - val_accuracy: 0.7222\n",
      "Epoch 262/500\n",
      "84/84 [==============================] - 0s 226us/step - loss: 0.5549 - accuracy: 0.7500 - val_loss: 0.5817 - val_accuracy: 0.7222\n",
      "Epoch 263/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.5545 - accuracy: 0.7500 - val_loss: 0.5813 - val_accuracy: 0.7222\n",
      "Epoch 264/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5540 - accuracy: 0.7500 - val_loss: 0.5808 - val_accuracy: 0.7222\n",
      "Epoch 265/500\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5536 - accuracy: 0.7500 - val_loss: 0.5804 - val_accuracy: 0.7222\n",
      "Epoch 266/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.5531 - accuracy: 0.7500 - val_loss: 0.5800 - val_accuracy: 0.7222\n",
      "Epoch 267/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5527 - accuracy: 0.7500 - val_loss: 0.5795 - val_accuracy: 0.7222\n",
      "Epoch 268/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 0.5522 - accuracy: 0.7500 - val_loss: 0.5791 - val_accuracy: 0.7222\n",
      "Epoch 269/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 0.5518 - accuracy: 0.7500 - val_loss: 0.5787 - val_accuracy: 0.7222\n",
      "Epoch 270/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.5514 - accuracy: 0.7500 - val_loss: 0.5783 - val_accuracy: 0.7222\n",
      "Epoch 271/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.5509 - accuracy: 0.7500 - val_loss: 0.5778 - val_accuracy: 0.7222\n",
      "Epoch 272/500\n",
      "84/84 [==============================] - 0s 798us/step - loss: 0.5505 - accuracy: 0.7500 - val_loss: 0.5774 - val_accuracy: 0.7222\n",
      "Epoch 273/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5501 - accuracy: 0.7500 - val_loss: 0.5770 - val_accuracy: 0.7222\n",
      "Epoch 274/500\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5496 - accuracy: 0.7500 - val_loss: 0.5766 - val_accuracy: 0.7222\n",
      "Epoch 275/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5492 - accuracy: 0.7500 - val_loss: 0.5762 - val_accuracy: 0.7222\n",
      "Epoch 276/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5488 - accuracy: 0.7500 - val_loss: 0.5758 - val_accuracy: 0.7222\n",
      "Epoch 277/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5484 - accuracy: 0.7500 - val_loss: 0.5754 - val_accuracy: 0.7222\n",
      "Epoch 278/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5479 - accuracy: 0.7619 - val_loss: 0.5750 - val_accuracy: 0.7222\n",
      "Epoch 279/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.5475 - accuracy: 0.7619 - val_loss: 0.5746 - val_accuracy: 0.7222\n",
      "Epoch 280/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.5471 - accuracy: 0.7619 - val_loss: 0.5742 - val_accuracy: 0.7222\n",
      "Epoch 281/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.5468 - accuracy: 0.7619 - val_loss: 0.5738 - val_accuracy: 0.7222\n",
      "Epoch 282/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5463 - accuracy: 0.7619 - val_loss: 0.5733 - val_accuracy: 0.7222\n",
      "Epoch 283/500\n",
      "84/84 [==============================] - 0s 226us/step - loss: 0.5459 - accuracy: 0.7619 - val_loss: 0.5729 - val_accuracy: 0.7222\n",
      "Epoch 284/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5455 - accuracy: 0.7619 - val_loss: 0.5725 - val_accuracy: 0.7222\n",
      "Epoch 285/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5451 - accuracy: 0.7619 - val_loss: 0.5721 - val_accuracy: 0.7222\n",
      "Epoch 286/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5448 - accuracy: 0.7619 - val_loss: 0.5717 - val_accuracy: 0.7500\n",
      "Epoch 287/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5443 - accuracy: 0.7619 - val_loss: 0.5713 - val_accuracy: 0.7500\n",
      "Epoch 288/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5439 - accuracy: 0.7619 - val_loss: 0.5709 - val_accuracy: 0.7222\n",
      "Epoch 289/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.5435 - accuracy: 0.7619 - val_loss: 0.5705 - val_accuracy: 0.7500\n",
      "Epoch 290/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5431 - accuracy: 0.7619 - val_loss: 0.5701 - val_accuracy: 0.7222\n",
      "Epoch 291/500\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5427 - accuracy: 0.7619 - val_loss: 0.5697 - val_accuracy: 0.7222\n",
      "Epoch 292/500\n",
      "84/84 [==============================] - 0s 536us/step - loss: 0.5423 - accuracy: 0.7619 - val_loss: 0.5694 - val_accuracy: 0.7222\n",
      "Epoch 293/500\n",
      "84/84 [==============================] - 0s 798us/step - loss: 0.5419 - accuracy: 0.7619 - val_loss: 0.5689 - val_accuracy: 0.7222\n",
      "Epoch 294/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5416 - accuracy: 0.7619 - val_loss: 0.5686 - val_accuracy: 0.7222\n",
      "Epoch 295/500\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5412 - accuracy: 0.7619 - val_loss: 0.5682 - val_accuracy: 0.7222\n",
      "Epoch 296/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.5408 - accuracy: 0.7619 - val_loss: 0.5678 - val_accuracy: 0.7222\n",
      "Epoch 297/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5404 - accuracy: 0.7619 - val_loss: 0.5675 - val_accuracy: 0.7222\n",
      "Epoch 298/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5401 - accuracy: 0.7619 - val_loss: 0.5671 - val_accuracy: 0.7222\n",
      "Epoch 299/500\n",
      "84/84 [==============================] - 0s 738us/step - loss: 0.5397 - accuracy: 0.7619 - val_loss: 0.5668 - val_accuracy: 0.7222\n",
      "Epoch 300/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.5393 - accuracy: 0.7619 - val_loss: 0.5664 - val_accuracy: 0.7222\n",
      "Epoch 301/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5389 - accuracy: 0.7619 - val_loss: 0.5660 - val_accuracy: 0.7222\n",
      "Epoch 302/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5385 - accuracy: 0.7619 - val_loss: 0.5657 - val_accuracy: 0.7222\n",
      "Epoch 303/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5382 - accuracy: 0.7619 - val_loss: 0.5654 - val_accuracy: 0.7222\n",
      "Epoch 304/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5378 - accuracy: 0.7619 - val_loss: 0.5650 - val_accuracy: 0.7500\n",
      "Epoch 305/500\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5375 - accuracy: 0.7619 - val_loss: 0.5647 - val_accuracy: 0.7500\n",
      "Epoch 306/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5371 - accuracy: 0.7619 - val_loss: 0.5643 - val_accuracy: 0.7222\n",
      "Epoch 307/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5367 - accuracy: 0.7619 - val_loss: 0.5640 - val_accuracy: 0.7222\n",
      "Epoch 308/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5364 - accuracy: 0.7619 - val_loss: 0.5636 - val_accuracy: 0.7222\n",
      "Epoch 309/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5360 - accuracy: 0.7619 - val_loss: 0.5633 - val_accuracy: 0.7222\n",
      "Epoch 310/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5357 - accuracy: 0.7619 - val_loss: 0.5629 - val_accuracy: 0.7222\n",
      "Epoch 311/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5353 - accuracy: 0.7619 - val_loss: 0.5626 - val_accuracy: 0.7222\n",
      "Epoch 312/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5349 - accuracy: 0.7619 - val_loss: 0.5622 - val_accuracy: 0.7500\n",
      "Epoch 313/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5346 - accuracy: 0.7619 - val_loss: 0.5619 - val_accuracy: 0.7500\n",
      "Epoch 314/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5342 - accuracy: 0.7619 - val_loss: 0.5615 - val_accuracy: 0.7500\n",
      "Epoch 315/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5339 - accuracy: 0.7738 - val_loss: 0.5612 - val_accuracy: 0.7778\n",
      "Epoch 316/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5336 - accuracy: 0.7857 - val_loss: 0.5608 - val_accuracy: 0.8056\n",
      "Epoch 317/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5332 - accuracy: 0.7976 - val_loss: 0.5605 - val_accuracy: 0.8056\n",
      "Epoch 318/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5329 - accuracy: 0.7976 - val_loss: 0.5601 - val_accuracy: 0.8056\n",
      "Epoch 319/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5326 - accuracy: 0.7976 - val_loss: 0.5598 - val_accuracy: 0.8056\n",
      "Epoch 320/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5322 - accuracy: 0.7976 - val_loss: 0.5594 - val_accuracy: 0.8056\n",
      "Epoch 321/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5318 - accuracy: 0.7976 - val_loss: 0.5591 - val_accuracy: 0.8056\n",
      "Epoch 322/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.5315 - accuracy: 0.7976 - val_loss: 0.5587 - val_accuracy: 0.8056\n",
      "Epoch 323/500\n",
      "84/84 [==============================] - 0s 726us/step - loss: 0.5311 - accuracy: 0.7976 - val_loss: 0.5584 - val_accuracy: 0.7778\n",
      "Epoch 324/500\n",
      "84/84 [==============================] - 0s 714us/step - loss: 0.5308 - accuracy: 0.7857 - val_loss: 0.5580 - val_accuracy: 0.7778\n",
      "Epoch 325/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.5305 - accuracy: 0.7857 - val_loss: 0.5577 - val_accuracy: 0.7500\n",
      "Epoch 326/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.5302 - accuracy: 0.7857 - val_loss: 0.5574 - val_accuracy: 0.7778\n",
      "Epoch 327/500\n",
      "84/84 [==============================] - 0s 703us/step - loss: 0.5298 - accuracy: 0.7857 - val_loss: 0.5570 - val_accuracy: 0.7778\n",
      "Epoch 328/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5295 - accuracy: 0.7857 - val_loss: 0.5567 - val_accuracy: 0.7500\n",
      "Epoch 329/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5291 - accuracy: 0.7857 - val_loss: 0.5563 - val_accuracy: 0.7778\n",
      "Epoch 330/500\n",
      "84/84 [==============================] - 0s 583us/step - loss: 0.5288 - accuracy: 0.7857 - val_loss: 0.5560 - val_accuracy: 0.8056\n",
      "Epoch 331/500\n",
      "84/84 [==============================] - 0s 762us/step - loss: 0.5285 - accuracy: 0.7976 - val_loss: 0.5556 - val_accuracy: 0.8056\n",
      "Epoch 332/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.5282 - accuracy: 0.7976 - val_loss: 0.5553 - val_accuracy: 0.8056\n",
      "Epoch 333/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5278 - accuracy: 0.7976 - val_loss: 0.5550 - val_accuracy: 0.8056\n",
      "Epoch 334/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.5275 - accuracy: 0.7976 - val_loss: 0.5546 - val_accuracy: 0.8056\n",
      "Epoch 335/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.5272 - accuracy: 0.7976 - val_loss: 0.5543 - val_accuracy: 0.8056\n",
      "Epoch 336/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5268 - accuracy: 0.7976 - val_loss: 0.5540 - val_accuracy: 0.8333\n",
      "Epoch 337/500\n",
      "84/84 [==============================] - 0s 631us/step - loss: 0.5265 - accuracy: 0.7976 - val_loss: 0.5537 - val_accuracy: 0.8333\n",
      "Epoch 338/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5262 - accuracy: 0.7976 - val_loss: 0.5534 - val_accuracy: 0.8333\n",
      "Epoch 339/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5259 - accuracy: 0.7976 - val_loss: 0.5530 - val_accuracy: 0.8333\n",
      "Epoch 340/500\n",
      "84/84 [==============================] - 0s 512us/step - loss: 0.5255 - accuracy: 0.7976 - val_loss: 0.5527 - val_accuracy: 0.8333\n",
      "Epoch 341/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5252 - accuracy: 0.7976 - val_loss: 0.5524 - val_accuracy: 0.8333\n",
      "Epoch 342/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5249 - accuracy: 0.7976 - val_loss: 0.5521 - val_accuracy: 0.8333\n",
      "Epoch 343/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5246 - accuracy: 0.7976 - val_loss: 0.5518 - val_accuracy: 0.8333\n",
      "Epoch 344/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5243 - accuracy: 0.7976 - val_loss: 0.5515 - val_accuracy: 0.8333\n",
      "Epoch 345/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5240 - accuracy: 0.7976 - val_loss: 0.5512 - val_accuracy: 0.8333\n",
      "Epoch 346/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5237 - accuracy: 0.7976 - val_loss: 0.5509 - val_accuracy: 0.8056\n",
      "Epoch 347/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.5234 - accuracy: 0.7976 - val_loss: 0.5506 - val_accuracy: 0.8056\n",
      "Epoch 348/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5231 - accuracy: 0.7976 - val_loss: 0.5503 - val_accuracy: 0.8056\n",
      "Epoch 349/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.5228 - accuracy: 0.7976 - val_loss: 0.5499 - val_accuracy: 0.8056\n",
      "Epoch 350/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.5224 - accuracy: 0.7976 - val_loss: 0.5496 - val_accuracy: 0.8056\n",
      "Epoch 351/500\n",
      "84/84 [==============================] - 0s 560us/step - loss: 0.5221 - accuracy: 0.7976 - val_loss: 0.5493 - val_accuracy: 0.8056\n",
      "Epoch 352/500\n",
      "84/84 [==============================] - 0s 643us/step - loss: 0.5218 - accuracy: 0.7976 - val_loss: 0.5489 - val_accuracy: 0.8333\n",
      "Epoch 353/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.5215 - accuracy: 0.7976 - val_loss: 0.5486 - val_accuracy: 0.8333\n",
      "Epoch 354/500\n",
      "84/84 [==============================] - 0s 560us/step - loss: 0.5212 - accuracy: 0.7976 - val_loss: 0.5483 - val_accuracy: 0.8333\n",
      "Epoch 355/500\n",
      "84/84 [==============================] - 0s 941us/step - loss: 0.5209 - accuracy: 0.7976 - val_loss: 0.5480 - val_accuracy: 0.8056\n",
      "Epoch 356/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.5206 - accuracy: 0.7976 - val_loss: 0.5477 - val_accuracy: 0.8056\n",
      "Epoch 357/500\n",
      "84/84 [==============================] - 0s 762us/step - loss: 0.5203 - accuracy: 0.7976 - val_loss: 0.5474 - val_accuracy: 0.8056\n",
      "Epoch 358/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5200 - accuracy: 0.7976 - val_loss: 0.5471 - val_accuracy: 0.8056\n",
      "Epoch 359/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.5197 - accuracy: 0.7976 - val_loss: 0.5468 - val_accuracy: 0.8056\n",
      "Epoch 360/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.5193 - accuracy: 0.8095 - val_loss: 0.5464 - val_accuracy: 0.8056\n",
      "Epoch 361/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5191 - accuracy: 0.8095 - val_loss: 0.5461 - val_accuracy: 0.8056\n",
      "Epoch 362/500\n",
      "84/84 [==============================] - 0s 857us/step - loss: 0.5187 - accuracy: 0.8095 - val_loss: 0.5458 - val_accuracy: 0.8333\n",
      "Epoch 363/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5185 - accuracy: 0.8095 - val_loss: 0.5454 - val_accuracy: 0.8333\n",
      "Epoch 364/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5182 - accuracy: 0.8333 - val_loss: 0.5451 - val_accuracy: 0.8333\n",
      "Epoch 365/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.5179 - accuracy: 0.8333 - val_loss: 0.5448 - val_accuracy: 0.8333\n",
      "Epoch 366/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5176 - accuracy: 0.8333 - val_loss: 0.5445 - val_accuracy: 0.8333\n",
      "Epoch 367/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5173 - accuracy: 0.8333 - val_loss: 0.5442 - val_accuracy: 0.8333\n",
      "Epoch 368/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5170 - accuracy: 0.8333 - val_loss: 0.5439 - val_accuracy: 0.8333\n",
      "Epoch 369/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5167 - accuracy: 0.8333 - val_loss: 0.5436 - val_accuracy: 0.8333\n",
      "Epoch 370/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5164 - accuracy: 0.8333 - val_loss: 0.5433 - val_accuracy: 0.8333\n",
      "Epoch 371/500\n",
      "84/84 [==============================] - 0s 321us/step - loss: 0.5161 - accuracy: 0.8333 - val_loss: 0.5430 - val_accuracy: 0.8333\n",
      "Epoch 372/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5158 - accuracy: 0.8333 - val_loss: 0.5427 - val_accuracy: 0.8333\n",
      "Epoch 373/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5155 - accuracy: 0.8095 - val_loss: 0.5424 - val_accuracy: 0.8056\n",
      "Epoch 374/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5152 - accuracy: 0.8095 - val_loss: 0.5421 - val_accuracy: 0.8056\n",
      "Epoch 375/500\n",
      "84/84 [==============================] - 0s 464us/step - loss: 0.5150 - accuracy: 0.8095 - val_loss: 0.5418 - val_accuracy: 0.8333\n",
      "Epoch 376/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5147 - accuracy: 0.8095 - val_loss: 0.5415 - val_accuracy: 0.8333\n",
      "Epoch 377/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5144 - accuracy: 0.8214 - val_loss: 0.5413 - val_accuracy: 0.8333\n",
      "Epoch 378/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5141 - accuracy: 0.8214 - val_loss: 0.5410 - val_accuracy: 0.8333\n",
      "Epoch 379/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5138 - accuracy: 0.8214 - val_loss: 0.5407 - val_accuracy: 0.8333\n",
      "Epoch 380/500\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.8214 - val_loss: 0.5403 - val_accuracy: 0.8333\n",
      "Epoch 381/500\n",
      "84/84 [==============================] - 0s 287us/step - loss: 0.5132 - accuracy: 0.8214 - val_loss: 0.5400 - val_accuracy: 0.8333\n",
      "Epoch 382/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.5130 - accuracy: 0.8095 - val_loss: 0.5398 - val_accuracy: 0.8333\n",
      "Epoch 383/500\n",
      "84/84 [==============================] - 0s 226us/step - loss: 0.5126 - accuracy: 0.8214 - val_loss: 0.5395 - val_accuracy: 0.8333\n",
      "Epoch 384/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5124 - accuracy: 0.8333 - val_loss: 0.5392 - val_accuracy: 0.8333\n",
      "Epoch 385/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5121 - accuracy: 0.8333 - val_loss: 0.5390 - val_accuracy: 0.8611\n",
      "Epoch 386/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5118 - accuracy: 0.8333 - val_loss: 0.5387 - val_accuracy: 0.8611\n",
      "Epoch 387/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5116 - accuracy: 0.8333 - val_loss: 0.5384 - val_accuracy: 0.8611\n",
      "Epoch 388/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5113 - accuracy: 0.8333 - val_loss: 0.5380 - val_accuracy: 0.8611\n",
      "Epoch 389/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5110 - accuracy: 0.8333 - val_loss: 0.5377 - val_accuracy: 0.8611\n",
      "Epoch 390/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5107 - accuracy: 0.8333 - val_loss: 0.5375 - val_accuracy: 0.8611\n",
      "Epoch 391/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5104 - accuracy: 0.8333 - val_loss: 0.5371 - val_accuracy: 0.8611\n",
      "Epoch 392/500\n",
      "84/84 [==============================] - 0s 226us/step - loss: 0.5101 - accuracy: 0.8333 - val_loss: 0.5369 - val_accuracy: 0.8611\n",
      "Epoch 393/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5099 - accuracy: 0.8333 - val_loss: 0.5366 - val_accuracy: 0.8611\n",
      "Epoch 394/500\n",
      "84/84 [==============================] - 0s 453us/step - loss: 0.5096 - accuracy: 0.8333 - val_loss: 0.5363 - val_accuracy: 0.8611\n",
      "Epoch 395/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.5094 - accuracy: 0.8333 - val_loss: 0.5359 - val_accuracy: 0.8611\n",
      "Epoch 396/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5091 - accuracy: 0.8333 - val_loss: 0.5356 - val_accuracy: 0.8611\n",
      "Epoch 397/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5088 - accuracy: 0.8333 - val_loss: 0.5352 - val_accuracy: 0.8611\n",
      "Epoch 398/500\n",
      "84/84 [==============================] - 0s 583us/step - loss: 0.5085 - accuracy: 0.8333 - val_loss: 0.5349 - val_accuracy: 0.8611\n",
      "Epoch 399/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5082 - accuracy: 0.8333 - val_loss: 0.5346 - val_accuracy: 0.8611\n",
      "Epoch 400/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.5080 - accuracy: 0.8333 - val_loss: 0.5343 - val_accuracy: 0.8611\n",
      "Epoch 401/500\n",
      "84/84 [==============================] - 0s 584us/step - loss: 0.5077 - accuracy: 0.8333 - val_loss: 0.5340 - val_accuracy: 0.8611\n",
      "Epoch 402/500\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.8333 - val_loss: 0.5337 - val_accuracy: 0.8611\n",
      "Epoch 403/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.5071 - accuracy: 0.8333 - val_loss: 0.5335 - val_accuracy: 0.8611\n",
      "Epoch 404/500\n",
      "84/84 [==============================] - 0s 511us/step - loss: 0.5069 - accuracy: 0.8333 - val_loss: 0.5332 - val_accuracy: 0.8611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.102024). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 405/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.5066 - accuracy: 0.8333 - val_loss: 0.5329 - val_accuracy: 0.8611\n",
      "Epoch 406/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5063 - accuracy: 0.8333 - val_loss: 0.5327 - val_accuracy: 0.8611\n",
      "Epoch 407/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5060 - accuracy: 0.8333 - val_loss: 0.5324 - val_accuracy: 0.8611\n",
      "Epoch 408/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.5058 - accuracy: 0.8333 - val_loss: 0.5321 - val_accuracy: 0.8611\n",
      "Epoch 409/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5055 - accuracy: 0.8333 - val_loss: 0.5317 - val_accuracy: 0.8611\n",
      "Epoch 410/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.5053 - accuracy: 0.8333 - val_loss: 0.5314 - val_accuracy: 0.8611\n",
      "Epoch 411/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.5051 - accuracy: 0.8333 - val_loss: 0.5311 - val_accuracy: 0.8611\n",
      "Epoch 412/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.5047 - accuracy: 0.8333 - val_loss: 0.5308 - val_accuracy: 0.8611\n",
      "Epoch 413/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5045 - accuracy: 0.8333 - val_loss: 0.5306 - val_accuracy: 0.8611\n",
      "Epoch 414/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5042 - accuracy: 0.8333 - val_loss: 0.5303 - val_accuracy: 0.8611\n",
      "Epoch 415/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5039 - accuracy: 0.8333 - val_loss: 0.5300 - val_accuracy: 0.8611\n",
      "Epoch 416/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5036 - accuracy: 0.8333 - val_loss: 0.5297 - val_accuracy: 0.8611\n",
      "Epoch 417/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5034 - accuracy: 0.8333 - val_loss: 0.5294 - val_accuracy: 0.8611\n",
      "Epoch 418/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5031 - accuracy: 0.8333 - val_loss: 0.5291 - val_accuracy: 0.8611\n",
      "Epoch 419/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5028 - accuracy: 0.8333 - val_loss: 0.5288 - val_accuracy: 0.8611\n",
      "Epoch 420/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5025 - accuracy: 0.8333 - val_loss: 0.5286 - val_accuracy: 0.8611\n",
      "Epoch 421/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.5023 - accuracy: 0.8452 - val_loss: 0.5284 - val_accuracy: 0.8611\n",
      "Epoch 422/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 0.5020 - accuracy: 0.8452 - val_loss: 0.5281 - val_accuracy: 0.8611\n",
      "Epoch 423/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5018 - accuracy: 0.8452 - val_loss: 0.5279 - val_accuracy: 0.8611\n",
      "Epoch 424/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5015 - accuracy: 0.8452 - val_loss: 0.5276 - val_accuracy: 0.8611\n",
      "Epoch 425/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5013 - accuracy: 0.8452 - val_loss: 0.5272 - val_accuracy: 0.8611\n",
      "Epoch 426/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5010 - accuracy: 0.8452 - val_loss: 0.5269 - val_accuracy: 0.8611\n",
      "Epoch 427/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.5008 - accuracy: 0.8333 - val_loss: 0.5266 - val_accuracy: 0.8611\n",
      "Epoch 428/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5004 - accuracy: 0.8333 - val_loss: 0.5263 - val_accuracy: 0.8611\n",
      "Epoch 429/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5002 - accuracy: 0.8333 - val_loss: 0.5260 - val_accuracy: 0.8611\n",
      "Epoch 430/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.4999 - accuracy: 0.8452 - val_loss: 0.5257 - val_accuracy: 0.8611\n",
      "Epoch 431/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.4997 - accuracy: 0.8333 - val_loss: 0.5255 - val_accuracy: 0.8611\n",
      "Epoch 432/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.4994 - accuracy: 0.8333 - val_loss: 0.5252 - val_accuracy: 0.8611\n",
      "Epoch 433/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.4991 - accuracy: 0.8333 - val_loss: 0.5249 - val_accuracy: 0.8611\n",
      "Epoch 434/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.4989 - accuracy: 0.8333 - val_loss: 0.5246 - val_accuracy: 0.8611\n",
      "Epoch 435/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.4986 - accuracy: 0.8333 - val_loss: 0.5244 - val_accuracy: 0.8611\n",
      "Epoch 436/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.4984 - accuracy: 0.8452 - val_loss: 0.5241 - val_accuracy: 0.8611\n",
      "Epoch 437/500\n",
      "84/84 [==============================] - 0s 464us/step - loss: 0.4981 - accuracy: 0.8452 - val_loss: 0.5238 - val_accuracy: 0.8611\n",
      "Epoch 438/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.4978 - accuracy: 0.8333 - val_loss: 0.5236 - val_accuracy: 0.8611\n",
      "Epoch 439/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.4976 - accuracy: 0.8333 - val_loss: 0.5233 - val_accuracy: 0.8611\n",
      "Epoch 440/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.4973 - accuracy: 0.8333 - val_loss: 0.5230 - val_accuracy: 0.8611\n",
      "Epoch 441/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.4971 - accuracy: 0.8452 - val_loss: 0.5228 - val_accuracy: 0.8611\n",
      "Epoch 442/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 0.4968 - accuracy: 0.8452 - val_loss: 0.5225 - val_accuracy: 0.8611\n",
      "Epoch 443/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.4965 - accuracy: 0.8452 - val_loss: 0.5222 - val_accuracy: 0.8611\n",
      "Epoch 444/500\n",
      "84/84 [==============================] - 0s 512us/step - loss: 0.4963 - accuracy: 0.8452 - val_loss: 0.5220 - val_accuracy: 0.8611\n",
      "Epoch 445/500\n",
      "84/84 [==============================] - 0s 452us/step - loss: 0.4960 - accuracy: 0.8452 - val_loss: 0.5216 - val_accuracy: 0.8611\n",
      "Epoch 446/500\n",
      "84/84 [==============================] - 0s 917us/step - loss: 0.4958 - accuracy: 0.8333 - val_loss: 0.5213 - val_accuracy: 0.8611\n",
      "Epoch 447/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.4955 - accuracy: 0.8333 - val_loss: 0.5210 - val_accuracy: 0.8611\n",
      "Epoch 448/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.4952 - accuracy: 0.8333 - val_loss: 0.5207 - val_accuracy: 0.8611\n",
      "Epoch 449/500\n",
      "84/84 [==============================] - 0s 976us/step - loss: 0.4950 - accuracy: 0.8333 - val_loss: 0.5205 - val_accuracy: 0.8611\n",
      "Epoch 450/500\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.8333 - val_loss: 0.5202 - val_accuracy: 0.8611\n",
      "Epoch 451/500\n",
      "84/84 [==============================] - 0s 595us/step - loss: 0.4945 - accuracy: 0.8333 - val_loss: 0.5199 - val_accuracy: 0.8611\n",
      "Epoch 452/500\n",
      "32/84 [==========>...................] - ETA: 0s - loss: 0.4625 - accuracy: 0.8125"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.135036). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 441us/step - loss: 0.4942 - accuracy: 0.8333 - val_loss: 0.5197 - val_accuracy: 0.8611\n",
      "Epoch 453/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.4939 - accuracy: 0.8333 - val_loss: 0.5194 - val_accuracy: 0.8611\n",
      "Epoch 454/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.4937 - accuracy: 0.8333 - val_loss: 0.5191 - val_accuracy: 0.8611\n",
      "Epoch 455/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.4934 - accuracy: 0.8333 - val_loss: 0.5188 - val_accuracy: 0.8611\n",
      "Epoch 456/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.4932 - accuracy: 0.8333 - val_loss: 0.5186 - val_accuracy: 0.8611\n",
      "Epoch 457/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.4929 - accuracy: 0.8333 - val_loss: 0.5183 - val_accuracy: 0.8611\n",
      "Epoch 458/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.4927 - accuracy: 0.8333 - val_loss: 0.5180 - val_accuracy: 0.8611\n",
      "Epoch 459/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.4924 - accuracy: 0.8333 - val_loss: 0.5177 - val_accuracy: 0.8611\n",
      "Epoch 460/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.4921 - accuracy: 0.8452 - val_loss: 0.5175 - val_accuracy: 0.8611\n",
      "Epoch 461/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.4919 - accuracy: 0.8452 - val_loss: 0.5173 - val_accuracy: 0.8611\n",
      "Epoch 462/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.4916 - accuracy: 0.8571 - val_loss: 0.5170 - val_accuracy: 0.8611\n",
      "Epoch 463/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.4914 - accuracy: 0.8571 - val_loss: 0.5167 - val_accuracy: 0.8611\n",
      "Epoch 464/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.4911 - accuracy: 0.8571 - val_loss: 0.5163 - val_accuracy: 0.8611\n",
      "Epoch 465/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.4910 - accuracy: 0.8571 - val_loss: 0.5159 - val_accuracy: 0.8611\n",
      "Epoch 466/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.4906 - accuracy: 0.8452 - val_loss: 0.5156 - val_accuracy: 0.8611\n",
      "Epoch 467/500\n",
      "84/84 [==============================] - 0s 988us/step - loss: 0.4903 - accuracy: 0.8571 - val_loss: 0.5153 - val_accuracy: 0.8611\n",
      "Epoch 468/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.4901 - accuracy: 0.8452 - val_loss: 0.5150 - val_accuracy: 0.8611\n",
      "Epoch 469/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.4898 - accuracy: 0.8452 - val_loss: 0.5148 - val_accuracy: 0.8611\n",
      "Epoch 470/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.5606 - accuracy: 0.81 - 0s 298us/step - loss: 0.4896 - accuracy: 0.8452 - val_loss: 0.5145 - val_accuracy: 0.8611\n",
      "Epoch 471/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.4893 - accuracy: 0.8452 - val_loss: 0.5142 - val_accuracy: 0.8611\n",
      "Epoch 472/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.4891 - accuracy: 0.8571 - val_loss: 0.5140 - val_accuracy: 0.8611\n",
      "Epoch 473/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.4888 - accuracy: 0.8571 - val_loss: 0.5138 - val_accuracy: 0.8611\n",
      "Epoch 474/500\n",
      "84/84 [==============================] - 0s 226us/step - loss: 0.4885 - accuracy: 0.8571 - val_loss: 0.5135 - val_accuracy: 0.8611\n",
      "Epoch 475/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.4883 - accuracy: 0.8571 - val_loss: 0.5132 - val_accuracy: 0.8611\n",
      "Epoch 476/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.4880 - accuracy: 0.8571 - val_loss: 0.5129 - val_accuracy: 0.8611\n",
      "Epoch 477/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.4878 - accuracy: 0.8571 - val_loss: 0.5127 - val_accuracy: 0.8611\n",
      "Epoch 478/500\n",
      "84/84 [==============================] - 0s 226us/step - loss: 0.4875 - accuracy: 0.8571 - val_loss: 0.5123 - val_accuracy: 0.8611\n",
      "Epoch 479/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.4873 - accuracy: 0.8571 - val_loss: 0.5120 - val_accuracy: 0.8611\n",
      "Epoch 480/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.4870 - accuracy: 0.8571 - val_loss: 0.5116 - val_accuracy: 0.8611\n",
      "Epoch 481/500\n",
      "84/84 [==============================] - 0s 584us/step - loss: 0.4868 - accuracy: 0.8571 - val_loss: 0.5113 - val_accuracy: 0.8611\n",
      "Epoch 482/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.4865 - accuracy: 0.8452 - val_loss: 0.5111 - val_accuracy: 0.8611\n",
      "Epoch 483/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.4863 - accuracy: 0.8452 - val_loss: 0.5108 - val_accuracy: 0.8611\n",
      "Epoch 484/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.4672 - accuracy: 0.84 - 0s 310us/step - loss: 0.4860 - accuracy: 0.8571 - val_loss: 0.5106 - val_accuracy: 0.8611\n",
      "Epoch 485/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.4857 - accuracy: 0.8571 - val_loss: 0.5103 - val_accuracy: 0.8611\n",
      "Epoch 486/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.4855 - accuracy: 0.8571 - val_loss: 0.5100 - val_accuracy: 0.8611\n",
      "Epoch 487/500\n",
      "84/84 [==============================] - 0s 822us/step - loss: 0.4853 - accuracy: 0.8571 - val_loss: 0.5096 - val_accuracy: 0.8611\n",
      "Epoch 488/500\n",
      "84/84 [==============================] - 0s 583us/step - loss: 0.4851 - accuracy: 0.8452 - val_loss: 0.5094 - val_accuracy: 0.8611\n",
      "Epoch 489/500\n",
      "84/84 [==============================] - 0s 512us/step - loss: 0.4847 - accuracy: 0.8452 - val_loss: 0.5091 - val_accuracy: 0.8611\n",
      "Epoch 490/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.4845 - accuracy: 0.8571 - val_loss: 0.5087 - val_accuracy: 0.8611\n",
      "Epoch 491/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.4842 - accuracy: 0.8571 - val_loss: 0.5085 - val_accuracy: 0.8611\n",
      "Epoch 492/500\n",
      "84/84 [==============================] - 0s 453us/step - loss: 0.4839 - accuracy: 0.8571 - val_loss: 0.5081 - val_accuracy: 0.8611\n",
      "Epoch 493/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.4837 - accuracy: 0.8571 - val_loss: 0.5078 - val_accuracy: 0.8611\n",
      "Epoch 494/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.4835 - accuracy: 0.8571 - val_loss: 0.5075 - val_accuracy: 0.8611\n",
      "Epoch 495/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.4832 - accuracy: 0.8571 - val_loss: 0.5073 - val_accuracy: 0.8611\n",
      "Epoch 496/500\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.8571 - val_loss: 0.5072 - val_accuracy: 0.8889\n",
      "Epoch 497/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.4828 - accuracy: 0.8452 - val_loss: 0.5067 - val_accuracy: 0.8611\n",
      "Epoch 498/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.4825 - accuracy: 0.8452 - val_loss: 0.5064 - val_accuracy: 0.8889\n",
      "Epoch 499/500\n",
      "84/84 [==============================] - 0s 453us/step - loss: 0.4822 - accuracy: 0.8452 - val_loss: 0.5060 - val_accuracy: 0.8611\n",
      "Epoch 500/500\n",
      "84/84 [==============================] - 0s 905us/step - loss: 0.4819 - accuracy: 0.8571 - val_loss: 0.5057 - val_accuracy: 0.8611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x20f5b86a6c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,epochs=500,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 1 Neuron\n",
      "[[ 3.4176016 -1.428774  -2.350525 ]]\n",
      "2. 2 Neuron:\n",
      "[[0.22552678 0.33404663 0.44042662]]\n",
      "3. Train\n",
      "[[0.8928013  0.09092157 0.01627707]]\n"
     ]
    }
   ],
   "source": [
    "print(\"1. 1 Neuron\")\n",
    "print(az)\n",
    "print(\"2. 2 Neuron:\")\n",
    "print(aza)\n",
    "print(\"3. Train\")\n",
    "print(model.predict(np.array([[5.1,5.3,1.4,0.2]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 167us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4888818025588989, 0.8583333492279053)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss, train_accuracy=model.evaluate(X_train, y_train)\n",
    "train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 367us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.48892590403556824, 0.8666666746139526)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss, train_accuracy=model.evaluate(X_test, y_test)\n",
    "train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOW TO:\n",
    "Using This Iris Framework (Data in MM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8928013  0.09092157 0.01627707]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(np.array([[5.1,5.3,1.4,0.2]])))#RANGE: SEPAL LENGHT, SEPAL WIDTH,PETAL LENGHT, PETAL WIDTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Vergleich mit ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "Xy=iris.data\n",
    "yy=iris.data\n",
    "Xy_sepal_lenght=Xy[:,0]\n",
    "Xy_sepal_width=Xy[:,1]\n",
    "Xy_petal_lenght=Xy[:,2]\n",
    "Xy_sepal_width=Xy[:,3]\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xy_train, Xy_test, yy_train, yy_test=train_test_split(X,y,test_size=0.4)\n",
    "#USING NEAREST NEIGHBORS\n",
    "from sklearn import neighbors\n",
    "clf=neighbors.KNeighborsClassifier(1)\n",
    "clf.fit(Xy_train,yy_train)\n",
    "print(clf.score(Xy_train,yy_train))\n",
    "print(clf.score(Xy_test,yy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vergleich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learning:\n",
      "Probability for zero in percent\n",
      "3.1\n",
      "Probability for one in percent\n",
      "40.9\n",
      "Probability for two in percent\n",
      "56.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Deep Learning:\")\n",
    "deplearn=model.predict(np.array([[6.3,2.7,5.5,1.5]]))\n",
    "print(\"Probability for zero in percent\")\n",
    "print(round(deplearn[0][0]*100,1))\n",
    "print(\"Probability for one in percent\")\n",
    "print(round(deplearn[0][1]*100,1))\n",
    "print(\"Probability for two in percent\")\n",
    "print(round(deplearn[0][2]*100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"ML:\")\n",
    "clf.predict([[6.3,2.7,5.5,1.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
