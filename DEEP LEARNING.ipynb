{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Verkehrszeichen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made by [Sharkbyteprojects](https://github.com/sharkbyteprojects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need\n",
    "- Keras\n",
    "- SKLEARN\n",
    "- numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "inputs=Input(shape=(4,))\n",
    "fc=Dense(3)(inputs)\n",
    "from keras.models import Model\n",
    "model=Model(input=inputs,output=fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zeige infos Ã¼ber Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and add new Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "             loss=\"categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])\n",
    "predictionss=Dense(8,activation=\"softmax\")(fc)\n",
    "predictions=Dense(3,activation=\"softmax\")(predictionss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test of Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "az=model.predict(np.array([[5.1,5.3,1.4,0.2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recompile and Retry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 15        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 74\n",
      "Trainable params: 74\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Model(input=inputs,output=predictions)\n",
    "model.compile(optimizer=\"adam\",\n",
    "             loss=\"categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "aza=model.predict(np.array([[5.1,5.3,1.4,0.2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris =datasets.load_iris()\n",
    "X=np.array(iris.data)\n",
    "y=np.array(iris.target)\n",
    "X.shape, y.shape\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y=to_categorical(y,3)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "complete prepare for train, start train:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84 samples, validate on 36 samples\n",
      "Epoch 1/500\n",
      "84/84 [==============================] - 3s 33ms/step - loss: 1.0822 - accuracy: 0.3452 - val_loss: 1.0931 - val_accuracy: 0.3056\n",
      "Epoch 2/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 1.0794 - accuracy: 0.3452 - val_loss: 1.0905 - val_accuracy: 0.3056\n",
      "Epoch 3/500\n",
      "84/84 [==============================] - 0s 452us/step - loss: 1.0764 - accuracy: 0.3452 - val_loss: 1.0879 - val_accuracy: 0.3056\n",
      "Epoch 4/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 1.0734 - accuracy: 0.3452 - val_loss: 1.0852 - val_accuracy: 0.3056\n",
      "Epoch 5/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 1.0704 - accuracy: 0.3452 - val_loss: 1.0825 - val_accuracy: 0.3056\n",
      "Epoch 6/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 1.0673 - accuracy: 0.3452 - val_loss: 1.0797 - val_accuracy: 0.3056\n",
      "Epoch 7/500\n",
      "84/84 [==============================] - 0s 584us/step - loss: 1.0640 - accuracy: 0.3452 - val_loss: 1.0767 - val_accuracy: 0.3056\n",
      "Epoch 8/500\n",
      "84/84 [==============================] - 0s 679us/step - loss: 1.0607 - accuracy: 0.3452 - val_loss: 1.0737 - val_accuracy: 0.3056\n",
      "Epoch 9/500\n",
      "84/84 [==============================] - 0s 583us/step - loss: 1.0572 - accuracy: 0.3452 - val_loss: 1.0706 - val_accuracy: 0.3056\n",
      "Epoch 10/500\n",
      "84/84 [==============================] - 0s 631us/step - loss: 1.0537 - accuracy: 0.3452 - val_loss: 1.0674 - val_accuracy: 0.3056\n",
      "Epoch 11/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 1.0502 - accuracy: 0.3452 - val_loss: 1.0640 - val_accuracy: 0.3056\n",
      "Epoch 12/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 1.0466 - accuracy: 0.3452 - val_loss: 1.0606 - val_accuracy: 0.3056\n",
      "Epoch 13/500\n",
      "84/84 [==============================] - 0s 679us/step - loss: 1.0426 - accuracy: 0.3452 - val_loss: 1.0571 - val_accuracy: 0.3056\n",
      "Epoch 14/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 1.0386 - accuracy: 0.3452 - val_loss: 1.0535 - val_accuracy: 0.3056\n",
      "Epoch 15/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 1.0346 - accuracy: 0.3452 - val_loss: 1.0498 - val_accuracy: 0.3056\n",
      "Epoch 16/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 1.0304 - accuracy: 0.3452 - val_loss: 1.0459 - val_accuracy: 0.3056\n",
      "Epoch 17/500\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 1.0260 - accuracy: 0.3929 - val_loss: 1.0419 - val_accuracy: 0.3889\n",
      "Epoch 18/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 1.0217 - accuracy: 0.4405 - val_loss: 1.0379 - val_accuracy: 0.4444\n",
      "Epoch 19/500\n",
      "84/84 [==============================] - 0s 667us/step - loss: 1.0171 - accuracy: 0.5000 - val_loss: 1.0338 - val_accuracy: 0.5556\n",
      "Epoch 20/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 1.0125 - accuracy: 0.5714 - val_loss: 1.0295 - val_accuracy: 0.5833\n",
      "Epoch 21/500\n",
      "84/84 [==============================] - 0s 583us/step - loss: 1.0079 - accuracy: 0.6071 - val_loss: 1.0252 - val_accuracy: 0.6111\n",
      "Epoch 22/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 1.0032 - accuracy: 0.6429 - val_loss: 1.0209 - val_accuracy: 0.6389\n",
      "Epoch 23/500\n",
      "84/84 [==============================] - 0s 750us/step - loss: 0.9984 - accuracy: 0.6667 - val_loss: 1.0165 - val_accuracy: 0.6389\n",
      "Epoch 24/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.9936 - accuracy: 0.6786 - val_loss: 1.0120 - val_accuracy: 0.6389\n",
      "Epoch 25/500\n",
      "84/84 [==============================] - 0s 512us/step - loss: 0.9891 - accuracy: 0.6786 - val_loss: 1.0075 - val_accuracy: 0.6389\n",
      "Epoch 26/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.9842 - accuracy: 0.6786 - val_loss: 1.0030 - val_accuracy: 0.6389\n",
      "Epoch 27/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.9792 - accuracy: 0.6786 - val_loss: 0.9985 - val_accuracy: 0.6389\n",
      "Epoch 28/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.9745 - accuracy: 0.6786 - val_loss: 0.9939 - val_accuracy: 0.6389\n",
      "Epoch 29/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.9697 - accuracy: 0.6786 - val_loss: 0.9893 - val_accuracy: 0.6389\n",
      "Epoch 30/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.9647 - accuracy: 0.6786 - val_loss: 0.9847 - val_accuracy: 0.6389\n",
      "Epoch 31/500\n",
      "84/84 [==============================] - 0s 607us/step - loss: 0.9601 - accuracy: 0.6786 - val_loss: 0.9801 - val_accuracy: 0.6389\n",
      "Epoch 32/500\n",
      "84/84 [==============================] - 0s 643us/step - loss: 0.9551 - accuracy: 0.6786 - val_loss: 0.9755 - val_accuracy: 0.6389\n",
      "Epoch 33/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.9502 - accuracy: 0.6786 - val_loss: 0.9709 - val_accuracy: 0.6389\n",
      "Epoch 34/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.9456 - accuracy: 0.6786 - val_loss: 0.9663 - val_accuracy: 0.6389\n",
      "Epoch 35/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.9407 - accuracy: 0.6786 - val_loss: 0.9618 - val_accuracy: 0.6389\n",
      "Epoch 36/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.9360 - accuracy: 0.6786 - val_loss: 0.9572 - val_accuracy: 0.6389\n",
      "Epoch 37/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.9312 - accuracy: 0.6786 - val_loss: 0.9527 - val_accuracy: 0.6389\n",
      "Epoch 38/500\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.9266 - accuracy: 0.6786 - val_loss: 0.9482 - val_accuracy: 0.6389\n",
      "Epoch 39/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.9220 - accuracy: 0.6786 - val_loss: 0.9438 - val_accuracy: 0.6389\n",
      "Epoch 40/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.9174 - accuracy: 0.6786 - val_loss: 0.9394 - val_accuracy: 0.6389\n",
      "Epoch 41/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.9129 - accuracy: 0.6786 - val_loss: 0.9350 - val_accuracy: 0.6389\n",
      "Epoch 42/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.9084 - accuracy: 0.6786 - val_loss: 0.9307 - val_accuracy: 0.6389\n",
      "Epoch 43/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.9041 - accuracy: 0.6786 - val_loss: 0.9265 - val_accuracy: 0.6389\n",
      "Epoch 44/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.8997 - accuracy: 0.6786 - val_loss: 0.9223 - val_accuracy: 0.6389\n",
      "Epoch 45/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.8955 - accuracy: 0.6786 - val_loss: 0.9181 - val_accuracy: 0.6389\n",
      "Epoch 46/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.8913 - accuracy: 0.6786 - val_loss: 0.9141 - val_accuracy: 0.6389\n",
      "Epoch 47/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.8871 - accuracy: 0.6786 - val_loss: 0.9101 - val_accuracy: 0.6389\n",
      "Epoch 48/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.8832 - accuracy: 0.6786 - val_loss: 0.9061 - val_accuracy: 0.6389\n",
      "Epoch 49/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.8791 - accuracy: 0.6786 - val_loss: 0.9022 - val_accuracy: 0.6389\n",
      "Epoch 50/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.8752 - accuracy: 0.6786 - val_loss: 0.8984 - val_accuracy: 0.6389\n",
      "Epoch 51/500\n",
      "84/84 [==============================] - 0s 953us/step - loss: 0.8714 - accuracy: 0.6786 - val_loss: 0.8946 - val_accuracy: 0.6389\n",
      "Epoch 52/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.8676 - accuracy: 0.6786 - val_loss: 0.8909 - val_accuracy: 0.6389\n",
      "Epoch 53/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.8639 - accuracy: 0.6786 - val_loss: 0.8873 - val_accuracy: 0.6389\n",
      "Epoch 54/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.8602 - accuracy: 0.6786 - val_loss: 0.8837 - val_accuracy: 0.6389\n",
      "Epoch 55/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.8566 - accuracy: 0.6786 - val_loss: 0.8802 - val_accuracy: 0.6389\n",
      "Epoch 56/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.8531 - accuracy: 0.6786 - val_loss: 0.8768 - val_accuracy: 0.6389\n",
      "Epoch 57/500\n",
      "84/84 [==============================] - 0s 595us/step - loss: 0.8497 - accuracy: 0.6786 - val_loss: 0.8734 - val_accuracy: 0.6389\n",
      "Epoch 58/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.8462 - accuracy: 0.6786 - val_loss: 0.8700 - val_accuracy: 0.6389\n",
      "Epoch 59/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.8429 - accuracy: 0.6786 - val_loss: 0.8667 - val_accuracy: 0.6389\n",
      "Epoch 60/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.8396 - accuracy: 0.6786 - val_loss: 0.8635 - val_accuracy: 0.6389\n",
      "Epoch 61/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.8363 - accuracy: 0.6786 - val_loss: 0.8603 - val_accuracy: 0.6389\n",
      "Epoch 62/500\n",
      "84/84 [==============================] - 0s 583us/step - loss: 0.8331 - accuracy: 0.6786 - val_loss: 0.8571 - val_accuracy: 0.6389\n",
      "Epoch 63/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.8300 - accuracy: 0.6786 - val_loss: 0.8540 - val_accuracy: 0.6389\n",
      "Epoch 64/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.8268 - accuracy: 0.6786 - val_loss: 0.8509 - val_accuracy: 0.6389\n",
      "Epoch 65/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.8238 - accuracy: 0.6786 - val_loss: 0.8479 - val_accuracy: 0.6389\n",
      "Epoch 66/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.8208 - accuracy: 0.6786 - val_loss: 0.8449 - val_accuracy: 0.6389\n",
      "Epoch 67/500\n",
      "84/84 [==============================] - 0s 321us/step - loss: 0.8178 - accuracy: 0.6786 - val_loss: 0.8419 - val_accuracy: 0.6389\n",
      "Epoch 68/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.8149 - accuracy: 0.6786 - val_loss: 0.8390 - val_accuracy: 0.6389\n",
      "Epoch 69/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.8120 - accuracy: 0.6786 - val_loss: 0.8361 - val_accuracy: 0.6389\n",
      "Epoch 70/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.8092 - accuracy: 0.6786 - val_loss: 0.8333 - val_accuracy: 0.6389\n",
      "Epoch 71/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.8063 - accuracy: 0.6786 - val_loss: 0.8305 - val_accuracy: 0.6389\n",
      "Epoch 72/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.8036 - accuracy: 0.6786 - val_loss: 0.8278 - val_accuracy: 0.6389\n",
      "Epoch 73/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.8008 - accuracy: 0.6786 - val_loss: 0.8251 - val_accuracy: 0.6389\n",
      "Epoch 74/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.7982 - accuracy: 0.6786 - val_loss: 0.8224 - val_accuracy: 0.6389\n",
      "Epoch 75/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.7955 - accuracy: 0.6786 - val_loss: 0.8198 - val_accuracy: 0.6389\n",
      "Epoch 76/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.7929 - accuracy: 0.6786 - val_loss: 0.8173 - val_accuracy: 0.6389\n",
      "Epoch 77/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.7904 - accuracy: 0.6786 - val_loss: 0.8147 - val_accuracy: 0.6667\n",
      "Epoch 78/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.7878 - accuracy: 0.6786 - val_loss: 0.8122 - val_accuracy: 0.6667\n",
      "Epoch 79/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.7853 - accuracy: 0.6786 - val_loss: 0.8098 - val_accuracy: 0.6667\n",
      "Epoch 80/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.7829 - accuracy: 0.6786 - val_loss: 0.8074 - val_accuracy: 0.6667\n",
      "Epoch 81/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.7805 - accuracy: 0.6786 - val_loss: 0.8050 - val_accuracy: 0.6389\n",
      "Epoch 82/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.7781 - accuracy: 0.6786 - val_loss: 0.8027 - val_accuracy: 0.6389\n",
      "Epoch 83/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.7758 - accuracy: 0.6786 - val_loss: 0.8004 - val_accuracy: 0.6389\n",
      "Epoch 84/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.7734 - accuracy: 0.6786 - val_loss: 0.7981 - val_accuracy: 0.6389\n",
      "Epoch 85/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.7712 - accuracy: 0.6786 - val_loss: 0.7959 - val_accuracy: 0.6667\n",
      "Epoch 86/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.7689 - accuracy: 0.6786 - val_loss: 0.7937 - val_accuracy: 0.6667\n",
      "Epoch 87/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.7667 - accuracy: 0.6786 - val_loss: 0.7915 - val_accuracy: 0.6667\n",
      "Epoch 88/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.7645 - accuracy: 0.6786 - val_loss: 0.7893 - val_accuracy: 0.6667\n",
      "Epoch 89/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.7624 - accuracy: 0.6786 - val_loss: 0.7872 - val_accuracy: 0.6667\n",
      "Epoch 90/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.7602 - accuracy: 0.6786 - val_loss: 0.7851 - val_accuracy: 0.6667\n",
      "Epoch 91/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.7582 - accuracy: 0.6786 - val_loss: 0.7830 - val_accuracy: 0.6389\n",
      "Epoch 92/500\n",
      "84/84 [==============================] - 0s 512us/step - loss: 0.7562 - accuracy: 0.6786 - val_loss: 0.7810 - val_accuracy: 0.6389\n",
      "Epoch 93/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.7541 - accuracy: 0.6786 - val_loss: 0.7790 - val_accuracy: 0.6389\n",
      "Epoch 94/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.7521 - accuracy: 0.6786 - val_loss: 0.7770 - val_accuracy: 0.6389\n",
      "Epoch 95/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.7502 - accuracy: 0.6786 - val_loss: 0.7751 - val_accuracy: 0.6389\n",
      "Epoch 96/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.7482 - accuracy: 0.6786 - val_loss: 0.7731 - val_accuracy: 0.6389\n",
      "Epoch 97/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.7463 - accuracy: 0.6786 - val_loss: 0.7712 - val_accuracy: 0.6389\n",
      "Epoch 98/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.7444 - accuracy: 0.6786 - val_loss: 0.7693 - val_accuracy: 0.6389\n",
      "Epoch 99/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.7425 - accuracy: 0.6786 - val_loss: 0.7675 - val_accuracy: 0.6389\n",
      "Epoch 100/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.7407 - accuracy: 0.6786 - val_loss: 0.7656 - val_accuracy: 0.6389\n",
      "Epoch 101/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.7389 - accuracy: 0.6786 - val_loss: 0.7638 - val_accuracy: 0.6389\n",
      "Epoch 102/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.7371 - accuracy: 0.6786 - val_loss: 0.7620 - val_accuracy: 0.6389\n",
      "Epoch 103/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.7261 - accuracy: 0.65 - 0s 429us/step - loss: 0.7353 - accuracy: 0.6786 - val_loss: 0.7603 - val_accuracy: 0.6389\n",
      "Epoch 104/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.7336 - accuracy: 0.6786 - val_loss: 0.7585 - val_accuracy: 0.6389\n",
      "Epoch 105/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.7318 - accuracy: 0.6786 - val_loss: 0.7568 - val_accuracy: 0.6389\n",
      "Epoch 106/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.7301 - accuracy: 0.6786 - val_loss: 0.7551 - val_accuracy: 0.6389\n",
      "Epoch 107/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.7285 - accuracy: 0.6786 - val_loss: 0.7534 - val_accuracy: 0.6389\n",
      "Epoch 108/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.7268 - accuracy: 0.6786 - val_loss: 0.7518 - val_accuracy: 0.6389\n",
      "Epoch 109/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.7252 - accuracy: 0.6786 - val_loss: 0.7502 - val_accuracy: 0.6389\n",
      "Epoch 110/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.7235 - accuracy: 0.6786 - val_loss: 0.7486 - val_accuracy: 0.6389\n",
      "Epoch 111/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.7220 - accuracy: 0.6786 - val_loss: 0.7470 - val_accuracy: 0.6389\n",
      "Epoch 112/500\n",
      "84/84 [==============================] - 0s 703us/step - loss: 0.7204 - accuracy: 0.6786 - val_loss: 0.7454 - val_accuracy: 0.6389\n",
      "Epoch 113/500\n",
      "84/84 [==============================] - 0s 619us/step - loss: 0.7188 - accuracy: 0.6786 - val_loss: 0.7439 - val_accuracy: 0.6389\n",
      "Epoch 114/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.7173 - accuracy: 0.6786 - val_loss: 0.7424 - val_accuracy: 0.6389\n",
      "Epoch 115/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.7077 - accuracy: 0.65 - 0s 322us/step - loss: 0.7157 - accuracy: 0.6786 - val_loss: 0.7409 - val_accuracy: 0.6389\n",
      "Epoch 116/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.7142 - accuracy: 0.6786 - val_loss: 0.7394 - val_accuracy: 0.6389\n",
      "Epoch 117/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.7127 - accuracy: 0.6786 - val_loss: 0.7379 - val_accuracy: 0.6389\n",
      "Epoch 118/500\n",
      "84/84 [==============================] - 0s 750us/step - loss: 0.7112 - accuracy: 0.6786 - val_loss: 0.7364 - val_accuracy: 0.6389\n",
      "Epoch 119/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.7098 - accuracy: 0.6786 - val_loss: 0.7350 - val_accuracy: 0.6389\n",
      "Epoch 120/500\n",
      "84/84 [==============================] - 0s 607us/step - loss: 0.7084 - accuracy: 0.6786 - val_loss: 0.7336 - val_accuracy: 0.6389\n",
      "Epoch 121/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.7069 - accuracy: 0.6786 - val_loss: 0.7322 - val_accuracy: 0.6389\n",
      "Epoch 122/500\n",
      "84/84 [==============================] - 0s 512us/step - loss: 0.7055 - accuracy: 0.6786 - val_loss: 0.7308 - val_accuracy: 0.6389\n",
      "Epoch 123/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.7041 - accuracy: 0.6786 - val_loss: 0.7294 - val_accuracy: 0.6389\n",
      "Epoch 124/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.7028 - accuracy: 0.6786 - val_loss: 0.7280 - val_accuracy: 0.6389\n",
      "Epoch 125/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.7014 - accuracy: 0.6786 - val_loss: 0.7267 - val_accuracy: 0.6389\n",
      "Epoch 126/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.7000 - accuracy: 0.6786 - val_loss: 0.7254 - val_accuracy: 0.6389\n",
      "Epoch 127/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.6987 - accuracy: 0.6786 - val_loss: 0.7240 - val_accuracy: 0.6389\n",
      "Epoch 128/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.6974 - accuracy: 0.6786 - val_loss: 0.7227 - val_accuracy: 0.6389\n",
      "Epoch 129/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.6961 - accuracy: 0.6786 - val_loss: 0.7214 - val_accuracy: 0.6389\n",
      "Epoch 130/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.6948 - accuracy: 0.6786 - val_loss: 0.7202 - val_accuracy: 0.6389\n",
      "Epoch 131/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.6935 - accuracy: 0.6786 - val_loss: 0.7189 - val_accuracy: 0.6389\n",
      "Epoch 132/500\n",
      "84/84 [==============================] - 0s 583us/step - loss: 0.6922 - accuracy: 0.6786 - val_loss: 0.7176 - val_accuracy: 0.6389\n",
      "Epoch 133/500\n",
      "84/84 [==============================] - 0s 583us/step - loss: 0.6910 - accuracy: 0.6786 - val_loss: 0.7164 - val_accuracy: 0.6389\n",
      "Epoch 134/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.6897 - accuracy: 0.6786 - val_loss: 0.7151 - val_accuracy: 0.6389\n",
      "Epoch 135/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6885 - accuracy: 0.6786 - val_loss: 0.7139 - val_accuracy: 0.6389\n",
      "Epoch 136/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.6872 - accuracy: 0.6786 - val_loss: 0.7127 - val_accuracy: 0.6389\n",
      "Epoch 137/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.6861 - accuracy: 0.6786 - val_loss: 0.7114 - val_accuracy: 0.6389\n",
      "Epoch 138/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.6848 - accuracy: 0.6786 - val_loss: 0.7102 - val_accuracy: 0.6389\n",
      "Epoch 139/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.6836 - accuracy: 0.6786 - val_loss: 0.7090 - val_accuracy: 0.6389\n",
      "Epoch 140/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.6825 - accuracy: 0.6786 - val_loss: 0.7078 - val_accuracy: 0.6389\n",
      "Epoch 141/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.6813 - accuracy: 0.6786 - val_loss: 0.7067 - val_accuracy: 0.6389\n",
      "Epoch 142/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.6802 - accuracy: 0.6786 - val_loss: 0.7055 - val_accuracy: 0.6389\n",
      "Epoch 143/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.6790 - accuracy: 0.6786 - val_loss: 0.7043 - val_accuracy: 0.6389\n",
      "Epoch 144/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.6779 - accuracy: 0.6786 - val_loss: 0.7032 - val_accuracy: 0.6389\n",
      "Epoch 145/500\n",
      "84/84 [==============================] - 0s 583us/step - loss: 0.6768 - accuracy: 0.6786 - val_loss: 0.7021 - val_accuracy: 0.6389\n",
      "Epoch 146/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.6756 - accuracy: 0.6786 - val_loss: 0.7010 - val_accuracy: 0.6389\n",
      "Epoch 147/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.6746 - accuracy: 0.6786 - val_loss: 0.6999 - val_accuracy: 0.6389\n",
      "Epoch 148/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.6735 - accuracy: 0.6786 - val_loss: 0.6988 - val_accuracy: 0.6389\n",
      "Epoch 149/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.6724 - accuracy: 0.6786 - val_loss: 0.6978 - val_accuracy: 0.6389\n",
      "Epoch 150/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.6713 - accuracy: 0.6786 - val_loss: 0.6967 - val_accuracy: 0.6389\n",
      "Epoch 151/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.6702 - accuracy: 0.6786 - val_loss: 0.6956 - val_accuracy: 0.6389\n",
      "Epoch 152/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6692 - accuracy: 0.6786 - val_loss: 0.6946 - val_accuracy: 0.6389\n",
      "Epoch 153/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 0.6682 - accuracy: 0.6786 - val_loss: 0.6936 - val_accuracy: 0.6389\n",
      "Epoch 154/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.6671 - accuracy: 0.6786 - val_loss: 0.6926 - val_accuracy: 0.6389\n",
      "Epoch 155/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.6661 - accuracy: 0.6786 - val_loss: 0.6916 - val_accuracy: 0.6389\n",
      "Epoch 156/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6651 - accuracy: 0.6786 - val_loss: 0.6906 - val_accuracy: 0.6389\n",
      "Epoch 157/500\n",
      "84/84 [==============================] - 0s 643us/step - loss: 0.6641 - accuracy: 0.6786 - val_loss: 0.6896 - val_accuracy: 0.6389\n",
      "Epoch 158/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 0.6631 - accuracy: 0.6786 - val_loss: 0.6886 - val_accuracy: 0.6389\n",
      "Epoch 159/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.6621 - accuracy: 0.6786 - val_loss: 0.6877 - val_accuracy: 0.6389\n",
      "Epoch 160/500\n",
      "84/84 [==============================] - 0s 595us/step - loss: 0.6611 - accuracy: 0.6786 - val_loss: 0.6867 - val_accuracy: 0.6389\n",
      "Epoch 161/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.6602 - accuracy: 0.6786 - val_loss: 0.6857 - val_accuracy: 0.6389\n",
      "Epoch 162/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.6591 - accuracy: 0.6786 - val_loss: 0.6848 - val_accuracy: 0.6389\n",
      "Epoch 163/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.6582 - accuracy: 0.6786 - val_loss: 0.6838 - val_accuracy: 0.6389\n",
      "Epoch 164/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.6572 - accuracy: 0.6786 - val_loss: 0.6829 - val_accuracy: 0.6389\n",
      "Epoch 165/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.6563 - accuracy: 0.6786 - val_loss: 0.6819 - val_accuracy: 0.6389\n",
      "Epoch 166/500\n",
      "84/84 [==============================] - 0s 607us/step - loss: 0.6554 - accuracy: 0.6786 - val_loss: 0.6810 - val_accuracy: 0.6389\n",
      "Epoch 167/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 0.6544 - accuracy: 0.6786 - val_loss: 0.6801 - val_accuracy: 0.6389\n",
      "Epoch 168/500\n",
      "84/84 [==============================] - 0s 536us/step - loss: 0.6535 - accuracy: 0.6786 - val_loss: 0.6792 - val_accuracy: 0.6389\n",
      "Epoch 169/500\n",
      "84/84 [==============================] - 0s 452us/step - loss: 0.6526 - accuracy: 0.6786 - val_loss: 0.6783 - val_accuracy: 0.6389\n",
      "Epoch 170/500\n",
      "84/84 [==============================] - 0s 643us/step - loss: 0.6517 - accuracy: 0.6786 - val_loss: 0.6774 - val_accuracy: 0.6389\n",
      "Epoch 171/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6508 - accuracy: 0.6786 - val_loss: 0.6765 - val_accuracy: 0.6389\n",
      "Epoch 172/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.6499 - accuracy: 0.6786 - val_loss: 0.6757 - val_accuracy: 0.6389\n",
      "Epoch 173/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.6490 - accuracy: 0.6786 - val_loss: 0.6748 - val_accuracy: 0.6389\n",
      "Epoch 174/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.6481 - accuracy: 0.6786 - val_loss: 0.6739 - val_accuracy: 0.6389\n",
      "Epoch 175/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.6473 - accuracy: 0.6786 - val_loss: 0.6731 - val_accuracy: 0.6389\n",
      "Epoch 176/500\n",
      "84/84 [==============================] - 0s 453us/step - loss: 0.6464 - accuracy: 0.6786 - val_loss: 0.6723 - val_accuracy: 0.6389\n",
      "Epoch 177/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.6456 - accuracy: 0.6786 - val_loss: 0.6714 - val_accuracy: 0.6389\n",
      "Epoch 178/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.6447 - accuracy: 0.6786 - val_loss: 0.6706 - val_accuracy: 0.6389\n",
      "Epoch 179/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.6439 - accuracy: 0.6786 - val_loss: 0.6698 - val_accuracy: 0.6389\n",
      "Epoch 180/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.6430 - accuracy: 0.6786 - val_loss: 0.6689 - val_accuracy: 0.6389\n",
      "Epoch 181/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.6422 - accuracy: 0.6786 - val_loss: 0.6681 - val_accuracy: 0.6389\n",
      "Epoch 182/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.6414 - accuracy: 0.6786 - val_loss: 0.6673 - val_accuracy: 0.6389\n",
      "Epoch 183/500\n",
      "84/84 [==============================] - 0s 607us/step - loss: 0.6406 - accuracy: 0.6786 - val_loss: 0.6665 - val_accuracy: 0.6389\n",
      "Epoch 184/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.6398 - accuracy: 0.6786 - val_loss: 0.6657 - val_accuracy: 0.6389\n",
      "Epoch 185/500\n",
      "84/84 [==============================] - 0s 452us/step - loss: 0.6390 - accuracy: 0.6786 - val_loss: 0.6649 - val_accuracy: 0.6389\n",
      "Epoch 186/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.6382 - accuracy: 0.6786 - val_loss: 0.6641 - val_accuracy: 0.6389\n",
      "Epoch 187/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.6374 - accuracy: 0.6786 - val_loss: 0.6634 - val_accuracy: 0.6389\n",
      "Epoch 188/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.6366 - accuracy: 0.6786 - val_loss: 0.6626 - val_accuracy: 0.6389\n",
      "Epoch 189/500\n",
      "84/84 [==============================] - 0s 452us/step - loss: 0.6358 - accuracy: 0.6786 - val_loss: 0.6618 - val_accuracy: 0.6389\n",
      "Epoch 190/500\n",
      "84/84 [==============================] - 0s 583us/step - loss: 0.6350 - accuracy: 0.6786 - val_loss: 0.6610 - val_accuracy: 0.6389\n",
      "Epoch 191/500\n",
      "84/84 [==============================] - 0s 536us/step - loss: 0.6342 - accuracy: 0.6786 - val_loss: 0.6603 - val_accuracy: 0.6389\n",
      "Epoch 192/500\n",
      "84/84 [==============================] - 0s 464us/step - loss: 0.6335 - accuracy: 0.6786 - val_loss: 0.6595 - val_accuracy: 0.6389\n",
      "Epoch 193/500\n",
      "84/84 [==============================] - 0s 595us/step - loss: 0.6327 - accuracy: 0.6786 - val_loss: 0.6587 - val_accuracy: 0.6389\n",
      "Epoch 194/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.6320 - accuracy: 0.6786 - val_loss: 0.6580 - val_accuracy: 0.6389\n",
      "Epoch 195/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.6312 - accuracy: 0.6786 - val_loss: 0.6572 - val_accuracy: 0.6389\n",
      "Epoch 196/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.6304 - accuracy: 0.6786 - val_loss: 0.6565 - val_accuracy: 0.6389\n",
      "Epoch 197/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6297 - accuracy: 0.6786 - val_loss: 0.6558 - val_accuracy: 0.6389\n",
      "Epoch 198/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.6290 - accuracy: 0.6786 - val_loss: 0.6550 - val_accuracy: 0.6389\n",
      "Epoch 199/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6282 - accuracy: 0.6786 - val_loss: 0.6543 - val_accuracy: 0.6389\n",
      "Epoch 200/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6275 - accuracy: 0.6786 - val_loss: 0.6536 - val_accuracy: 0.6389\n",
      "Epoch 201/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.6268 - accuracy: 0.6786 - val_loss: 0.6528 - val_accuracy: 0.6389\n",
      "Epoch 202/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.6260 - accuracy: 0.6786 - val_loss: 0.6521 - val_accuracy: 0.6389\n",
      "Epoch 203/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.6253 - accuracy: 0.6786 - val_loss: 0.6514 - val_accuracy: 0.6389\n",
      "Epoch 204/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6246 - accuracy: 0.6786 - val_loss: 0.6506 - val_accuracy: 0.6389\n",
      "Epoch 205/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.6239 - accuracy: 0.6786 - val_loss: 0.6499 - val_accuracy: 0.6389\n",
      "Epoch 206/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.6232 - accuracy: 0.6786 - val_loss: 0.6492 - val_accuracy: 0.6389\n",
      "Epoch 207/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6225 - accuracy: 0.6786 - val_loss: 0.6485 - val_accuracy: 0.6389\n",
      "Epoch 208/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.6218 - accuracy: 0.6786 - val_loss: 0.6479 - val_accuracy: 0.6389\n",
      "Epoch 209/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.6212 - accuracy: 0.6786 - val_loss: 0.6471 - val_accuracy: 0.6389\n",
      "Epoch 210/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.6204 - accuracy: 0.6786 - val_loss: 0.6465 - val_accuracy: 0.6389\n",
      "Epoch 211/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.6198 - accuracy: 0.6786 - val_loss: 0.6458 - val_accuracy: 0.6389\n",
      "Epoch 212/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.6191 - accuracy: 0.6786 - val_loss: 0.6451 - val_accuracy: 0.6389\n",
      "Epoch 213/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.6184 - accuracy: 0.6786 - val_loss: 0.6444 - val_accuracy: 0.6389\n",
      "Epoch 214/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.6178 - accuracy: 0.6786 - val_loss: 0.6438 - val_accuracy: 0.6389\n",
      "Epoch 215/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.6171 - accuracy: 0.6786 - val_loss: 0.6432 - val_accuracy: 0.6389\n",
      "Epoch 216/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 0.6164 - accuracy: 0.6786 - val_loss: 0.6425 - val_accuracy: 0.6389\n",
      "Epoch 217/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 0.6158 - accuracy: 0.6786 - val_loss: 0.6419 - val_accuracy: 0.6389\n",
      "Epoch 218/500\n",
      "84/84 [==============================] - 0s 453us/step - loss: 0.6151 - accuracy: 0.6786 - val_loss: 0.6412 - val_accuracy: 0.6389\n",
      "Epoch 219/500\n",
      "84/84 [==============================] - 0s 643us/step - loss: 0.6145 - accuracy: 0.6786 - val_loss: 0.6406 - val_accuracy: 0.6389\n",
      "Epoch 220/500\n",
      "84/84 [==============================] - 0s 560us/step - loss: 0.6138 - accuracy: 0.6786 - val_loss: 0.6399 - val_accuracy: 0.6389\n",
      "Epoch 221/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 0.6132 - accuracy: 0.6786 - val_loss: 0.6393 - val_accuracy: 0.6389\n",
      "Epoch 222/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.6125 - accuracy: 0.6786 - val_loss: 0.6387 - val_accuracy: 0.6389\n",
      "Epoch 223/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.6119 - accuracy: 0.6786 - val_loss: 0.6381 - val_accuracy: 0.6389\n",
      "Epoch 224/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.6113 - accuracy: 0.6786 - val_loss: 0.6374 - val_accuracy: 0.6389\n",
      "Epoch 225/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.6107 - accuracy: 0.6786 - val_loss: 0.6368 - val_accuracy: 0.6389\n",
      "Epoch 226/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6101 - accuracy: 0.6786 - val_loss: 0.6361 - val_accuracy: 0.6389\n",
      "Epoch 227/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.6094 - accuracy: 0.6786 - val_loss: 0.6355 - val_accuracy: 0.6389\n",
      "Epoch 228/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.6088 - accuracy: 0.6786 - val_loss: 0.6350 - val_accuracy: 0.6389\n",
      "Epoch 229/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.6082 - accuracy: 0.6786 - val_loss: 0.6344 - val_accuracy: 0.6389\n",
      "Epoch 230/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.6076 - accuracy: 0.6786 - val_loss: 0.6338 - val_accuracy: 0.6389\n",
      "Epoch 231/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.6070 - accuracy: 0.6786 - val_loss: 0.6332 - val_accuracy: 0.6389\n",
      "Epoch 232/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.6064 - accuracy: 0.6786 - val_loss: 0.6326 - val_accuracy: 0.6389\n",
      "Epoch 233/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.6058 - accuracy: 0.6786 - val_loss: 0.6320 - val_accuracy: 0.6389\n",
      "Epoch 234/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.6798 - accuracy: 0.46 - 0s 393us/step - loss: 0.6053 - accuracy: 0.6786 - val_loss: 0.6314 - val_accuracy: 0.6389\n",
      "Epoch 235/500\n",
      "84/84 [==============================] - 0s 595us/step - loss: 0.6046 - accuracy: 0.6786 - val_loss: 0.6308 - val_accuracy: 0.6389\n",
      "Epoch 236/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.6041 - accuracy: 0.6786 - val_loss: 0.6302 - val_accuracy: 0.6389\n",
      "Epoch 237/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.6035 - accuracy: 0.6786 - val_loss: 0.6297 - val_accuracy: 0.6389\n",
      "Epoch 238/500\n",
      "84/84 [==============================] - 0s 536us/step - loss: 0.6029 - accuracy: 0.6786 - val_loss: 0.6291 - val_accuracy: 0.6389\n",
      "Epoch 239/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.6023 - accuracy: 0.6786 - val_loss: 0.6285 - val_accuracy: 0.6389\n",
      "Epoch 240/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6018 - accuracy: 0.6786 - val_loss: 0.6279 - val_accuracy: 0.6389\n",
      "Epoch 241/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.6012 - accuracy: 0.6786 - val_loss: 0.6274 - val_accuracy: 0.6389\n",
      "Epoch 242/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.6007 - accuracy: 0.6786 - val_loss: 0.6268 - val_accuracy: 0.6389\n",
      "Epoch 243/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.6001 - accuracy: 0.6786 - val_loss: 0.6262 - val_accuracy: 0.6389\n",
      "Epoch 244/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5995 - accuracy: 0.6786 - val_loss: 0.6257 - val_accuracy: 0.6389\n",
      "Epoch 245/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5990 - accuracy: 0.6786 - val_loss: 0.6251 - val_accuracy: 0.6389\n",
      "Epoch 246/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.5985 - accuracy: 0.6786 - val_loss: 0.6245 - val_accuracy: 0.6389\n",
      "Epoch 247/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5979 - accuracy: 0.6786 - val_loss: 0.6239 - val_accuracy: 0.6389\n",
      "Epoch 248/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5973 - accuracy: 0.6786 - val_loss: 0.6234 - val_accuracy: 0.6389\n",
      "Epoch 249/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5968 - accuracy: 0.6786 - val_loss: 0.6228 - val_accuracy: 0.6667\n",
      "Epoch 250/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 0.5963 - accuracy: 0.6786 - val_loss: 0.6223 - val_accuracy: 0.6667\n",
      "Epoch 251/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5957 - accuracy: 0.6786 - val_loss: 0.6217 - val_accuracy: 0.6667\n",
      "Epoch 252/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5952 - accuracy: 0.6786 - val_loss: 0.6212 - val_accuracy: 0.6667\n",
      "Epoch 253/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5947 - accuracy: 0.6786 - val_loss: 0.6207 - val_accuracy: 0.6667\n",
      "Epoch 254/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5942 - accuracy: 0.6786 - val_loss: 0.6201 - val_accuracy: 0.6667\n",
      "Epoch 255/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5937 - accuracy: 0.6786 - val_loss: 0.6196 - val_accuracy: 0.6667\n",
      "Epoch 256/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.5931 - accuracy: 0.6786 - val_loss: 0.6191 - val_accuracy: 0.6667\n",
      "Epoch 257/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5926 - accuracy: 0.6786 - val_loss: 0.6186 - val_accuracy: 0.6667\n",
      "Epoch 258/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5921 - accuracy: 0.6786 - val_loss: 0.6181 - val_accuracy: 0.6667\n",
      "Epoch 259/500\n",
      "84/84 [==============================] - 0s 321us/step - loss: 0.5916 - accuracy: 0.6786 - val_loss: 0.6176 - val_accuracy: 0.6667\n",
      "Epoch 260/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5911 - accuracy: 0.6786 - val_loss: 0.6171 - val_accuracy: 0.6667\n",
      "Epoch 261/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5906 - accuracy: 0.6786 - val_loss: 0.6166 - val_accuracy: 0.6667\n",
      "Epoch 262/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.5901 - accuracy: 0.6786 - val_loss: 0.6161 - val_accuracy: 0.6667\n",
      "Epoch 263/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5896 - accuracy: 0.6786 - val_loss: 0.6156 - val_accuracy: 0.6667\n",
      "Epoch 264/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.5891 - accuracy: 0.6786 - val_loss: 0.6151 - val_accuracy: 0.6667\n",
      "Epoch 265/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5886 - accuracy: 0.6786 - val_loss: 0.6146 - val_accuracy: 0.6667\n",
      "Epoch 266/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.5882 - accuracy: 0.6786 - val_loss: 0.6141 - val_accuracy: 0.6667\n",
      "Epoch 267/500\n",
      "84/84 [==============================] - 0s 512us/step - loss: 0.5877 - accuracy: 0.6786 - val_loss: 0.6137 - val_accuracy: 0.6667\n",
      "Epoch 268/500\n",
      "84/84 [==============================] - 0s 321us/step - loss: 0.5872 - accuracy: 0.6786 - val_loss: 0.6131 - val_accuracy: 0.6667\n",
      "Epoch 269/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.5867 - accuracy: 0.6786 - val_loss: 0.6127 - val_accuracy: 0.6667\n",
      "Epoch 270/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5862 - accuracy: 0.6786 - val_loss: 0.6122 - val_accuracy: 0.6667\n",
      "Epoch 271/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.5857 - accuracy: 0.6786 - val_loss: 0.6117 - val_accuracy: 0.6667\n",
      "Epoch 272/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.5853 - accuracy: 0.6786 - val_loss: 0.6112 - val_accuracy: 0.6667\n",
      "Epoch 273/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.5848 - accuracy: 0.6786 - val_loss: 0.6107 - val_accuracy: 0.6667\n",
      "Epoch 274/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.5844 - accuracy: 0.6786 - val_loss: 0.6103 - val_accuracy: 0.6667\n",
      "Epoch 275/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5839 - accuracy: 0.6786 - val_loss: 0.6098 - val_accuracy: 0.6667\n",
      "Epoch 276/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.5834 - accuracy: 0.6786 - val_loss: 0.6094 - val_accuracy: 0.6667\n",
      "Epoch 277/500\n",
      "84/84 [==============================] - 0s 536us/step - loss: 0.5830 - accuracy: 0.6786 - val_loss: 0.6089 - val_accuracy: 0.6667\n",
      "Epoch 278/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.5826 - accuracy: 0.6786 - val_loss: 0.6084 - val_accuracy: 0.6667\n",
      "Epoch 279/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5821 - accuracy: 0.6786 - val_loss: 0.6080 - val_accuracy: 0.6667\n",
      "Epoch 280/500\n",
      "84/84 [==============================] - 0s 905us/step - loss: 0.5816 - accuracy: 0.6786 - val_loss: 0.6075 - val_accuracy: 0.6667\n",
      "Epoch 281/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5812 - accuracy: 0.6786 - val_loss: 0.6071 - val_accuracy: 0.6667\n",
      "Epoch 282/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.5807 - accuracy: 0.6786 - val_loss: 0.6067 - val_accuracy: 0.6667\n",
      "Epoch 283/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5803 - accuracy: 0.6786 - val_loss: 0.6062 - val_accuracy: 0.6667\n",
      "Epoch 284/500\n",
      "84/84 [==============================] - 0s 453us/step - loss: 0.5798 - accuracy: 0.6786 - val_loss: 0.6058 - val_accuracy: 0.6667\n",
      "Epoch 285/500\n",
      "84/84 [==============================] - 0s 631us/step - loss: 0.5794 - accuracy: 0.6786 - val_loss: 0.6053 - val_accuracy: 0.6667\n",
      "Epoch 286/500\n",
      "84/84 [==============================] - 0s 560us/step - loss: 0.5789 - accuracy: 0.6786 - val_loss: 0.6049 - val_accuracy: 0.6667\n",
      "Epoch 287/500\n",
      "84/84 [==============================] - 0s 726us/step - loss: 0.5785 - accuracy: 0.6786 - val_loss: 0.6044 - val_accuracy: 0.6667\n",
      "Epoch 288/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5781 - accuracy: 0.6786 - val_loss: 0.6040 - val_accuracy: 0.6667\n",
      "Epoch 289/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5777 - accuracy: 0.6786 - val_loss: 0.6036 - val_accuracy: 0.6667\n",
      "Epoch 290/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.5773 - accuracy: 0.6786 - val_loss: 0.6031 - val_accuracy: 0.6667\n",
      "Epoch 291/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5768 - accuracy: 0.6786 - val_loss: 0.6027 - val_accuracy: 0.6667\n",
      "Epoch 292/500\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.6786 - val_loss: 0.6023 - val_accuracy: 0.6667\n",
      "Epoch 293/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.5760 - accuracy: 0.6786 - val_loss: 0.6018 - val_accuracy: 0.6667\n",
      "Epoch 294/500\n",
      "84/84 [==============================] - 0s 846us/step - loss: 0.5756 - accuracy: 0.6786 - val_loss: 0.6014 - val_accuracy: 0.6667\n",
      "Epoch 295/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.5752 - accuracy: 0.6786 - val_loss: 0.6010 - val_accuracy: 0.6667\n",
      "Epoch 296/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5747 - accuracy: 0.6786 - val_loss: 0.6006 - val_accuracy: 0.6667\n",
      "Epoch 297/500\n",
      "84/84 [==============================] - 0s 679us/step - loss: 0.5743 - accuracy: 0.6786 - val_loss: 0.6002 - val_accuracy: 0.6667\n",
      "Epoch 298/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.5740 - accuracy: 0.6786 - val_loss: 0.5998 - val_accuracy: 0.6667\n",
      "Epoch 299/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5735 - accuracy: 0.6786 - val_loss: 0.5993 - val_accuracy: 0.6667\n",
      "Epoch 300/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5731 - accuracy: 0.6786 - val_loss: 0.5990 - val_accuracy: 0.6667\n",
      "Epoch 301/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.5728 - accuracy: 0.6786 - val_loss: 0.5986 - val_accuracy: 0.6667\n",
      "Epoch 302/500\n",
      "84/84 [==============================] - 0s 452us/step - loss: 0.5724 - accuracy: 0.6786 - val_loss: 0.5982 - val_accuracy: 0.6667\n",
      "Epoch 303/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.5719 - accuracy: 0.6786 - val_loss: 0.5978 - val_accuracy: 0.6667\n",
      "Epoch 304/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.5716 - accuracy: 0.6786 - val_loss: 0.5974 - val_accuracy: 0.6667\n",
      "Epoch 305/500\n",
      "84/84 [==============================] - 0s 464us/step - loss: 0.5711 - accuracy: 0.6786 - val_loss: 0.5970 - val_accuracy: 0.6667\n",
      "Epoch 306/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.5708 - accuracy: 0.6786 - val_loss: 0.5966 - val_accuracy: 0.6667\n",
      "Epoch 307/500\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5704 - accuracy: 0.6786 - val_loss: 0.5962 - val_accuracy: 0.6667\n",
      "Epoch 308/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.5321 - accuracy: 0.71 - 0s 381us/step - loss: 0.5700 - accuracy: 0.6786 - val_loss: 0.5958 - val_accuracy: 0.6667\n",
      "Epoch 309/500\n",
      "84/84 [==============================] - 0s 691us/step - loss: 0.5696 - accuracy: 0.6786 - val_loss: 0.5954 - val_accuracy: 0.6667\n",
      "Epoch 310/500\n",
      "84/84 [==============================] - 0s 631us/step - loss: 0.5692 - accuracy: 0.6786 - val_loss: 0.5951 - val_accuracy: 0.6667\n",
      "Epoch 311/500\n",
      "84/84 [==============================] - 0s 607us/step - loss: 0.5689 - accuracy: 0.6786 - val_loss: 0.5947 - val_accuracy: 0.6667\n",
      "Epoch 312/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5684 - accuracy: 0.6786 - val_loss: 0.5944 - val_accuracy: 0.6667\n",
      "Epoch 313/500\n",
      "84/84 [==============================] - 0s 464us/step - loss: 0.5681 - accuracy: 0.6786 - val_loss: 0.5940 - val_accuracy: 0.6667\n",
      "Epoch 314/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5677 - accuracy: 0.6786 - val_loss: 0.5936 - val_accuracy: 0.6667\n",
      "Epoch 315/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5673 - accuracy: 0.6786 - val_loss: 0.5933 - val_accuracy: 0.6667\n",
      "Epoch 316/500\n",
      "84/84 [==============================] - 0s 560us/step - loss: 0.5669 - accuracy: 0.6786 - val_loss: 0.5929 - val_accuracy: 0.6667\n",
      "Epoch 317/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.5665 - accuracy: 0.6786 - val_loss: 0.5925 - val_accuracy: 0.6667\n",
      "Epoch 318/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5662 - accuracy: 0.6786 - val_loss: 0.5922 - val_accuracy: 0.6667\n",
      "Epoch 319/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.5658 - accuracy: 0.6786 - val_loss: 0.5919 - val_accuracy: 0.6667\n",
      "Epoch 320/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5654 - accuracy: 0.6786 - val_loss: 0.5915 - val_accuracy: 0.6667\n",
      "Epoch 321/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5651 - accuracy: 0.6786 - val_loss: 0.5912 - val_accuracy: 0.6667\n",
      "Epoch 322/500\n",
      "84/84 [==============================] - 0s 584us/step - loss: 0.5647 - accuracy: 0.6786 - val_loss: 0.5908 - val_accuracy: 0.6667\n",
      "Epoch 323/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5643 - accuracy: 0.6786 - val_loss: 0.5905 - val_accuracy: 0.6667\n",
      "Epoch 324/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5640 - accuracy: 0.6786 - val_loss: 0.5902 - val_accuracy: 0.6667\n",
      "Epoch 325/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5636 - accuracy: 0.6786 - val_loss: 0.5898 - val_accuracy: 0.6667\n",
      "Epoch 326/500\n",
      "84/84 [==============================] - 0s 560us/step - loss: 0.5633 - accuracy: 0.6786 - val_loss: 0.5895 - val_accuracy: 0.6667\n",
      "Epoch 327/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5629 - accuracy: 0.6786 - val_loss: 0.5891 - val_accuracy: 0.6667\n",
      "Epoch 328/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.5626 - accuracy: 0.6786 - val_loss: 0.5888 - val_accuracy: 0.6667\n",
      "Epoch 329/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.5622 - accuracy: 0.6786 - val_loss: 0.5885 - val_accuracy: 0.6667\n",
      "Epoch 330/500\n",
      "84/84 [==============================] - 0s 595us/step - loss: 0.5619 - accuracy: 0.6786 - val_loss: 0.5882 - val_accuracy: 0.6667\n",
      "Epoch 331/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.5615 - accuracy: 0.6786 - val_loss: 0.5878 - val_accuracy: 0.6667\n",
      "Epoch 332/500\n",
      "84/84 [==============================] - 0s 726us/step - loss: 0.5612 - accuracy: 0.6786 - val_loss: 0.5875 - val_accuracy: 0.6667\n",
      "Epoch 333/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.5608 - accuracy: 0.6786 - val_loss: 0.5872 - val_accuracy: 0.6667\n",
      "Epoch 334/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.5605 - accuracy: 0.6786 - val_loss: 0.5869 - val_accuracy: 0.6667\n",
      "Epoch 335/500\n",
      "84/84 [==============================] - 0s 583us/step - loss: 0.5601 - accuracy: 0.6786 - val_loss: 0.5865 - val_accuracy: 0.6667\n",
      "Epoch 336/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.5598 - accuracy: 0.6786 - val_loss: 0.5862 - val_accuracy: 0.6667\n",
      "Epoch 337/500\n",
      "84/84 [==============================] - 0s 607us/step - loss: 0.5595 - accuracy: 0.6786 - val_loss: 0.5859 - val_accuracy: 0.6667\n",
      "Epoch 338/500\n",
      "84/84 [==============================] - 0s 667us/step - loss: 0.5591 - accuracy: 0.6786 - val_loss: 0.5856 - val_accuracy: 0.6667\n",
      "Epoch 339/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.5588 - accuracy: 0.6786 - val_loss: 0.5853 - val_accuracy: 0.6667\n",
      "Epoch 340/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.5606 - accuracy: 0.65 - 0s 548us/step - loss: 0.5585 - accuracy: 0.6786 - val_loss: 0.5849 - val_accuracy: 0.6667\n",
      "Epoch 341/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.5581 - accuracy: 0.6786 - val_loss: 0.5846 - val_accuracy: 0.6667\n",
      "Epoch 342/500\n",
      "84/84 [==============================] - 0s 536us/step - loss: 0.5578 - accuracy: 0.6786 - val_loss: 0.5843 - val_accuracy: 0.6667\n",
      "Epoch 343/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.5575 - accuracy: 0.6786 - val_loss: 0.5840 - val_accuracy: 0.6389\n",
      "Epoch 344/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.5571 - accuracy: 0.6786 - val_loss: 0.5837 - val_accuracy: 0.6389\n",
      "Epoch 345/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5568 - accuracy: 0.6786 - val_loss: 0.5834 - val_accuracy: 0.6389\n",
      "Epoch 346/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5565 - accuracy: 0.6786 - val_loss: 0.5831 - val_accuracy: 0.6389\n",
      "Epoch 347/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5562 - accuracy: 0.6786 - val_loss: 0.5828 - val_accuracy: 0.6389\n",
      "Epoch 348/500\n",
      "84/84 [==============================] - 0s 584us/step - loss: 0.5559 - accuracy: 0.6786 - val_loss: 0.5825 - val_accuracy: 0.6389\n",
      "Epoch 349/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5555 - accuracy: 0.6786 - val_loss: 0.5822 - val_accuracy: 0.6389\n",
      "Epoch 350/500\n",
      "84/84 [==============================] - 0s 774us/step - loss: 0.5553 - accuracy: 0.6786 - val_loss: 0.5820 - val_accuracy: 0.6389\n",
      "Epoch 351/500\n",
      "84/84 [==============================] - 0s 607us/step - loss: 0.5549 - accuracy: 0.6786 - val_loss: 0.5817 - val_accuracy: 0.6389\n",
      "Epoch 352/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.5546 - accuracy: 0.6786 - val_loss: 0.5814 - val_accuracy: 0.6389\n",
      "Epoch 353/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.5543 - accuracy: 0.6786 - val_loss: 0.5811 - val_accuracy: 0.6389\n",
      "Epoch 354/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5540 - accuracy: 0.6786 - val_loss: 0.5808 - val_accuracy: 0.6389\n",
      "Epoch 355/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5537 - accuracy: 0.6786 - val_loss: 0.5805 - val_accuracy: 0.6389\n",
      "Epoch 356/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5534 - accuracy: 0.6786 - val_loss: 0.5802 - val_accuracy: 0.6389\n",
      "Epoch 357/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5531 - accuracy: 0.6786 - val_loss: 0.5799 - val_accuracy: 0.6389\n",
      "Epoch 358/500\n",
      "84/84 [==============================] - 0s 334us/step - loss: 0.5528 - accuracy: 0.6786 - val_loss: 0.5796 - val_accuracy: 0.6389\n",
      "Epoch 359/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5524 - accuracy: 0.6786 - val_loss: 0.5793 - val_accuracy: 0.6389\n",
      "Epoch 360/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5521 - accuracy: 0.6786 - val_loss: 0.5789 - val_accuracy: 0.6389\n",
      "Epoch 361/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5518 - accuracy: 0.6786 - val_loss: 0.5786 - val_accuracy: 0.6389\n",
      "Epoch 362/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5516 - accuracy: 0.6786 - val_loss: 0.5783 - val_accuracy: 0.6389\n",
      "Epoch 363/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.5513 - accuracy: 0.6786 - val_loss: 0.5780 - val_accuracy: 0.6389\n",
      "Epoch 364/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5509 - accuracy: 0.6786 - val_loss: 0.5777 - val_accuracy: 0.6389\n",
      "Epoch 365/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5507 - accuracy: 0.6786 - val_loss: 0.5774 - val_accuracy: 0.6389\n",
      "Epoch 366/500\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5504 - accuracy: 0.6786 - val_loss: 0.5771 - val_accuracy: 0.6389\n",
      "Epoch 367/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5501 - accuracy: 0.6786 - val_loss: 0.5769 - val_accuracy: 0.6389\n",
      "Epoch 368/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5498 - accuracy: 0.6786 - val_loss: 0.5766 - val_accuracy: 0.6389\n",
      "Epoch 369/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.5495 - accuracy: 0.6786 - val_loss: 0.5763 - val_accuracy: 0.6389\n",
      "Epoch 370/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.5492 - accuracy: 0.6786 - val_loss: 0.5760 - val_accuracy: 0.6389\n",
      "Epoch 371/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.5489 - accuracy: 0.6786 - val_loss: 0.5758 - val_accuracy: 0.6389\n",
      "Epoch 372/500\n",
      "84/84 [==============================] - 0s 631us/step - loss: 0.5486 - accuracy: 0.6786 - val_loss: 0.5755 - val_accuracy: 0.6389\n",
      "Epoch 373/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.5483 - accuracy: 0.6786 - val_loss: 0.5752 - val_accuracy: 0.6389\n",
      "Epoch 374/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5481 - accuracy: 0.6786 - val_loss: 0.5749 - val_accuracy: 0.6389\n",
      "Epoch 375/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5478 - accuracy: 0.6786 - val_loss: 0.5746 - val_accuracy: 0.6389\n",
      "Epoch 376/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5475 - accuracy: 0.6786 - val_loss: 0.5744 - val_accuracy: 0.6389\n",
      "Epoch 377/500\n",
      "84/84 [==============================] - 0s 536us/step - loss: 0.5472 - accuracy: 0.6786 - val_loss: 0.5741 - val_accuracy: 0.6389\n",
      "Epoch 378/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5470 - accuracy: 0.6786 - val_loss: 0.5739 - val_accuracy: 0.6389\n",
      "Epoch 379/500\n",
      "84/84 [==============================] - 0s 560us/step - loss: 0.5467 - accuracy: 0.6786 - val_loss: 0.5736 - val_accuracy: 0.6389\n",
      "Epoch 380/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.5464 - accuracy: 0.6786 - val_loss: 0.5733 - val_accuracy: 0.6389\n",
      "Epoch 381/500\n",
      "84/84 [==============================] - 0s 453us/step - loss: 0.5461 - accuracy: 0.6786 - val_loss: 0.5730 - val_accuracy: 0.6389\n",
      "Epoch 382/500\n",
      "84/84 [==============================] - 0s 536us/step - loss: 0.5459 - accuracy: 0.6786 - val_loss: 0.5727 - val_accuracy: 0.6389\n",
      "Epoch 383/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5456 - accuracy: 0.6786 - val_loss: 0.5725 - val_accuracy: 0.6389\n",
      "Epoch 384/500\n",
      "84/84 [==============================] - 0s 655us/step - loss: 0.5453 - accuracy: 0.6786 - val_loss: 0.5722 - val_accuracy: 0.6389\n",
      "Epoch 385/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.5450 - accuracy: 0.6786 - val_loss: 0.5719 - val_accuracy: 0.6389\n",
      "Epoch 386/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5447 - accuracy: 0.6786 - val_loss: 0.5717 - val_accuracy: 0.6389\n",
      "Epoch 387/500\n",
      "84/84 [==============================] - 0s 714us/step - loss: 0.5445 - accuracy: 0.6786 - val_loss: 0.5714 - val_accuracy: 0.6389\n",
      "Epoch 388/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.5442 - accuracy: 0.6786 - val_loss: 0.5712 - val_accuracy: 0.6389\n",
      "Epoch 389/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.5439 - accuracy: 0.6786 - val_loss: 0.5709 - val_accuracy: 0.6389\n",
      "Epoch 390/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5437 - accuracy: 0.6786 - val_loss: 0.5707 - val_accuracy: 0.6389\n",
      "Epoch 391/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.5434 - accuracy: 0.6786 - val_loss: 0.5704 - val_accuracy: 0.6389\n",
      "Epoch 392/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5432 - accuracy: 0.6786 - val_loss: 0.5702 - val_accuracy: 0.6389\n",
      "Epoch 393/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5429 - accuracy: 0.6786 - val_loss: 0.5699 - val_accuracy: 0.6389\n",
      "Epoch 394/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5426 - accuracy: 0.6786 - val_loss: 0.5696 - val_accuracy: 0.6389\n",
      "Epoch 395/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5424 - accuracy: 0.6786 - val_loss: 0.5694 - val_accuracy: 0.6389\n",
      "Epoch 396/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5422 - accuracy: 0.6786 - val_loss: 0.5691 - val_accuracy: 0.6389\n",
      "Epoch 397/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5419 - accuracy: 0.6786 - val_loss: 0.5689 - val_accuracy: 0.6389\n",
      "Epoch 398/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5416 - accuracy: 0.6786 - val_loss: 0.5686 - val_accuracy: 0.6389\n",
      "Epoch 399/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5413 - accuracy: 0.6786 - val_loss: 0.5684 - val_accuracy: 0.6389\n",
      "Epoch 400/500\n",
      "84/84 [==============================] - 0s 512us/step - loss: 0.5411 - accuracy: 0.6786 - val_loss: 0.5682 - val_accuracy: 0.6389\n",
      "Epoch 401/500\n",
      "84/84 [==============================] - 0s 607us/step - loss: 0.5409 - accuracy: 0.6786 - val_loss: 0.5679 - val_accuracy: 0.6389\n",
      "Epoch 402/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5406 - accuracy: 0.6786 - val_loss: 0.5677 - val_accuracy: 0.6389\n",
      "Epoch 403/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5404 - accuracy: 0.6786 - val_loss: 0.5675 - val_accuracy: 0.6389\n",
      "Epoch 404/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.5453 - accuracy: 0.62 - 0s 345us/step - loss: 0.5401 - accuracy: 0.6786 - val_loss: 0.5672 - val_accuracy: 0.6389\n",
      "Epoch 405/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5399 - accuracy: 0.6786 - val_loss: 0.5670 - val_accuracy: 0.6389\n",
      "Epoch 406/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5396 - accuracy: 0.6786 - val_loss: 0.5668 - val_accuracy: 0.6389\n",
      "Epoch 407/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5394 - accuracy: 0.6786 - val_loss: 0.5666 - val_accuracy: 0.6389\n",
      "Epoch 408/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5391 - accuracy: 0.6786 - val_loss: 0.5663 - val_accuracy: 0.6389\n",
      "Epoch 409/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5389 - accuracy: 0.6786 - val_loss: 0.5661 - val_accuracy: 0.6389\n",
      "Epoch 410/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5387 - accuracy: 0.6786 - val_loss: 0.5659 - val_accuracy: 0.6389\n",
      "Epoch 411/500\n",
      "84/84 [==============================] - 0s 703us/step - loss: 0.5384 - accuracy: 0.6786 - val_loss: 0.5657 - val_accuracy: 0.6389\n",
      "Epoch 412/500\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.6786 - val_loss: 0.5655 - val_accuracy: 0.6389\n",
      "Epoch 413/500\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5379 - accuracy: 0.6786 - val_loss: 0.5652 - val_accuracy: 0.6389\n",
      "Epoch 414/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5377 - accuracy: 0.6786 - val_loss: 0.5650 - val_accuracy: 0.6389\n",
      "Epoch 415/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.5375 - accuracy: 0.6786 - val_loss: 0.5647 - val_accuracy: 0.6389\n",
      "Epoch 416/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5372 - accuracy: 0.6786 - val_loss: 0.5645 - val_accuracy: 0.6389\n",
      "Epoch 417/500\n",
      "84/84 [==============================] - 0s 834us/step - loss: 0.5370 - accuracy: 0.6786 - val_loss: 0.5643 - val_accuracy: 0.6389\n",
      "Epoch 418/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.5367 - accuracy: 0.6786 - val_loss: 0.5640 - val_accuracy: 0.6389\n",
      "Epoch 419/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.5365 - accuracy: 0.6786 - val_loss: 0.5638 - val_accuracy: 0.6389\n",
      "Epoch 420/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5363 - accuracy: 0.6786 - val_loss: 0.5635 - val_accuracy: 0.6389\n",
      "Epoch 421/500\n",
      "84/84 [==============================] - 0s 595us/step - loss: 0.5361 - accuracy: 0.6786 - val_loss: 0.5633 - val_accuracy: 0.6389\n",
      "Epoch 422/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5358 - accuracy: 0.6786 - val_loss: 0.5631 - val_accuracy: 0.6389\n",
      "Epoch 423/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5356 - accuracy: 0.6786 - val_loss: 0.5629 - val_accuracy: 0.6389\n",
      "Epoch 424/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.5354 - accuracy: 0.6786 - val_loss: 0.5627 - val_accuracy: 0.6389\n",
      "Epoch 425/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5351 - accuracy: 0.6786 - val_loss: 0.5625 - val_accuracy: 0.6389\n",
      "Epoch 426/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.5349 - accuracy: 0.6786 - val_loss: 0.5623 - val_accuracy: 0.6389\n",
      "Epoch 427/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5347 - accuracy: 0.6786 - val_loss: 0.5620 - val_accuracy: 0.6389\n",
      "Epoch 428/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5344 - accuracy: 0.6786 - val_loss: 0.5618 - val_accuracy: 0.6389\n",
      "Epoch 429/500\n",
      "84/84 [==============================] - 0s 619us/step - loss: 0.5342 - accuracy: 0.6786 - val_loss: 0.5615 - val_accuracy: 0.6389\n",
      "Epoch 430/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5340 - accuracy: 0.6786 - val_loss: 0.5613 - val_accuracy: 0.6389\n",
      "Epoch 431/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5338 - accuracy: 0.6786 - val_loss: 0.5611 - val_accuracy: 0.6389\n",
      "Epoch 432/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5336 - accuracy: 0.6786 - val_loss: 0.5609 - val_accuracy: 0.6389\n",
      "Epoch 433/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5333 - accuracy: 0.6786 - val_loss: 0.5607 - val_accuracy: 0.6389\n",
      "Epoch 434/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5331 - accuracy: 0.6786 - val_loss: 0.5604 - val_accuracy: 0.6389\n",
      "Epoch 435/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.5329 - accuracy: 0.6786 - val_loss: 0.5602 - val_accuracy: 0.6389\n",
      "Epoch 436/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.5327 - accuracy: 0.6786 - val_loss: 0.5599 - val_accuracy: 0.6389\n",
      "Epoch 437/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5325 - accuracy: 0.6786 - val_loss: 0.5597 - val_accuracy: 0.6389\n",
      "Epoch 438/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5322 - accuracy: 0.6786 - val_loss: 0.5595 - val_accuracy: 0.6389\n",
      "Epoch 439/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5320 - accuracy: 0.6786 - val_loss: 0.5592 - val_accuracy: 0.6389\n",
      "Epoch 440/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5318 - accuracy: 0.6786 - val_loss: 0.5590 - val_accuracy: 0.6389\n",
      "Epoch 441/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5316 - accuracy: 0.6786 - val_loss: 0.5588 - val_accuracy: 0.6389\n",
      "Epoch 442/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5314 - accuracy: 0.6786 - val_loss: 0.5586 - val_accuracy: 0.6389\n",
      "Epoch 443/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5312 - accuracy: 0.6786 - val_loss: 0.5583 - val_accuracy: 0.6389\n",
      "Epoch 444/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5309 - accuracy: 0.6786 - val_loss: 0.5581 - val_accuracy: 0.6389\n",
      "Epoch 445/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5307 - accuracy: 0.6786 - val_loss: 0.5579 - val_accuracy: 0.6389\n",
      "Epoch 446/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5305 - accuracy: 0.6786 - val_loss: 0.5577 - val_accuracy: 0.6389\n",
      "Epoch 447/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5303 - accuracy: 0.6786 - val_loss: 0.5575 - val_accuracy: 0.6389\n",
      "Epoch 448/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5301 - accuracy: 0.6786 - val_loss: 0.5573 - val_accuracy: 0.6389\n",
      "Epoch 449/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5299 - accuracy: 0.6786 - val_loss: 0.5571 - val_accuracy: 0.6389\n",
      "Epoch 450/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5297 - accuracy: 0.6786 - val_loss: 0.5569 - val_accuracy: 0.6389\n",
      "Epoch 451/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5295 - accuracy: 0.6786 - val_loss: 0.5567 - val_accuracy: 0.6389\n",
      "Epoch 452/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5293 - accuracy: 0.6786 - val_loss: 0.5564 - val_accuracy: 0.6389\n",
      "Epoch 453/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5291 - accuracy: 0.6786 - val_loss: 0.5562 - val_accuracy: 0.6667\n",
      "Epoch 454/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5289 - accuracy: 0.6786 - val_loss: 0.5560 - val_accuracy: 0.6667\n",
      "Epoch 455/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5287 - accuracy: 0.6786 - val_loss: 0.5558 - val_accuracy: 0.6667\n",
      "Epoch 456/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5285 - accuracy: 0.6786 - val_loss: 0.5556 - val_accuracy: 0.6667\n",
      "Epoch 457/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5283 - accuracy: 0.6786 - val_loss: 0.5554 - val_accuracy: 0.6667\n",
      "Epoch 458/500\n",
      "84/84 [==============================] - 0s 226us/step - loss: 0.5281 - accuracy: 0.6786 - val_loss: 0.5552 - val_accuracy: 0.6667\n",
      "Epoch 459/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5279 - accuracy: 0.6786 - val_loss: 0.5549 - val_accuracy: 0.6667\n",
      "Epoch 460/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5277 - accuracy: 0.6786 - val_loss: 0.5547 - val_accuracy: 0.6667\n",
      "Epoch 461/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5275 - accuracy: 0.6786 - val_loss: 0.5545 - val_accuracy: 0.6667\n",
      "Epoch 462/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5273 - accuracy: 0.6786 - val_loss: 0.5543 - val_accuracy: 0.6667\n",
      "Epoch 463/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5272 - accuracy: 0.6786 - val_loss: 0.5541 - val_accuracy: 0.6667\n",
      "Epoch 464/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5269 - accuracy: 0.6786 - val_loss: 0.5539 - val_accuracy: 0.6667\n",
      "Epoch 465/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5267 - accuracy: 0.6786 - val_loss: 0.5537 - val_accuracy: 0.6667\n",
      "Epoch 466/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5265 - accuracy: 0.6786 - val_loss: 0.5535 - val_accuracy: 0.6667\n",
      "Epoch 467/500\n",
      "84/84 [==============================] - 0s 226us/step - loss: 0.5263 - accuracy: 0.6786 - val_loss: 0.5533 - val_accuracy: 0.6667\n",
      "Epoch 468/500\n",
      "84/84 [==============================] - 0s 226us/step - loss: 0.5261 - accuracy: 0.6786 - val_loss: 0.5531 - val_accuracy: 0.6667\n",
      "Epoch 469/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5259 - accuracy: 0.6786 - val_loss: 0.5529 - val_accuracy: 0.6667\n",
      "Epoch 470/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.6086 - accuracy: 0.59 - 0s 238us/step - loss: 0.5257 - accuracy: 0.6786 - val_loss: 0.5527 - val_accuracy: 0.6667\n",
      "Epoch 471/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5256 - accuracy: 0.6786 - val_loss: 0.5525 - val_accuracy: 0.6667\n",
      "Epoch 472/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5254 - accuracy: 0.6786 - val_loss: 0.5523 - val_accuracy: 0.6667\n",
      "Epoch 473/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5252 - accuracy: 0.6786 - val_loss: 0.5521 - val_accuracy: 0.6667\n",
      "Epoch 474/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5250 - accuracy: 0.6786 - val_loss: 0.5520 - val_accuracy: 0.6667\n",
      "Epoch 475/500\n",
      "84/84 [==============================] - 0s 321us/step - loss: 0.5248 - accuracy: 0.6786 - val_loss: 0.5518 - val_accuracy: 0.6667\n",
      "Epoch 476/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5246 - accuracy: 0.6786 - val_loss: 0.5516 - val_accuracy: 0.6667\n",
      "Epoch 477/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5244 - accuracy: 0.6786 - val_loss: 0.5514 - val_accuracy: 0.6667\n",
      "Epoch 478/500\n",
      "84/84 [==============================] - 0s 513us/step - loss: 0.5242 - accuracy: 0.6786 - val_loss: 0.5513 - val_accuracy: 0.6667\n",
      "Epoch 479/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5240 - accuracy: 0.6786 - val_loss: 0.5511 - val_accuracy: 0.6667\n",
      "Epoch 480/500\n",
      "84/84 [==============================] - 0s 214us/step - loss: 0.5238 - accuracy: 0.6786 - val_loss: 0.5509 - val_accuracy: 0.6667\n",
      "Epoch 481/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5237 - accuracy: 0.6786 - val_loss: 0.5507 - val_accuracy: 0.6667\n",
      "Epoch 482/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5235 - accuracy: 0.6786 - val_loss: 0.5505 - val_accuracy: 0.6667\n",
      "Epoch 483/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5233 - accuracy: 0.6786 - val_loss: 0.5504 - val_accuracy: 0.6667\n",
      "Epoch 484/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5231 - accuracy: 0.6786 - val_loss: 0.5502 - val_accuracy: 0.6667\n",
      "Epoch 485/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5230 - accuracy: 0.6786 - val_loss: 0.5500 - val_accuracy: 0.6667\n",
      "Epoch 486/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5228 - accuracy: 0.6786 - val_loss: 0.5498 - val_accuracy: 0.6667\n",
      "Epoch 487/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5226 - accuracy: 0.6786 - val_loss: 0.5496 - val_accuracy: 0.6667\n",
      "Epoch 488/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5224 - accuracy: 0.6786 - val_loss: 0.5495 - val_accuracy: 0.6667\n",
      "Epoch 489/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5222 - accuracy: 0.6786 - val_loss: 0.5493 - val_accuracy: 0.6667\n",
      "Epoch 490/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5220 - accuracy: 0.6786 - val_loss: 0.5492 - val_accuracy: 0.6667\n",
      "Epoch 491/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5219 - accuracy: 0.6786 - val_loss: 0.5490 - val_accuracy: 0.6667\n",
      "Epoch 492/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5217 - accuracy: 0.6786 - val_loss: 0.5488 - val_accuracy: 0.6667\n",
      "Epoch 493/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5215 - accuracy: 0.6786 - val_loss: 0.5486 - val_accuracy: 0.6667\n",
      "Epoch 494/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.5214 - accuracy: 0.6786 - val_loss: 0.5485 - val_accuracy: 0.6667\n",
      "Epoch 495/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5212 - accuracy: 0.6786 - val_loss: 0.5483 - val_accuracy: 0.6667\n",
      "Epoch 496/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5210 - accuracy: 0.6786 - val_loss: 0.5481 - val_accuracy: 0.6667\n",
      "Epoch 497/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5209 - accuracy: 0.6786 - val_loss: 0.5480 - val_accuracy: 0.6667\n",
      "Epoch 498/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.5206 - accuracy: 0.6786 - val_loss: 0.5478 - val_accuracy: 0.6667\n",
      "Epoch 499/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5205 - accuracy: 0.6786 - val_loss: 0.5476 - val_accuracy: 0.6667\n",
      "Epoch 500/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5203 - accuracy: 0.6786 - val_loss: 0.5475 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2980d862788>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,epochs=500,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 1 Neuron\n",
      "[[ 3.9194474 -2.2678359  0.8465632]]\n",
      "2. 2 Neuron:\n",
      "[[0.38667923 0.29085717 0.3224636 ]]\n",
      "3. Train\n",
      "[[0.9096995  0.05517308 0.03512748]]\n"
     ]
    }
   ],
   "source": [
    "print(\"1. 1 Neuron\")\n",
    "print(az)\n",
    "print(\"2. 2 Neuron:\")\n",
    "print(aza)\n",
    "print(\"3. Train\")\n",
    "print(model.predict(np.array([[5.1,5.3,1.4,0.2]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 108us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(52.8, 67.5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss, train_accuracy=model.evaluate(X_train, y_train)\n",
    "round(train_loss*100,1), round(train_accuracy*100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 67us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(52.8, 66.7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_accuracy=model.evaluate(X_test, y_test)\n",
    "round(test_loss*100,1), round(test_accuracy*100,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOW TO:\n",
    "Using This Iris Framework (Data in MM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9096995  0.05517308 0.03512748]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(np.array([[5.1,5.3,1.4,0.2]])))#RANGE: SEPAL LENGHT, SEPAL WIDTH,PETAL LENGHT, PETAL WIDTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Vergleich mit ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "Xy=iris.data\n",
    "yy=iris.data\n",
    "Xy_sepal_lenght=Xy[:,0]\n",
    "Xy_sepal_width=Xy[:,1]\n",
    "Xy_petal_lenght=Xy[:,2]\n",
    "Xy_sepal_width=Xy[:,3]\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xy_train, Xy_test, yy_train, yy_test=train_test_split(X,y,test_size=0.4)\n",
    "#USING NEAREST NEIGHBORS\n",
    "from sklearn import neighbors\n",
    "clf=neighbors.KNeighborsClassifier(1)\n",
    "clf.fit(Xy_train,yy_train)\n",
    "print(clf.score(Xy_train,yy_train))\n",
    "print(clf.score(Xy_test,yy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vergleich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learning:\n",
      "Probability for zero in percent\n",
      "5.0\n",
      "Probability for one in percent\n",
      "46.2\n",
      "Probability for two in percent\n",
      "48.8\n"
     ]
    }
   ],
   "source": [
    "print(\"Deep Learning:\")\n",
    "deplearn=model.predict(np.array([[6.3,2.7,5.5,1.5]]))\n",
    "print(\"Probability for zero in percent\")\n",
    "print(round(deplearn[0][0]*100,1))\n",
    "print(\"Probability for one in percent\")\n",
    "print(round(deplearn[0][1]*100,1))\n",
    "print(\"Probability for two in percent\")\n",
    "print(round(deplearn[0][2]*100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"ML:\")\n",
    "clf.predict([[6.3,2.7,5.5,1.5]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
