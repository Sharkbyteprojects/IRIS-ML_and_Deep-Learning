{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Verkehrszeichen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made by [Sharkbyteprojects](https://github.com/sharkbyteprojects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need\n",
    "- Keras\n",
    "- SKLEARN\n",
    "- numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "inputs=Input(shape=(4,))\n",
    "fc=Dense(3)(inputs)\n",
    "from keras.models import Model\n",
    "model=Model(input=inputs,output=fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zeige infos Ã¼ber Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and add new Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "             loss=\"categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])\n",
    "predictionss=Dense(8,activation=\"softmax\")(fc)\n",
    "predictions=Dense(3,activation=\"softmax\")(predictionss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test of Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "az=model.predict(np.array([[5.1,5.3,1.4,0.2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recompile and Retry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 15        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 74\n",
      "Trainable params: 74\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Model(input=inputs,output=predictions)\n",
    "model.compile(optimizer=\"adam\",\n",
    "             loss=\"categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "aza=model.predict(np.array([[5.1,5.3,1.4,0.2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris =datasets.load_iris()\n",
    "X=np.array(iris.data)\n",
    "y=np.array(iris.target)\n",
    "X.shape, y.shape\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y=to_categorical(y,3)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "complete prepare for train, start train:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84 samples, validate on 36 samples\n",
      "Epoch 1/500\n",
      "84/84 [==============================] - 3s 37ms/step - loss: 1.1123 - accuracy: 0.3452 - val_loss: 1.1231 - val_accuracy: 0.3056\n",
      "Epoch 2/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 1.1110 - accuracy: 0.3452 - val_loss: 1.1217 - val_accuracy: 0.3056\n",
      "Epoch 3/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 1.1098 - accuracy: 0.3452 - val_loss: 1.1204 - val_accuracy: 0.3056\n",
      "Epoch 4/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 1.1088 - accuracy: 0.3452 - val_loss: 1.1193 - val_accuracy: 0.3056\n",
      "Epoch 5/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 1.1078 - accuracy: 0.3452 - val_loss: 1.1182 - val_accuracy: 0.3056\n",
      "Epoch 6/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 1.1070 - accuracy: 0.3452 - val_loss: 1.1173 - val_accuracy: 0.3056\n",
      "Epoch 7/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 1.1064 - accuracy: 0.3452 - val_loss: 1.1164 - val_accuracy: 0.3056\n",
      "Epoch 8/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 1.1056 - accuracy: 0.3452 - val_loss: 1.1157 - val_accuracy: 0.3056\n",
      "Epoch 9/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 1.1050 - accuracy: 0.3452 - val_loss: 1.1150 - val_accuracy: 0.3056\n",
      "Epoch 10/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 1.1045 - accuracy: 0.3452 - val_loss: 1.1143 - val_accuracy: 0.3056\n",
      "Epoch 11/500\n",
      "84/84 [==============================] - 0s 464us/step - loss: 1.1040 - accuracy: 0.3452 - val_loss: 1.1137 - val_accuracy: 0.3056\n",
      "Epoch 12/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 1.1036 - accuracy: 0.3452 - val_loss: 1.1130 - val_accuracy: 0.3056\n",
      "Epoch 13/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 1.1032 - accuracy: 0.3452 - val_loss: 1.1125 - val_accuracy: 0.3056\n",
      "Epoch 14/500\n",
      "84/84 [==============================] - 0s 560us/step - loss: 1.1029 - accuracy: 0.3452 - val_loss: 1.1119 - val_accuracy: 0.3056\n",
      "Epoch 15/500\n",
      "84/84 [==============================] - 0s 523us/step - loss: 1.1025 - accuracy: 0.3452 - val_loss: 1.1114 - val_accuracy: 0.3056\n",
      "Epoch 16/500\n",
      "84/84 [==============================] - 0s 583us/step - loss: 1.1022 - accuracy: 0.3452 - val_loss: 1.1109 - val_accuracy: 0.3056\n",
      "Epoch 17/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 1.1019 - accuracy: 0.3452 - val_loss: 1.1105 - val_accuracy: 0.3056\n",
      "Epoch 18/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 1.1017 - accuracy: 0.3452 - val_loss: 1.1101 - val_accuracy: 0.3056\n",
      "Epoch 19/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 1.1013 - accuracy: 0.3452 - val_loss: 1.1097 - val_accuracy: 0.3056\n",
      "Epoch 20/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 1.1012 - accuracy: 0.3452 - val_loss: 1.1093 - val_accuracy: 0.3056\n",
      "Epoch 21/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 1.1010 - accuracy: 0.3452 - val_loss: 1.1090 - val_accuracy: 0.3056\n",
      "Epoch 22/500\n",
      "84/84 [==============================] - 0s 643us/step - loss: 1.1008 - accuracy: 0.3452 - val_loss: 1.1086 - val_accuracy: 0.3056\n",
      "Epoch 23/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 1.1006 - accuracy: 0.3452 - val_loss: 1.1083 - val_accuracy: 0.3056\n",
      "Epoch 24/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 1.1003 - accuracy: 0.3452 - val_loss: 1.1081 - val_accuracy: 0.3056\n",
      "Epoch 25/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 1.1002 - accuracy: 0.3452 - val_loss: 1.1078 - val_accuracy: 0.3056\n",
      "Epoch 26/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 1.1001 - accuracy: 0.3452 - val_loss: 1.1075 - val_accuracy: 0.3056\n",
      "Epoch 27/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 1.0999 - accuracy: 0.3452 - val_loss: 1.1072 - val_accuracy: 0.3056\n",
      "Epoch 28/500\n",
      "84/84 [==============================] - 0s 643us/step - loss: 1.0997 - accuracy: 0.3452 - val_loss: 1.1070 - val_accuracy: 0.3056\n",
      "Epoch 29/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 1.0995 - accuracy: 0.3452 - val_loss: 1.1068 - val_accuracy: 0.3056\n",
      "Epoch 30/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 1.0993 - accuracy: 0.3452 - val_loss: 1.1065 - val_accuracy: 0.3056\n",
      "Epoch 31/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 1.0991 - accuracy: 0.3452 - val_loss: 1.1062 - val_accuracy: 0.3056\n",
      "Epoch 32/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 1.0989 - accuracy: 0.3452 - val_loss: 1.1059 - val_accuracy: 0.3056\n",
      "Epoch 33/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 1.0987 - accuracy: 0.3452 - val_loss: 1.1056 - val_accuracy: 0.3056\n",
      "Epoch 34/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 1.0984 - accuracy: 0.3452 - val_loss: 1.1053 - val_accuracy: 0.3056\n",
      "Epoch 35/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 1.0981 - accuracy: 0.3452 - val_loss: 1.1049 - val_accuracy: 0.3056\n",
      "Epoch 36/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 1.0978 - accuracy: 0.3452 - val_loss: 1.1045 - val_accuracy: 0.3056\n",
      "Epoch 37/500\n",
      "84/84 [==============================] - 0s 774us/step - loss: 1.0974 - accuracy: 0.3452 - val_loss: 1.1040 - val_accuracy: 0.3056\n",
      "Epoch 38/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 1.0970 - accuracy: 0.3452 - val_loss: 1.1035 - val_accuracy: 0.3056\n",
      "Epoch 39/500\n",
      "84/84 [==============================] - 0s 536us/step - loss: 1.0965 - accuracy: 0.3452 - val_loss: 1.1028 - val_accuracy: 0.3056\n",
      "Epoch 40/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 1.0960 - accuracy: 0.3452 - val_loss: 1.1022 - val_accuracy: 0.3056\n",
      "Epoch 41/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 1.0953 - accuracy: 0.3452 - val_loss: 1.1015 - val_accuracy: 0.3056\n",
      "Epoch 42/500\n",
      "84/84 [==============================] - 0s 762us/step - loss: 1.0945 - accuracy: 0.3452 - val_loss: 1.1007 - val_accuracy: 0.3056\n",
      "Epoch 43/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 1.0938 - accuracy: 0.3452 - val_loss: 1.0997 - val_accuracy: 0.3056\n",
      "Epoch 44/500\n",
      "84/84 [==============================] - 0s 798us/step - loss: 1.0926 - accuracy: 0.3452 - val_loss: 1.0986 - val_accuracy: 0.3056\n",
      "Epoch 45/500\n",
      "84/84 [==============================] - 0s 560us/step - loss: 1.0916 - accuracy: 0.3452 - val_loss: 1.0974 - val_accuracy: 0.3056\n",
      "Epoch 46/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 1.0903 - accuracy: 0.3452 - val_loss: 1.0960 - val_accuracy: 0.3056\n",
      "Epoch 47/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 1.0888 - accuracy: 0.3452 - val_loss: 1.0945 - val_accuracy: 0.3056\n",
      "Epoch 48/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 1.0874 - accuracy: 0.3452 - val_loss: 1.0929 - val_accuracy: 0.3056\n",
      "Epoch 49/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 1.0856 - accuracy: 0.3452 - val_loss: 1.0913 - val_accuracy: 0.3056\n",
      "Epoch 50/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 1.0838 - accuracy: 0.3452 - val_loss: 1.0895 - val_accuracy: 0.3056\n",
      "Epoch 51/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 1.0818 - accuracy: 0.3452 - val_loss: 1.0877 - val_accuracy: 0.3056\n",
      "Epoch 52/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 1.0799 - accuracy: 0.3452 - val_loss: 1.0857 - val_accuracy: 0.3056\n",
      "Epoch 53/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 1.0777 - accuracy: 0.3452 - val_loss: 1.0835 - val_accuracy: 0.3056\n",
      "Epoch 54/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 1.0755 - accuracy: 0.3452 - val_loss: 1.0813 - val_accuracy: 0.3056\n",
      "Epoch 55/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 1.0730 - accuracy: 0.3452 - val_loss: 1.0789 - val_accuracy: 0.3056\n",
      "Epoch 56/500\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 1.0707 - accuracy: 0.3452 - val_loss: 1.0764 - val_accuracy: 0.3056\n",
      "Epoch 57/500\n",
      "84/84 [==============================] - 0s 452us/step - loss: 1.0679 - accuracy: 0.3452 - val_loss: 1.0738 - val_accuracy: 0.3056\n",
      "Epoch 58/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 1.0650 - accuracy: 0.3452 - val_loss: 1.0710 - val_accuracy: 0.3056\n",
      "Epoch 59/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 1.0622 - accuracy: 0.3452 - val_loss: 1.0681 - val_accuracy: 0.3056\n",
      "Epoch 60/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 1.0591 - accuracy: 0.3452 - val_loss: 1.0651 - val_accuracy: 0.3056\n",
      "Epoch 61/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 1.0559 - accuracy: 0.3452 - val_loss: 1.0618 - val_accuracy: 0.3056\n",
      "Epoch 62/500\n",
      "84/84 [==============================] - 0s 560us/step - loss: 1.0525 - accuracy: 0.3571 - val_loss: 1.0585 - val_accuracy: 0.3056\n",
      "Epoch 63/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 1.0490 - accuracy: 0.3690 - val_loss: 1.0550 - val_accuracy: 0.3056\n",
      "Epoch 64/500\n",
      "84/84 [==============================] - 0s 560us/step - loss: 1.0452 - accuracy: 0.4048 - val_loss: 1.0514 - val_accuracy: 0.3333\n",
      "Epoch 65/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 1.0417 - accuracy: 0.4167 - val_loss: 1.0477 - val_accuracy: 0.3889\n",
      "Epoch 66/500\n",
      "84/84 [==============================] - 0s 512us/step - loss: 1.0376 - accuracy: 0.4524 - val_loss: 1.0439 - val_accuracy: 0.3889\n",
      "Epoch 67/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 1.0336 - accuracy: 0.4524 - val_loss: 1.0399 - val_accuracy: 0.4444\n",
      "Epoch 68/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 1.0296 - accuracy: 0.4762 - val_loss: 1.0359 - val_accuracy: 0.5000\n",
      "Epoch 69/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 1.0254 - accuracy: 0.5000 - val_loss: 1.0317 - val_accuracy: 0.5278\n",
      "Epoch 70/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 1.0210 - accuracy: 0.5357 - val_loss: 1.0275 - val_accuracy: 0.5278\n",
      "Epoch 71/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 1.0165 - accuracy: 0.5714 - val_loss: 1.0231 - val_accuracy: 0.5556\n",
      "Epoch 72/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 1.0122 - accuracy: 0.6071 - val_loss: 1.0188 - val_accuracy: 0.6389\n",
      "Epoch 73/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 1.0075 - accuracy: 0.6190 - val_loss: 1.0143 - val_accuracy: 0.6389\n",
      "Epoch 74/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 1.0028 - accuracy: 0.6190 - val_loss: 1.0099 - val_accuracy: 0.6389\n",
      "Epoch 75/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.9980 - accuracy: 0.6310 - val_loss: 1.0054 - val_accuracy: 0.6389\n",
      "Epoch 76/500\n",
      "84/84 [==============================] - 0s 536us/step - loss: 0.9934 - accuracy: 0.6310 - val_loss: 1.0008 - val_accuracy: 0.6389\n",
      "Epoch 77/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.9885 - accuracy: 0.6786 - val_loss: 0.9963 - val_accuracy: 0.6389\n",
      "Epoch 78/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.9837 - accuracy: 0.6786 - val_loss: 0.9917 - val_accuracy: 0.6389\n",
      "Epoch 79/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.9789 - accuracy: 0.6786 - val_loss: 0.9871 - val_accuracy: 0.6389\n",
      "Epoch 80/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.9742 - accuracy: 0.6786 - val_loss: 0.9825 - val_accuracy: 0.6389\n",
      "Epoch 81/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.9693 - accuracy: 0.6786 - val_loss: 0.9780 - val_accuracy: 0.6389\n",
      "Epoch 82/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.9645 - accuracy: 0.6786 - val_loss: 0.9734 - val_accuracy: 0.6389\n",
      "Epoch 83/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.9598 - accuracy: 0.6786 - val_loss: 0.9688 - val_accuracy: 0.6389\n",
      "Epoch 84/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.9548 - accuracy: 0.6786 - val_loss: 0.9643 - val_accuracy: 0.6389\n",
      "Epoch 85/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.9501 - accuracy: 0.6786 - val_loss: 0.9599 - val_accuracy: 0.6389\n",
      "Epoch 86/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.9454 - accuracy: 0.6786 - val_loss: 0.9555 - val_accuracy: 0.6389\n",
      "Epoch 87/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.9408 - accuracy: 0.6786 - val_loss: 0.9511 - val_accuracy: 0.6389\n",
      "Epoch 88/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.9362 - accuracy: 0.6786 - val_loss: 0.9468 - val_accuracy: 0.6389\n",
      "Epoch 89/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.9315 - accuracy: 0.6786 - val_loss: 0.9426 - val_accuracy: 0.6389\n",
      "Epoch 90/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.9271 - accuracy: 0.6786 - val_loss: 0.9384 - val_accuracy: 0.6389\n",
      "Epoch 91/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.9227 - accuracy: 0.6786 - val_loss: 0.9343 - val_accuracy: 0.6389\n",
      "Epoch 92/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.9184 - accuracy: 0.6786 - val_loss: 0.9302 - val_accuracy: 0.6389\n",
      "Epoch 93/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.9140 - accuracy: 0.6786 - val_loss: 0.9262 - val_accuracy: 0.6389\n",
      "Epoch 94/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.9097 - accuracy: 0.6786 - val_loss: 0.9223 - val_accuracy: 0.6389\n",
      "Epoch 95/500\n",
      "84/84 [==============================] - 0s 452us/step - loss: 0.9055 - accuracy: 0.6786 - val_loss: 0.9184 - val_accuracy: 0.6389\n",
      "Epoch 96/500\n",
      "84/84 [==============================] - 0s 595us/step - loss: 0.9017 - accuracy: 0.6786 - val_loss: 0.9147 - val_accuracy: 0.6389\n",
      "Epoch 97/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.8975 - accuracy: 0.6786 - val_loss: 0.9110 - val_accuracy: 0.6389\n",
      "Epoch 98/500\n",
      "84/84 [==============================] - 0s 619us/step - loss: 0.8936 - accuracy: 0.6786 - val_loss: 0.9074 - val_accuracy: 0.6389\n",
      "Epoch 99/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.8897 - accuracy: 0.6786 - val_loss: 0.9039 - val_accuracy: 0.6389\n",
      "Epoch 100/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.8860 - accuracy: 0.6786 - val_loss: 0.9004 - val_accuracy: 0.6389\n",
      "Epoch 101/500\n",
      "84/84 [==============================] - 0s 452us/step - loss: 0.8823 - accuracy: 0.6786 - val_loss: 0.8970 - val_accuracy: 0.6389\n",
      "Epoch 102/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.8786 - accuracy: 0.6786 - val_loss: 0.8936 - val_accuracy: 0.6389\n",
      "Epoch 103/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.8750 - accuracy: 0.6786 - val_loss: 0.8904 - val_accuracy: 0.6389\n",
      "Epoch 104/500\n",
      "84/84 [==============================] - 0s 453us/step - loss: 0.8715 - accuracy: 0.6786 - val_loss: 0.8872 - val_accuracy: 0.6389\n",
      "Epoch 105/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.8682 - accuracy: 0.6786 - val_loss: 0.8840 - val_accuracy: 0.6389\n",
      "Epoch 106/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.8647 - accuracy: 0.6786 - val_loss: 0.8809 - val_accuracy: 0.6389\n",
      "Epoch 107/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.8614 - accuracy: 0.6786 - val_loss: 0.8779 - val_accuracy: 0.6389\n",
      "Epoch 108/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.8582 - accuracy: 0.6786 - val_loss: 0.8749 - val_accuracy: 0.6389\n",
      "Epoch 109/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.8551 - accuracy: 0.6786 - val_loss: 0.8720 - val_accuracy: 0.6389\n",
      "Epoch 110/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.8518 - accuracy: 0.6905 - val_loss: 0.8690 - val_accuracy: 0.6389\n",
      "Epoch 111/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.8767 - accuracy: 0.62 - 0s 333us/step - loss: 0.8488 - accuracy: 0.6905 - val_loss: 0.8662 - val_accuracy: 0.6389\n",
      "Epoch 112/500\n",
      "84/84 [==============================] - 0s 560us/step - loss: 0.8459 - accuracy: 0.6905 - val_loss: 0.8634 - val_accuracy: 0.6389\n",
      "Epoch 113/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.8428 - accuracy: 0.6786 - val_loss: 0.8606 - val_accuracy: 0.6389\n",
      "Epoch 114/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.8398 - accuracy: 0.6786 - val_loss: 0.8579 - val_accuracy: 0.6389\n",
      "Epoch 115/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.8370 - accuracy: 0.6786 - val_loss: 0.8552 - val_accuracy: 0.6389\n",
      "Epoch 116/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.8343 - accuracy: 0.6786 - val_loss: 0.8526 - val_accuracy: 0.6389\n",
      "Epoch 117/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.8314 - accuracy: 0.6786 - val_loss: 0.8500 - val_accuracy: 0.6389\n",
      "Epoch 118/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.8286 - accuracy: 0.6905 - val_loss: 0.8475 - val_accuracy: 0.6389\n",
      "Epoch 119/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.8259 - accuracy: 0.7024 - val_loss: 0.8449 - val_accuracy: 0.6667\n",
      "Epoch 120/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.8233 - accuracy: 0.7024 - val_loss: 0.8425 - val_accuracy: 0.6667\n",
      "Epoch 121/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.8207 - accuracy: 0.7143 - val_loss: 0.8400 - val_accuracy: 0.6667\n",
      "Epoch 122/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.8181 - accuracy: 0.7143 - val_loss: 0.8376 - val_accuracy: 0.6667\n",
      "Epoch 123/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.8155 - accuracy: 0.7143 - val_loss: 0.8352 - val_accuracy: 0.6667\n",
      "Epoch 124/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.8130 - accuracy: 0.7143 - val_loss: 0.8329 - val_accuracy: 0.6667\n",
      "Epoch 125/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.8106 - accuracy: 0.7024 - val_loss: 0.8306 - val_accuracy: 0.6667\n",
      "Epoch 126/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.8081 - accuracy: 0.7024 - val_loss: 0.8283 - val_accuracy: 0.6667\n",
      "Epoch 127/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.8057 - accuracy: 0.7024 - val_loss: 0.8260 - val_accuracy: 0.6389\n",
      "Epoch 128/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.8034 - accuracy: 0.7024 - val_loss: 0.8238 - val_accuracy: 0.6389\n",
      "Epoch 129/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.8010 - accuracy: 0.7024 - val_loss: 0.8216 - val_accuracy: 0.6389\n",
      "Epoch 130/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.7987 - accuracy: 0.7024 - val_loss: 0.8194 - val_accuracy: 0.6389\n",
      "Epoch 131/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.7965 - accuracy: 0.6905 - val_loss: 0.8173 - val_accuracy: 0.6389\n",
      "Epoch 132/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.7942 - accuracy: 0.6905 - val_loss: 0.8152 - val_accuracy: 0.6389\n",
      "Epoch 133/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.7920 - accuracy: 0.6905 - val_loss: 0.8131 - val_accuracy: 0.6389\n",
      "Epoch 134/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.7898 - accuracy: 0.6905 - val_loss: 0.8110 - val_accuracy: 0.6389\n",
      "Epoch 135/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.7876 - accuracy: 0.6905 - val_loss: 0.8090 - val_accuracy: 0.6389\n",
      "Epoch 136/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.7856 - accuracy: 0.6905 - val_loss: 0.8070 - val_accuracy: 0.6389\n",
      "Epoch 137/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.7834 - accuracy: 0.6905 - val_loss: 0.8050 - val_accuracy: 0.6389\n",
      "Epoch 138/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.7813 - accuracy: 0.6905 - val_loss: 0.8030 - val_accuracy: 0.6389\n",
      "Epoch 139/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.7793 - accuracy: 0.6905 - val_loss: 0.8011 - val_accuracy: 0.6389\n",
      "Epoch 140/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.7773 - accuracy: 0.6786 - val_loss: 0.7993 - val_accuracy: 0.6389\n",
      "Epoch 141/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.7752 - accuracy: 0.6786 - val_loss: 0.7974 - val_accuracy: 0.6389\n",
      "Epoch 142/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.7733 - accuracy: 0.6786 - val_loss: 0.7955 - val_accuracy: 0.6389\n",
      "Epoch 143/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.7713 - accuracy: 0.6786 - val_loss: 0.7937 - val_accuracy: 0.6389\n",
      "Epoch 144/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.7694 - accuracy: 0.6786 - val_loss: 0.7919 - val_accuracy: 0.6389\n",
      "Epoch 145/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.7675 - accuracy: 0.6786 - val_loss: 0.7900 - val_accuracy: 0.6389\n",
      "Epoch 146/500\n",
      "84/84 [==============================] - 0s 308us/step - loss: 0.7657 - accuracy: 0.6786 - val_loss: 0.7882 - val_accuracy: 0.6389\n",
      "Epoch 147/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.7638 - accuracy: 0.6786 - val_loss: 0.7865 - val_accuracy: 0.6389\n",
      "Epoch 148/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.7619 - accuracy: 0.6786 - val_loss: 0.7847 - val_accuracy: 0.6389\n",
      "Epoch 149/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.7601 - accuracy: 0.6786 - val_loss: 0.7830 - val_accuracy: 0.6389\n",
      "Epoch 150/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.7583 - accuracy: 0.6786 - val_loss: 0.7813 - val_accuracy: 0.6389\n",
      "Epoch 151/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.7565 - accuracy: 0.6786 - val_loss: 0.7796 - val_accuracy: 0.6389\n",
      "Epoch 152/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.7547 - accuracy: 0.6786 - val_loss: 0.7779 - val_accuracy: 0.6389\n",
      "Epoch 153/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.7530 - accuracy: 0.6786 - val_loss: 0.7762 - val_accuracy: 0.6389\n",
      "Epoch 154/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.7513 - accuracy: 0.6786 - val_loss: 0.7746 - val_accuracy: 0.6389\n",
      "Epoch 155/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.7496 - accuracy: 0.6786 - val_loss: 0.7729 - val_accuracy: 0.6389\n",
      "Epoch 156/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.7479 - accuracy: 0.6786 - val_loss: 0.7713 - val_accuracy: 0.6389\n",
      "Epoch 157/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.7462 - accuracy: 0.6786 - val_loss: 0.7697 - val_accuracy: 0.6389\n",
      "Epoch 158/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.7446 - accuracy: 0.6786 - val_loss: 0.7682 - val_accuracy: 0.6389\n",
      "Epoch 159/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.7429 - accuracy: 0.6786 - val_loss: 0.7666 - val_accuracy: 0.6389\n",
      "Epoch 160/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.7413 - accuracy: 0.6905 - val_loss: 0.7651 - val_accuracy: 0.6389\n",
      "Epoch 161/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.7397 - accuracy: 0.6905 - val_loss: 0.7636 - val_accuracy: 0.6389\n",
      "Epoch 162/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.7381 - accuracy: 0.6905 - val_loss: 0.7621 - val_accuracy: 0.6389\n",
      "Epoch 163/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.7365 - accuracy: 0.6905 - val_loss: 0.7606 - val_accuracy: 0.6389\n",
      "Epoch 164/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.7350 - accuracy: 0.6905 - val_loss: 0.7591 - val_accuracy: 0.6389\n",
      "Epoch 165/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.7334 - accuracy: 0.6905 - val_loss: 0.7576 - val_accuracy: 0.6389\n",
      "Epoch 166/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.7319 - accuracy: 0.6905 - val_loss: 0.7561 - val_accuracy: 0.6389\n",
      "Epoch 167/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.7303 - accuracy: 0.6905 - val_loss: 0.7547 - val_accuracy: 0.6389\n",
      "Epoch 168/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.7288 - accuracy: 0.6905 - val_loss: 0.7532 - val_accuracy: 0.6389\n",
      "Epoch 169/500\n",
      "84/84 [==============================] - 0s 583us/step - loss: 0.7273 - accuracy: 0.6905 - val_loss: 0.7518 - val_accuracy: 0.6389\n",
      "Epoch 170/500\n",
      "84/84 [==============================] - 0s 762us/step - loss: 0.7258 - accuracy: 0.6905 - val_loss: 0.7504 - val_accuracy: 0.6389\n",
      "Epoch 171/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.7244 - accuracy: 0.6905 - val_loss: 0.7489 - val_accuracy: 0.6389\n",
      "Epoch 172/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.7229 - accuracy: 0.6905 - val_loss: 0.7475 - val_accuracy: 0.6389\n",
      "Epoch 173/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.7215 - accuracy: 0.6905 - val_loss: 0.7461 - val_accuracy: 0.6389\n",
      "Epoch 174/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.7200 - accuracy: 0.6905 - val_loss: 0.7447 - val_accuracy: 0.6389\n",
      "Epoch 175/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.7186 - accuracy: 0.6905 - val_loss: 0.7434 - val_accuracy: 0.6389\n",
      "Epoch 176/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.7172 - accuracy: 0.6905 - val_loss: 0.7420 - val_accuracy: 0.6389\n",
      "Epoch 177/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.7158 - accuracy: 0.6905 - val_loss: 0.7407 - val_accuracy: 0.6389\n",
      "Epoch 178/500\n",
      "84/84 [==============================] - 0s 383us/step - loss: 0.7144 - accuracy: 0.6905 - val_loss: 0.7394 - val_accuracy: 0.6389\n",
      "Epoch 179/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.7131 - accuracy: 0.6905 - val_loss: 0.7380 - val_accuracy: 0.6389\n",
      "Epoch 180/500\n",
      "84/84 [==============================] - 0s 845us/step - loss: 0.7117 - accuracy: 0.6905 - val_loss: 0.7367 - val_accuracy: 0.6389\n",
      "Epoch 181/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.7104 - accuracy: 0.6905 - val_loss: 0.7354 - val_accuracy: 0.6389\n",
      "Epoch 182/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.7091 - accuracy: 0.6905 - val_loss: 0.7342 - val_accuracy: 0.6389\n",
      "Epoch 183/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.7078 - accuracy: 0.6905 - val_loss: 0.7329 - val_accuracy: 0.6389\n",
      "Epoch 184/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.7065 - accuracy: 0.6905 - val_loss: 0.7316 - val_accuracy: 0.6389\n",
      "Epoch 185/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.7052 - accuracy: 0.6905 - val_loss: 0.7304 - val_accuracy: 0.6389\n",
      "Epoch 186/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.7039 - accuracy: 0.6905 - val_loss: 0.7292 - val_accuracy: 0.6389\n",
      "Epoch 187/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.7026 - accuracy: 0.6905 - val_loss: 0.7280 - val_accuracy: 0.6389\n",
      "Epoch 188/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.7013 - accuracy: 0.6905 - val_loss: 0.7268 - val_accuracy: 0.6389\n",
      "Epoch 189/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.7001 - accuracy: 0.6905 - val_loss: 0.7256 - val_accuracy: 0.6389\n",
      "Epoch 190/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.6989 - accuracy: 0.6905 - val_loss: 0.7243 - val_accuracy: 0.6389\n",
      "Epoch 191/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.6976 - accuracy: 0.6905 - val_loss: 0.7232 - val_accuracy: 0.6389\n",
      "Epoch 192/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.6964 - accuracy: 0.6905 - val_loss: 0.7220 - val_accuracy: 0.6389\n",
      "Epoch 193/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6952 - accuracy: 0.6905 - val_loss: 0.7208 - val_accuracy: 0.6389\n",
      "Epoch 194/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.6940 - accuracy: 0.6905 - val_loss: 0.7196 - val_accuracy: 0.6389\n",
      "Epoch 195/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.6928 - accuracy: 0.6905 - val_loss: 0.7185 - val_accuracy: 0.6389\n",
      "Epoch 196/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.6917 - accuracy: 0.6905 - val_loss: 0.7173 - val_accuracy: 0.6389\n",
      "Epoch 197/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.6905 - accuracy: 0.6905 - val_loss: 0.7162 - val_accuracy: 0.6389\n",
      "Epoch 198/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.6894 - accuracy: 0.6905 - val_loss: 0.7151 - val_accuracy: 0.6389\n",
      "Epoch 199/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.6882 - accuracy: 0.6905 - val_loss: 0.7140 - val_accuracy: 0.6389\n",
      "Epoch 200/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.6871 - accuracy: 0.6905 - val_loss: 0.7129 - val_accuracy: 0.6389\n",
      "Epoch 201/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.6860 - accuracy: 0.6905 - val_loss: 0.7118 - val_accuracy: 0.6389\n",
      "Epoch 202/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.6848 - accuracy: 0.6905 - val_loss: 0.7107 - val_accuracy: 0.6389\n",
      "Epoch 203/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.6838 - accuracy: 0.6905 - val_loss: 0.7097 - val_accuracy: 0.6389\n",
      "Epoch 204/500\n",
      "84/84 [==============================] - 0s 356us/step - loss: 0.6826 - accuracy: 0.6905 - val_loss: 0.7086 - val_accuracy: 0.6389\n",
      "Epoch 205/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.6815 - accuracy: 0.6905 - val_loss: 0.7075 - val_accuracy: 0.6389\n",
      "Epoch 206/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.6805 - accuracy: 0.6905 - val_loss: 0.7065 - val_accuracy: 0.6667\n",
      "Epoch 207/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6794 - accuracy: 0.6905 - val_loss: 0.7054 - val_accuracy: 0.6667\n",
      "Epoch 208/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.6783 - accuracy: 0.6905 - val_loss: 0.7044 - val_accuracy: 0.6667\n",
      "Epoch 209/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.6773 - accuracy: 0.6905 - val_loss: 0.7034 - val_accuracy: 0.6667\n",
      "Epoch 210/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.6762 - accuracy: 0.6905 - val_loss: 0.7023 - val_accuracy: 0.6667\n",
      "Epoch 211/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.6752 - accuracy: 0.6905 - val_loss: 0.7013 - val_accuracy: 0.6667\n",
      "Epoch 212/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.6741 - accuracy: 0.6905 - val_loss: 0.7003 - val_accuracy: 0.6667\n",
      "Epoch 213/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.6731 - accuracy: 0.6905 - val_loss: 0.6993 - val_accuracy: 0.6667\n",
      "Epoch 214/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.6721 - accuracy: 0.6905 - val_loss: 0.6983 - val_accuracy: 0.6667\n",
      "Epoch 215/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.6711 - accuracy: 0.6905 - val_loss: 0.6974 - val_accuracy: 0.6667\n",
      "Epoch 216/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.6701 - accuracy: 0.6905 - val_loss: 0.6963 - val_accuracy: 0.6667\n",
      "Epoch 217/500\n",
      "84/84 [==============================] - 0s 536us/step - loss: 0.6691 - accuracy: 0.6905 - val_loss: 0.6954 - val_accuracy: 0.6667\n",
      "Epoch 218/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.6681 - accuracy: 0.6905 - val_loss: 0.6944 - val_accuracy: 0.6667\n",
      "Epoch 219/500\n",
      "84/84 [==============================] - 0s 453us/step - loss: 0.6671 - accuracy: 0.6905 - val_loss: 0.6935 - val_accuracy: 0.6667\n",
      "Epoch 220/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.6661 - accuracy: 0.6905 - val_loss: 0.6925 - val_accuracy: 0.6667\n",
      "Epoch 221/500\n",
      "84/84 [==============================] - 0s 560us/step - loss: 0.6651 - accuracy: 0.6905 - val_loss: 0.6915 - val_accuracy: 0.6667\n",
      "Epoch 222/500\n",
      "84/84 [==============================] - 0s 452us/step - loss: 0.6642 - accuracy: 0.6905 - val_loss: 0.6906 - val_accuracy: 0.6667\n",
      "Epoch 223/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.6632 - accuracy: 0.6905 - val_loss: 0.6896 - val_accuracy: 0.6667\n",
      "Epoch 224/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.6623 - accuracy: 0.6905 - val_loss: 0.6886 - val_accuracy: 0.6667\n",
      "Epoch 225/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.6613 - accuracy: 0.6905 - val_loss: 0.6877 - val_accuracy: 0.6667\n",
      "Epoch 226/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.6604 - accuracy: 0.6905 - val_loss: 0.6868 - val_accuracy: 0.6667\n",
      "Epoch 227/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.6594 - accuracy: 0.6905 - val_loss: 0.6858 - val_accuracy: 0.6667\n",
      "Epoch 228/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.6585 - accuracy: 0.6905 - val_loss: 0.6849 - val_accuracy: 0.6667\n",
      "Epoch 229/500\n",
      "84/84 [==============================] - 0s 512us/step - loss: 0.6576 - accuracy: 0.6905 - val_loss: 0.6840 - val_accuracy: 0.6667\n",
      "Epoch 230/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.6567 - accuracy: 0.6905 - val_loss: 0.6830 - val_accuracy: 0.6667\n",
      "Epoch 231/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.6558 - accuracy: 0.6905 - val_loss: 0.6821 - val_accuracy: 0.6667\n",
      "Epoch 232/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.6549 - accuracy: 0.6905 - val_loss: 0.6813 - val_accuracy: 0.6667\n",
      "Epoch 233/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.6540 - accuracy: 0.6905 - val_loss: 0.6804 - val_accuracy: 0.6667\n",
      "Epoch 234/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.6531 - accuracy: 0.6905 - val_loss: 0.6795 - val_accuracy: 0.6667\n",
      "Epoch 235/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.6522 - accuracy: 0.6905 - val_loss: 0.6786 - val_accuracy: 0.6667\n",
      "Epoch 236/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.6513 - accuracy: 0.6905 - val_loss: 0.6777 - val_accuracy: 0.6667\n",
      "Epoch 237/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6505 - accuracy: 0.6905 - val_loss: 0.6768 - val_accuracy: 0.6667\n",
      "Epoch 238/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.6496 - accuracy: 0.6905 - val_loss: 0.6760 - val_accuracy: 0.6667\n",
      "Epoch 239/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 0.6487 - accuracy: 0.6905 - val_loss: 0.6751 - val_accuracy: 0.6667\n",
      "Epoch 240/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.6479 - accuracy: 0.6905 - val_loss: 0.6743 - val_accuracy: 0.6667\n",
      "Epoch 241/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.6471 - accuracy: 0.6905 - val_loss: 0.6734 - val_accuracy: 0.6667\n",
      "Epoch 242/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.6462 - accuracy: 0.6905 - val_loss: 0.6726 - val_accuracy: 0.6667\n",
      "Epoch 243/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.6454 - accuracy: 0.6905 - val_loss: 0.6719 - val_accuracy: 0.6667\n",
      "Epoch 244/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.6445 - accuracy: 0.6905 - val_loss: 0.6711 - val_accuracy: 0.6667\n",
      "Epoch 245/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.6438 - accuracy: 0.6905 - val_loss: 0.6703 - val_accuracy: 0.6667\n",
      "Epoch 246/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.6429 - accuracy: 0.6905 - val_loss: 0.6696 - val_accuracy: 0.6667\n",
      "Epoch 247/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.6421 - accuracy: 0.6905 - val_loss: 0.6688 - val_accuracy: 0.6667\n",
      "Epoch 248/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.6413 - accuracy: 0.6905 - val_loss: 0.6680 - val_accuracy: 0.6667\n",
      "Epoch 249/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.6405 - accuracy: 0.6905 - val_loss: 0.6672 - val_accuracy: 0.6667\n",
      "Epoch 250/500\n",
      "84/84 [==============================] - 0s 512us/step - loss: 0.6398 - accuracy: 0.6905 - val_loss: 0.6664 - val_accuracy: 0.6667\n",
      "Epoch 251/500\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.6389 - accuracy: 0.6905 - val_loss: 0.6656 - val_accuracy: 0.6667\n",
      "Epoch 252/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6382 - accuracy: 0.6905 - val_loss: 0.6649 - val_accuracy: 0.6667\n",
      "Epoch 253/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.6374 - accuracy: 0.6905 - val_loss: 0.6641 - val_accuracy: 0.6667\n",
      "Epoch 254/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.6366 - accuracy: 0.6905 - val_loss: 0.6633 - val_accuracy: 0.6667\n",
      "Epoch 255/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.6359 - accuracy: 0.6905 - val_loss: 0.6626 - val_accuracy: 0.6667\n",
      "Epoch 256/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.6351 - accuracy: 0.6905 - val_loss: 0.6618 - val_accuracy: 0.6667\n",
      "Epoch 257/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.6344 - accuracy: 0.6905 - val_loss: 0.6610 - val_accuracy: 0.6667\n",
      "Epoch 258/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.6336 - accuracy: 0.6905 - val_loss: 0.6603 - val_accuracy: 0.6667\n",
      "Epoch 259/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.6328 - accuracy: 0.6905 - val_loss: 0.6595 - val_accuracy: 0.6667\n",
      "Epoch 260/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.6321 - accuracy: 0.6905 - val_loss: 0.6588 - val_accuracy: 0.6667\n",
      "Epoch 261/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.6314 - accuracy: 0.6905 - val_loss: 0.6581 - val_accuracy: 0.6667\n",
      "Epoch 262/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.6306 - accuracy: 0.6905 - val_loss: 0.6573 - val_accuracy: 0.6667\n",
      "Epoch 263/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.6299 - accuracy: 0.6905 - val_loss: 0.6566 - val_accuracy: 0.6667\n",
      "Epoch 264/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.6292 - accuracy: 0.6905 - val_loss: 0.6559 - val_accuracy: 0.6667\n",
      "Epoch 265/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.6285 - accuracy: 0.6905 - val_loss: 0.6553 - val_accuracy: 0.6667\n",
      "Epoch 266/500\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.6278 - accuracy: 0.6905 - val_loss: 0.6546 - val_accuracy: 0.6667\n",
      "Epoch 267/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.6271 - accuracy: 0.6905 - val_loss: 0.6539 - val_accuracy: 0.6667\n",
      "Epoch 268/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.6263 - accuracy: 0.6905 - val_loss: 0.6532 - val_accuracy: 0.6667\n",
      "Epoch 269/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.6256 - accuracy: 0.6905 - val_loss: 0.6526 - val_accuracy: 0.6667\n",
      "Epoch 270/500\n",
      "84/84 [==============================] - 0s 631us/step - loss: 0.6250 - accuracy: 0.6905 - val_loss: 0.6519 - val_accuracy: 0.6667\n",
      "Epoch 271/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.6243 - accuracy: 0.6905 - val_loss: 0.6512 - val_accuracy: 0.6667\n",
      "Epoch 272/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.6236 - accuracy: 0.6905 - val_loss: 0.6506 - val_accuracy: 0.6667\n",
      "Epoch 273/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.6229 - accuracy: 0.6905 - val_loss: 0.6499 - val_accuracy: 0.6667\n",
      "Epoch 274/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.6222 - accuracy: 0.6905 - val_loss: 0.6492 - val_accuracy: 0.6667\n",
      "Epoch 275/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.6215 - accuracy: 0.6905 - val_loss: 0.6485 - val_accuracy: 0.6667\n",
      "Epoch 276/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.6209 - accuracy: 0.6905 - val_loss: 0.6478 - val_accuracy: 0.6667\n",
      "Epoch 277/500\n",
      "84/84 [==============================] - 0s 619us/step - loss: 0.6202 - accuracy: 0.6905 - val_loss: 0.6471 - val_accuracy: 0.6667\n",
      "Epoch 278/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.6196 - accuracy: 0.6905 - val_loss: 0.6465 - val_accuracy: 0.6667\n",
      "Epoch 279/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.6189 - accuracy: 0.6905 - val_loss: 0.6458 - val_accuracy: 0.6667\n",
      "Epoch 280/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.6183 - accuracy: 0.6905 - val_loss: 0.6452 - val_accuracy: 0.6667\n",
      "Epoch 281/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.6176 - accuracy: 0.6905 - val_loss: 0.6445 - val_accuracy: 0.6667\n",
      "Epoch 282/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6170 - accuracy: 0.6905 - val_loss: 0.6439 - val_accuracy: 0.6667\n",
      "Epoch 283/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.6164 - accuracy: 0.6905 - val_loss: 0.6433 - val_accuracy: 0.6667\n",
      "Epoch 284/500\n",
      "84/84 [==============================] - 0s 667us/step - loss: 0.6157 - accuracy: 0.6905 - val_loss: 0.6427 - val_accuracy: 0.6667\n",
      "Epoch 285/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6151 - accuracy: 0.6905 - val_loss: 0.6421 - val_accuracy: 0.6667\n",
      "Epoch 286/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.6144 - accuracy: 0.6905 - val_loss: 0.6415 - val_accuracy: 0.6667\n",
      "Epoch 287/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.6138 - accuracy: 0.6905 - val_loss: 0.6409 - val_accuracy: 0.6667\n",
      "Epoch 288/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.6132 - accuracy: 0.6905 - val_loss: 0.6403 - val_accuracy: 0.6667\n",
      "Epoch 289/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6126 - accuracy: 0.6905 - val_loss: 0.6397 - val_accuracy: 0.6667\n",
      "Epoch 290/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.6120 - accuracy: 0.6905 - val_loss: 0.6391 - val_accuracy: 0.6667\n",
      "Epoch 291/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.6114 - accuracy: 0.6905 - val_loss: 0.6385 - val_accuracy: 0.6667\n",
      "Epoch 292/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.6108 - accuracy: 0.6905 - val_loss: 0.6379 - val_accuracy: 0.6667\n",
      "Epoch 293/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.6102 - accuracy: 0.6905 - val_loss: 0.6373 - val_accuracy: 0.6667\n",
      "Epoch 294/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.6096 - accuracy: 0.6905 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 295/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.6090 - accuracy: 0.6905 - val_loss: 0.6361 - val_accuracy: 0.6667\n",
      "Epoch 296/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.6084 - accuracy: 0.6905 - val_loss: 0.6356 - val_accuracy: 0.6667\n",
      "Epoch 297/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.6078 - accuracy: 0.6905 - val_loss: 0.6350 - val_accuracy: 0.6667\n",
      "Epoch 298/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.6072 - accuracy: 0.6905 - val_loss: 0.6344 - val_accuracy: 0.6667\n",
      "Epoch 299/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.6066 - accuracy: 0.6905 - val_loss: 0.6337 - val_accuracy: 0.6667\n",
      "Epoch 300/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.6061 - accuracy: 0.6905 - val_loss: 0.6332 - val_accuracy: 0.6667\n",
      "Epoch 301/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.6055 - accuracy: 0.6905 - val_loss: 0.6326 - val_accuracy: 0.6667\n",
      "Epoch 302/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6049 - accuracy: 0.6905 - val_loss: 0.6320 - val_accuracy: 0.6667\n",
      "Epoch 303/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6043 - accuracy: 0.6905 - val_loss: 0.6315 - val_accuracy: 0.6667\n",
      "Epoch 304/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.6038 - accuracy: 0.6905 - val_loss: 0.6309 - val_accuracy: 0.6667\n",
      "Epoch 305/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.6032 - accuracy: 0.6905 - val_loss: 0.6304 - val_accuracy: 0.6667\n",
      "Epoch 306/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.6026 - accuracy: 0.6905 - val_loss: 0.6298 - val_accuracy: 0.6667\n",
      "Epoch 307/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.6021 - accuracy: 0.6905 - val_loss: 0.6292 - val_accuracy: 0.6667\n",
      "Epoch 308/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.6016 - accuracy: 0.6905 - val_loss: 0.6287 - val_accuracy: 0.6667\n",
      "Epoch 309/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6010 - accuracy: 0.6905 - val_loss: 0.6281 - val_accuracy: 0.6667\n",
      "Epoch 310/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.6005 - accuracy: 0.6905 - val_loss: 0.6276 - val_accuracy: 0.6667\n",
      "Epoch 311/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5999 - accuracy: 0.6905 - val_loss: 0.6271 - val_accuracy: 0.6667\n",
      "Epoch 312/500\n",
      "84/84 [==============================] - 0s 560us/step - loss: 0.5994 - accuracy: 0.6905 - val_loss: 0.6265 - val_accuracy: 0.6667\n",
      "Epoch 313/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5988 - accuracy: 0.6905 - val_loss: 0.6260 - val_accuracy: 0.6667\n",
      "Epoch 314/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5983 - accuracy: 0.6905 - val_loss: 0.6254 - val_accuracy: 0.6667\n",
      "Epoch 315/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5978 - accuracy: 0.6905 - val_loss: 0.6250 - val_accuracy: 0.6667\n",
      "Epoch 316/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.6284 - accuracy: 0.56 - 0s 500us/step - loss: 0.5973 - accuracy: 0.6905 - val_loss: 0.6244 - val_accuracy: 0.6667\n",
      "Epoch 317/500\n",
      "84/84 [==============================] - 0s 536us/step - loss: 0.5967 - accuracy: 0.6905 - val_loss: 0.6239 - val_accuracy: 0.6667\n",
      "Epoch 318/500\n",
      "84/84 [==============================] - 0s 536us/step - loss: 0.5962 - accuracy: 0.6905 - val_loss: 0.6234 - val_accuracy: 0.6667\n",
      "Epoch 319/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5957 - accuracy: 0.6905 - val_loss: 0.6229 - val_accuracy: 0.6667\n",
      "Epoch 320/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5952 - accuracy: 0.6905 - val_loss: 0.6224 - val_accuracy: 0.6667\n",
      "Epoch 321/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5947 - accuracy: 0.6905 - val_loss: 0.6219 - val_accuracy: 0.6667\n",
      "Epoch 322/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5942 - accuracy: 0.6905 - val_loss: 0.6214 - val_accuracy: 0.6667\n",
      "Epoch 323/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.5937 - accuracy: 0.6905 - val_loss: 0.6209 - val_accuracy: 0.6667\n",
      "Epoch 324/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5932 - accuracy: 0.6905 - val_loss: 0.6204 - val_accuracy: 0.6667\n",
      "Epoch 325/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5927 - accuracy: 0.6905 - val_loss: 0.6199 - val_accuracy: 0.6667\n",
      "Epoch 326/500\n",
      "84/84 [==============================] - 0s 406us/step - loss: 0.5922 - accuracy: 0.6905 - val_loss: 0.6194 - val_accuracy: 0.6667\n",
      "Epoch 327/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.5917 - accuracy: 0.6905 - val_loss: 0.6189 - val_accuracy: 0.6667\n",
      "Epoch 328/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5912 - accuracy: 0.6905 - val_loss: 0.6185 - val_accuracy: 0.6667\n",
      "Epoch 329/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5907 - accuracy: 0.6905 - val_loss: 0.6180 - val_accuracy: 0.6667\n",
      "Epoch 330/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5902 - accuracy: 0.6905 - val_loss: 0.6176 - val_accuracy: 0.6667\n",
      "Epoch 331/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5898 - accuracy: 0.6905 - val_loss: 0.6171 - val_accuracy: 0.6667\n",
      "Epoch 332/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5893 - accuracy: 0.6905 - val_loss: 0.6166 - val_accuracy: 0.6667\n",
      "Epoch 333/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.5888 - accuracy: 0.6905 - val_loss: 0.6162 - val_accuracy: 0.6667\n",
      "Epoch 334/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5883 - accuracy: 0.6905 - val_loss: 0.6157 - val_accuracy: 0.6667\n",
      "Epoch 335/500\n",
      "84/84 [==============================] - 0s 464us/step - loss: 0.5878 - accuracy: 0.6905 - val_loss: 0.6152 - val_accuracy: 0.6667\n",
      "Epoch 336/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.5874 - accuracy: 0.6905 - val_loss: 0.6147 - val_accuracy: 0.6667\n",
      "Epoch 337/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.5869 - accuracy: 0.6905 - val_loss: 0.6142 - val_accuracy: 0.6667\n",
      "Epoch 338/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.5864 - accuracy: 0.6905 - val_loss: 0.6138 - val_accuracy: 0.6667\n",
      "Epoch 339/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5860 - accuracy: 0.6905 - val_loss: 0.6134 - val_accuracy: 0.6667\n",
      "Epoch 340/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5855 - accuracy: 0.6905 - val_loss: 0.6129 - val_accuracy: 0.6667\n",
      "Epoch 341/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5851 - accuracy: 0.6905 - val_loss: 0.6125 - val_accuracy: 0.6667\n",
      "Epoch 342/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5846 - accuracy: 0.6905 - val_loss: 0.6120 - val_accuracy: 0.6667\n",
      "Epoch 343/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5841 - accuracy: 0.6905 - val_loss: 0.6116 - val_accuracy: 0.6667\n",
      "Epoch 344/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5837 - accuracy: 0.6905 - val_loss: 0.6112 - val_accuracy: 0.6667\n",
      "Epoch 345/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.5833 - accuracy: 0.6905 - val_loss: 0.6107 - val_accuracy: 0.6667\n",
      "Epoch 346/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5828 - accuracy: 0.6905 - val_loss: 0.6103 - val_accuracy: 0.6667\n",
      "Epoch 347/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5824 - accuracy: 0.6905 - val_loss: 0.6099 - val_accuracy: 0.6667\n",
      "Epoch 348/500\n",
      "84/84 [==============================] - 0s 226us/step - loss: 0.5819 - accuracy: 0.6905 - val_loss: 0.6095 - val_accuracy: 0.6667\n",
      "Epoch 349/500\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.5815 - accuracy: 0.6905 - val_loss: 0.6091 - val_accuracy: 0.6667\n",
      "Epoch 350/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5811 - accuracy: 0.6905 - val_loss: 0.6086 - val_accuracy: 0.6667\n",
      "Epoch 351/500\n",
      "84/84 [==============================] - 0s 226us/step - loss: 0.5806 - accuracy: 0.6905 - val_loss: 0.6082 - val_accuracy: 0.6667\n",
      "Epoch 352/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5802 - accuracy: 0.6905 - val_loss: 0.6078 - val_accuracy: 0.6667\n",
      "Epoch 353/500\n",
      "84/84 [==============================] - 0s 226us/step - loss: 0.5798 - accuracy: 0.6905 - val_loss: 0.6074 - val_accuracy: 0.6667\n",
      "Epoch 354/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5794 - accuracy: 0.6905 - val_loss: 0.6070 - val_accuracy: 0.6667\n",
      "Epoch 355/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5790 - accuracy: 0.6905 - val_loss: 0.6067 - val_accuracy: 0.6667\n",
      "Epoch 356/500\n",
      "84/84 [==============================] - 0s 226us/step - loss: 0.5786 - accuracy: 0.6905 - val_loss: 0.6062 - val_accuracy: 0.6667\n",
      "Epoch 357/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5781 - accuracy: 0.6905 - val_loss: 0.6058 - val_accuracy: 0.6667\n",
      "Epoch 358/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5777 - accuracy: 0.6905 - val_loss: 0.6055 - val_accuracy: 0.6667\n",
      "Epoch 359/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.5773 - accuracy: 0.6905 - val_loss: 0.6051 - val_accuracy: 0.6667\n",
      "Epoch 360/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5769 - accuracy: 0.6905 - val_loss: 0.6047 - val_accuracy: 0.6667\n",
      "Epoch 361/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5765 - accuracy: 0.6905 - val_loss: 0.6043 - val_accuracy: 0.6667\n",
      "Epoch 362/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5761 - accuracy: 0.6905 - val_loss: 0.6039 - val_accuracy: 0.6667\n",
      "Epoch 363/500\n",
      "84/84 [==============================] - 0s 226us/step - loss: 0.5757 - accuracy: 0.6905 - val_loss: 0.6035 - val_accuracy: 0.6667\n",
      "Epoch 364/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5753 - accuracy: 0.6905 - val_loss: 0.6032 - val_accuracy: 0.6667\n",
      "Epoch 365/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5749 - accuracy: 0.6905 - val_loss: 0.6028 - val_accuracy: 0.6667\n",
      "Epoch 366/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5745 - accuracy: 0.6905 - val_loss: 0.6024 - val_accuracy: 0.6667\n",
      "Epoch 367/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5741 - accuracy: 0.6905 - val_loss: 0.6019 - val_accuracy: 0.6667\n",
      "Epoch 368/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.5737 - accuracy: 0.6905 - val_loss: 0.6015 - val_accuracy: 0.6667\n",
      "Epoch 369/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5733 - accuracy: 0.6905 - val_loss: 0.6011 - val_accuracy: 0.6667\n",
      "Epoch 370/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.5843 - accuracy: 0.62 - 0s 548us/step - loss: 0.5729 - accuracy: 0.6905 - val_loss: 0.6006 - val_accuracy: 0.6667\n",
      "Epoch 371/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5725 - accuracy: 0.6905 - val_loss: 0.6002 - val_accuracy: 0.6667\n",
      "Epoch 372/500\n",
      "84/84 [==============================] - 0s 715us/step - loss: 0.5721 - accuracy: 0.6905 - val_loss: 0.5998 - val_accuracy: 0.6667\n",
      "Epoch 373/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.5717 - accuracy: 0.6905 - val_loss: 0.5995 - val_accuracy: 0.6667\n",
      "Epoch 374/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 0.5713 - accuracy: 0.6905 - val_loss: 0.5991 - val_accuracy: 0.6667\n",
      "Epoch 375/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.5710 - accuracy: 0.6905 - val_loss: 0.5987 - val_accuracy: 0.6667\n",
      "Epoch 376/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.5706 - accuracy: 0.6905 - val_loss: 0.5983 - val_accuracy: 0.6667\n",
      "Epoch 377/500\n",
      "84/84 [==============================] - 0s 560us/step - loss: 0.5702 - accuracy: 0.6905 - val_loss: 0.5980 - val_accuracy: 0.6667\n",
      "Epoch 378/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.5698 - accuracy: 0.6905 - val_loss: 0.5976 - val_accuracy: 0.6667\n",
      "Epoch 379/500\n",
      "84/84 [==============================] - 0s 726us/step - loss: 0.5694 - accuracy: 0.6905 - val_loss: 0.5972 - val_accuracy: 0.6667\n",
      "Epoch 380/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.5690 - accuracy: 0.6905 - val_loss: 0.5969 - val_accuracy: 0.6667\n",
      "Epoch 381/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.5687 - accuracy: 0.6905 - val_loss: 0.5965 - val_accuracy: 0.6667\n",
      "Epoch 382/500\n",
      "84/84 [==============================] - 0s 822us/step - loss: 0.5683 - accuracy: 0.6905 - val_loss: 0.5961 - val_accuracy: 0.6667\n",
      "Epoch 383/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.5679 - accuracy: 0.6905 - val_loss: 0.5957 - val_accuracy: 0.6667\n",
      "Epoch 384/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.5675 - accuracy: 0.6905 - val_loss: 0.5953 - val_accuracy: 0.6667\n",
      "Epoch 385/500\n",
      "84/84 [==============================] - 0s 560us/step - loss: 0.5672 - accuracy: 0.6905 - val_loss: 0.5949 - val_accuracy: 0.6667\n",
      "Epoch 386/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5668 - accuracy: 0.6905 - val_loss: 0.5946 - val_accuracy: 0.6667\n",
      "Epoch 387/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5665 - accuracy: 0.6905 - val_loss: 0.5942 - val_accuracy: 0.6667\n",
      "Epoch 388/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5662 - accuracy: 0.6905 - val_loss: 0.5938 - val_accuracy: 0.6667\n",
      "Epoch 389/500\n",
      "84/84 [==============================] - 0s 631us/step - loss: 0.5657 - accuracy: 0.6905 - val_loss: 0.5934 - val_accuracy: 0.6667\n",
      "Epoch 390/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.5654 - accuracy: 0.6905 - val_loss: 0.5930 - val_accuracy: 0.6667\n",
      "Epoch 391/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5650 - accuracy: 0.6905 - val_loss: 0.5926 - val_accuracy: 0.6667\n",
      "Epoch 392/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5647 - accuracy: 0.6905 - val_loss: 0.5922 - val_accuracy: 0.6667\n",
      "Epoch 393/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5643 - accuracy: 0.6905 - val_loss: 0.5918 - val_accuracy: 0.6667\n",
      "Epoch 394/500\n",
      "84/84 [==============================] - 0s 452us/step - loss: 0.5640 - accuracy: 0.6905 - val_loss: 0.5915 - val_accuracy: 0.6667\n",
      "Epoch 395/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.5636 - accuracy: 0.6905 - val_loss: 0.5911 - val_accuracy: 0.6667\n",
      "Epoch 396/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.5633 - accuracy: 0.6905 - val_loss: 0.5908 - val_accuracy: 0.6667\n",
      "Epoch 397/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.5629 - accuracy: 0.6905 - val_loss: 0.5905 - val_accuracy: 0.6667\n",
      "Epoch 398/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.5626 - accuracy: 0.6905 - val_loss: 0.5901 - val_accuracy: 0.6667\n",
      "Epoch 399/500\n",
      "84/84 [==============================] - 0s 750us/step - loss: 0.5622 - accuracy: 0.6905 - val_loss: 0.5898 - val_accuracy: 0.6667\n",
      "Epoch 400/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5619 - accuracy: 0.6905 - val_loss: 0.5895 - val_accuracy: 0.6667\n",
      "Epoch 401/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.5616 - accuracy: 0.6905 - val_loss: 0.5891 - val_accuracy: 0.6667\n",
      "Epoch 402/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5612 - accuracy: 0.6905 - val_loss: 0.5888 - val_accuracy: 0.6667\n",
      "Epoch 403/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5609 - accuracy: 0.6905 - val_loss: 0.5885 - val_accuracy: 0.6667\n",
      "Epoch 404/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.5606 - accuracy: 0.6905 - val_loss: 0.5882 - val_accuracy: 0.6667\n",
      "Epoch 405/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5602 - accuracy: 0.6905 - val_loss: 0.5879 - val_accuracy: 0.6667\n",
      "Epoch 406/500\n",
      "84/84 [==============================] - 0s 464us/step - loss: 0.5599 - accuracy: 0.6905 - val_loss: 0.5876 - val_accuracy: 0.6667\n",
      "Epoch 407/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5596 - accuracy: 0.6905 - val_loss: 0.5872 - val_accuracy: 0.6667\n",
      "Epoch 408/500\n",
      "84/84 [==============================] - 0s 619us/step - loss: 0.5592 - accuracy: 0.6905 - val_loss: 0.5869 - val_accuracy: 0.6667\n",
      "Epoch 409/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5589 - accuracy: 0.6905 - val_loss: 0.5865 - val_accuracy: 0.6667\n",
      "Epoch 410/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.5586 - accuracy: 0.6905 - val_loss: 0.5862 - val_accuracy: 0.6667\n",
      "Epoch 411/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5583 - accuracy: 0.6905 - val_loss: 0.5859 - val_accuracy: 0.6667\n",
      "Epoch 412/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5580 - accuracy: 0.6905 - val_loss: 0.5856 - val_accuracy: 0.6667\n",
      "Epoch 413/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.5576 - accuracy: 0.6905 - val_loss: 0.5853 - val_accuracy: 0.6667\n",
      "Epoch 414/500\n",
      "84/84 [==============================] - 0s 536us/step - loss: 0.5573 - accuracy: 0.6905 - val_loss: 0.5850 - val_accuracy: 0.6667\n",
      "Epoch 415/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5570 - accuracy: 0.6905 - val_loss: 0.5847 - val_accuracy: 0.6667\n",
      "Epoch 416/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5567 - accuracy: 0.6905 - val_loss: 0.5844 - val_accuracy: 0.6667\n",
      "Epoch 417/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5564 - accuracy: 0.6905 - val_loss: 0.5841 - val_accuracy: 0.6667\n",
      "Epoch 418/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.5561 - accuracy: 0.6905 - val_loss: 0.5838 - val_accuracy: 0.6667\n",
      "Epoch 419/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.5558 - accuracy: 0.6905 - val_loss: 0.5835 - val_accuracy: 0.6667\n",
      "Epoch 420/500\n",
      "84/84 [==============================] - 0s 464us/step - loss: 0.5554 - accuracy: 0.6905 - val_loss: 0.5832 - val_accuracy: 0.6667\n",
      "Epoch 421/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5551 - accuracy: 0.6905 - val_loss: 0.5829 - val_accuracy: 0.6667\n",
      "Epoch 422/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5548 - accuracy: 0.6905 - val_loss: 0.5825 - val_accuracy: 0.6667\n",
      "Epoch 423/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5546 - accuracy: 0.6905 - val_loss: 0.5822 - val_accuracy: 0.6667\n",
      "Epoch 424/500\n",
      "84/84 [==============================] - 0s 464us/step - loss: 0.5542 - accuracy: 0.6905 - val_loss: 0.5819 - val_accuracy: 0.6667\n",
      "Epoch 425/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5540 - accuracy: 0.6905 - val_loss: 0.5815 - val_accuracy: 0.6667\n",
      "Epoch 426/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5536 - accuracy: 0.6905 - val_loss: 0.5813 - val_accuracy: 0.6667\n",
      "Epoch 427/500\n",
      "84/84 [==============================] - 0s 762us/step - loss: 0.5533 - accuracy: 0.6905 - val_loss: 0.5810 - val_accuracy: 0.6667\n",
      "Epoch 428/500\n",
      "84/84 [==============================] - 0s 786us/step - loss: 0.5531 - accuracy: 0.6905 - val_loss: 0.5807 - val_accuracy: 0.6667\n",
      "Epoch 429/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5527 - accuracy: 0.6905 - val_loss: 0.5804 - val_accuracy: 0.6667\n",
      "Epoch 430/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5525 - accuracy: 0.6905 - val_loss: 0.5801 - val_accuracy: 0.6667\n",
      "Epoch 431/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5522 - accuracy: 0.6905 - val_loss: 0.5798 - val_accuracy: 0.6667\n",
      "Epoch 432/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5518 - accuracy: 0.6905 - val_loss: 0.5795 - val_accuracy: 0.6667\n",
      "Epoch 433/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5516 - accuracy: 0.6905 - val_loss: 0.5792 - val_accuracy: 0.6667\n",
      "Epoch 434/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.5513 - accuracy: 0.6905 - val_loss: 0.5789 - val_accuracy: 0.6667\n",
      "Epoch 435/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.5510 - accuracy: 0.6905 - val_loss: 0.5786 - val_accuracy: 0.6667\n",
      "Epoch 436/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5507 - accuracy: 0.6905 - val_loss: 0.5783 - val_accuracy: 0.6667\n",
      "Epoch 437/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.5504 - accuracy: 0.6905 - val_loss: 0.5781 - val_accuracy: 0.6667\n",
      "Epoch 438/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5501 - accuracy: 0.6905 - val_loss: 0.5778 - val_accuracy: 0.6667\n",
      "Epoch 439/500\n",
      "84/84 [==============================] - 0s 905us/step - loss: 0.5498 - accuracy: 0.6905 - val_loss: 0.5775 - val_accuracy: 0.6667\n",
      "Epoch 440/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5496 - accuracy: 0.6905 - val_loss: 0.5773 - val_accuracy: 0.6667\n",
      "Epoch 441/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5493 - accuracy: 0.6905 - val_loss: 0.5770 - val_accuracy: 0.6667\n",
      "Epoch 442/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5490 - accuracy: 0.6905 - val_loss: 0.5768 - val_accuracy: 0.6667\n",
      "Epoch 443/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5487 - accuracy: 0.6905 - val_loss: 0.5765 - val_accuracy: 0.6667\n",
      "Epoch 444/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5484 - accuracy: 0.6905 - val_loss: 0.5763 - val_accuracy: 0.6667\n",
      "Epoch 445/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5481 - accuracy: 0.6905 - val_loss: 0.5760 - val_accuracy: 0.6667\n",
      "Epoch 446/500\n",
      "84/84 [==============================] - 0s 631us/step - loss: 0.5479 - accuracy: 0.6905 - val_loss: 0.5758 - val_accuracy: 0.6667\n",
      "Epoch 447/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5476 - accuracy: 0.6905 - val_loss: 0.5755 - val_accuracy: 0.6667\n",
      "Epoch 448/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.5473 - accuracy: 0.6905 - val_loss: 0.5753 - val_accuracy: 0.6667\n",
      "Epoch 449/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5470 - accuracy: 0.6905 - val_loss: 0.5750 - val_accuracy: 0.6667\n",
      "Epoch 450/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5468 - accuracy: 0.6905 - val_loss: 0.5748 - val_accuracy: 0.6667\n",
      "Epoch 451/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5465 - accuracy: 0.6905 - val_loss: 0.5746 - val_accuracy: 0.6667\n",
      "Epoch 452/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5463 - accuracy: 0.6905 - val_loss: 0.5743 - val_accuracy: 0.6667\n",
      "Epoch 453/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5460 - accuracy: 0.6905 - val_loss: 0.5741 - val_accuracy: 0.6667\n",
      "Epoch 454/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.5457 - accuracy: 0.6905 - val_loss: 0.5738 - val_accuracy: 0.6667\n",
      "Epoch 455/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5455 - accuracy: 0.6905 - val_loss: 0.5736 - val_accuracy: 0.6667\n",
      "Epoch 456/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5452 - accuracy: 0.6905 - val_loss: 0.5733 - val_accuracy: 0.6667\n",
      "Epoch 457/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.5449 - accuracy: 0.6905 - val_loss: 0.5731 - val_accuracy: 0.6667\n",
      "Epoch 458/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5447 - accuracy: 0.6905 - val_loss: 0.5728 - val_accuracy: 0.6667\n",
      "Epoch 459/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5444 - accuracy: 0.6905 - val_loss: 0.5726 - val_accuracy: 0.6667\n",
      "Epoch 460/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5442 - accuracy: 0.6905 - val_loss: 0.5723 - val_accuracy: 0.6667\n",
      "Epoch 461/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5439 - accuracy: 0.6905 - val_loss: 0.5721 - val_accuracy: 0.6667\n",
      "Epoch 462/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5436 - accuracy: 0.6905 - val_loss: 0.5718 - val_accuracy: 0.6667\n",
      "Epoch 463/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5434 - accuracy: 0.6905 - val_loss: 0.5716 - val_accuracy: 0.6667\n",
      "Epoch 464/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5432 - accuracy: 0.6905 - val_loss: 0.5714 - val_accuracy: 0.6667\n",
      "Epoch 465/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5429 - accuracy: 0.6905 - val_loss: 0.5711 - val_accuracy: 0.6667\n",
      "Epoch 466/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5427 - accuracy: 0.6905 - val_loss: 0.5709 - val_accuracy: 0.6667\n",
      "Epoch 467/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5424 - accuracy: 0.6905 - val_loss: 0.5706 - val_accuracy: 0.6667\n",
      "Epoch 468/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5422 - accuracy: 0.6905 - val_loss: 0.5704 - val_accuracy: 0.6667\n",
      "Epoch 469/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5419 - accuracy: 0.6905 - val_loss: 0.5701 - val_accuracy: 0.6667\n",
      "Epoch 470/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.5416 - accuracy: 0.6905 - val_loss: 0.5699 - val_accuracy: 0.6667\n",
      "Epoch 471/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5414 - accuracy: 0.6905 - val_loss: 0.5697 - val_accuracy: 0.6667\n",
      "Epoch 472/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5412 - accuracy: 0.6905 - val_loss: 0.5694 - val_accuracy: 0.6667\n",
      "Epoch 473/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5409 - accuracy: 0.6905 - val_loss: 0.5692 - val_accuracy: 0.6667\n",
      "Epoch 474/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5407 - accuracy: 0.6905 - val_loss: 0.5690 - val_accuracy: 0.6667\n",
      "Epoch 475/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.5404 - accuracy: 0.6905 - val_loss: 0.5688 - val_accuracy: 0.6667\n",
      "Epoch 476/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5402 - accuracy: 0.6905 - val_loss: 0.5685 - val_accuracy: 0.6667\n",
      "Epoch 477/500\n",
      "84/84 [==============================] - 0s 251us/step - loss: 0.5400 - accuracy: 0.6905 - val_loss: 0.5683 - val_accuracy: 0.6667\n",
      "Epoch 478/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.5397 - accuracy: 0.6905 - val_loss: 0.5681 - val_accuracy: 0.6667\n",
      "Epoch 479/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5395 - accuracy: 0.6905 - val_loss: 0.5678 - val_accuracy: 0.6667\n",
      "Epoch 480/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5392 - accuracy: 0.6905 - val_loss: 0.5676 - val_accuracy: 0.6667\n",
      "Epoch 481/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5390 - accuracy: 0.6905 - val_loss: 0.5673 - val_accuracy: 0.6667\n",
      "Epoch 482/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.5387 - accuracy: 0.6905 - val_loss: 0.5670 - val_accuracy: 0.6667\n",
      "Epoch 483/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5385 - accuracy: 0.6905 - val_loss: 0.5668 - val_accuracy: 0.6667\n",
      "Epoch 484/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5383 - accuracy: 0.6905 - val_loss: 0.5665 - val_accuracy: 0.6667\n",
      "Epoch 485/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5380 - accuracy: 0.6905 - val_loss: 0.5663 - val_accuracy: 0.6667\n",
      "Epoch 486/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5378 - accuracy: 0.6905 - val_loss: 0.5660 - val_accuracy: 0.6667\n",
      "Epoch 487/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5376 - accuracy: 0.6905 - val_loss: 0.5658 - val_accuracy: 0.6667\n",
      "Epoch 488/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5373 - accuracy: 0.6905 - val_loss: 0.5656 - val_accuracy: 0.6667\n",
      "Epoch 489/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.5371 - accuracy: 0.6905 - val_loss: 0.5654 - val_accuracy: 0.6667\n",
      "Epoch 490/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5369 - accuracy: 0.6905 - val_loss: 0.5651 - val_accuracy: 0.6667\n",
      "Epoch 491/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.5366 - accuracy: 0.6905 - val_loss: 0.5649 - val_accuracy: 0.6667\n",
      "Epoch 492/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.5364 - accuracy: 0.6905 - val_loss: 0.5646 - val_accuracy: 0.6667\n",
      "Epoch 493/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5362 - accuracy: 0.6905 - val_loss: 0.5644 - val_accuracy: 0.6667\n",
      "Epoch 494/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.5359 - accuracy: 0.6905 - val_loss: 0.5642 - val_accuracy: 0.6667\n",
      "Epoch 495/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5357 - accuracy: 0.6905 - val_loss: 0.5639 - val_accuracy: 0.6667\n",
      "Epoch 496/500\n",
      "84/84 [==============================] - 0s 822us/step - loss: 0.5355 - accuracy: 0.6905 - val_loss: 0.5637 - val_accuracy: 0.6667\n",
      "Epoch 497/500\n",
      "84/84 [==============================] - 0s 512us/step - loss: 0.5353 - accuracy: 0.6905 - val_loss: 0.5635 - val_accuracy: 0.6667\n",
      "Epoch 498/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.5351 - accuracy: 0.6905 - val_loss: 0.5633 - val_accuracy: 0.6667\n",
      "Epoch 499/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.5348 - accuracy: 0.6905 - val_loss: 0.5631 - val_accuracy: 0.6667\n",
      "Epoch 500/500\n",
      "84/84 [==============================] - 0s 607us/step - loss: 0.5346 - accuracy: 0.6905 - val_loss: 0.5629 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x201240f28c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,epochs=500,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 1 Neuron\n",
      "[[4.0191116 5.559356  2.1950998]]\n",
      "2. 2 Neuron:\n",
      "[[0.3650286  0.27377746 0.361194  ]]\n",
      "3. Train\n",
      "[[0.8907314  0.07109444 0.0381741 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"1. 1 Neuron\")\n",
    "print(az)\n",
    "print(\"2. 2 Neuron:\")\n",
    "print(aza)\n",
    "print(\"3. Train\")\n",
    "print(model.predict(np.array([[5.1,5.3,1.4,0.2]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 158us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(54.3, 68.3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss, train_accuracy=model.evaluate(X_train, y_train)\n",
    "round(train_loss*100,1), round(train_accuracy*100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 67us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(54.3, 66.7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_accuracy=model.evaluate(X_test, y_test)\n",
    "round(test_loss*100,1), round(test_accuracy*100,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOW TO:\n",
    "Using This Iris Framework (Data in MM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8907314  0.07109444 0.0381741 ]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(np.array([[5.1,5.3,1.4,0.2]])))#RANGE: SEPAL LENGHT, SEPAL WIDTH,PETAL LENGHT, PETAL WIDTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Vergleich mit ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "Xy=iris.data\n",
    "yy=iris.data\n",
    "Xy_sepal_lenght=Xy[:,0]\n",
    "Xy_sepal_width=Xy[:,1]\n",
    "Xy_petal_lenght=Xy[:,2]\n",
    "Xy_petal_width=Xy[:,3]\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xy_train, Xy_test, yy_train, yy_test=train_test_split(X,y,test_size=0.4)\n",
    "#USING NEAREST NEIGHBORS\n",
    "from sklearn import neighbors\n",
    "clf=neighbors.KNeighborsClassifier(1)\n",
    "clf.fit(Xy_train,yy_train)\n",
    "print(clf.score(Xy_train,yy_train))\n",
    "print(clf.score(Xy_test,yy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vergleich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learning:\n",
      "Probability for zero in percent\n",
      "6.0\n",
      "Probability for one in percent\n",
      "45.0\n",
      "Probability for two in percent\n",
      "49.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Deep Learning:\")\n",
    "deplearn=model.predict(np.array([[6.3,2.7,5.5,1.5]]))\n",
    "print(\"Probability for zero in percent\")\n",
    "print(round(deplearn[0][0]*100,1))\n",
    "print(\"Probability for one in percent\")\n",
    "print(round(deplearn[0][1]*100,1))\n",
    "print(\"Probability for two in percent\")\n",
    "print(round(deplearn[0][2]*100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"ML:\")\n",
    "clf.predict([[6.3,2.7,5.5,1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distribution of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.JointGrid at 0x20124f5ed48>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(Xy_sepal_lenght, Xy_petal_lenght)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.JointGrid at 0x20124e80308>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.jointplot(Xy_sepal_width, Xy_petal_width)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
