{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Made by [Sharkbyteprojects](https://github.com/sharkbyteprojects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ON GITHUB](https://github.com/Sharkbyteprojects/IRIS-ML_and_Deep-Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Other Example](https://mybinder.org/v2/gh/Sharkbyteprojects/IRIS-ML_and_Deep-Learning/master?filepath=csv%20based%2F%3D%20or%20not.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need\n",
    "\n",
    "\n",
    "- Keras\n",
    "- SKLEARN\n",
    "- numpy\n",
    "- seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "inputs=Input(shape=(4,))\n",
    "fc=Dense(3)(inputs)\n",
    "from keras.models import Model\n",
    "model=Model(input=inputs,output=fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zeige infos Ã¼ber Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and add new Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "             loss=\"categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])\n",
    "predictionss=Dense(8,activation=\"softmax\")(fc)\n",
    "predictions=Dense(3,activation=\"softmax\")(predictionss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test of Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "az=model.predict(np.array([[5.1,5.3,1.4,0.2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recompile and Retry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 15        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 74\n",
      "Trainable params: 74\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Model(input=inputs,output=predictions)\n",
    "model.compile(optimizer=\"adam\",\n",
    "             loss=\"categorical_crossentropy\",\n",
    "             metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "aza=model.predict(np.array([[5.1,5.3,1.4,0.2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris =datasets.load_iris()\n",
    "X=np.array(iris.data)\n",
    "y=np.array(iris.target)\n",
    "X.shape, y.shape\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y=to_categorical(y,3)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "complete prepare for train, start train:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 84 samples, validate on 36 samples\n",
      "Epoch 1/500\n",
      "84/84 [==============================] - 4s 42ms/step - loss: 1.0999 - accuracy: 0.3452 - val_loss: 1.1103 - val_accuracy: 0.3056\n",
      "Epoch 2/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 1.0970 - accuracy: 0.3452 - val_loss: 1.1071 - val_accuracy: 0.3056\n",
      "Epoch 3/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 1.0942 - accuracy: 0.3452 - val_loss: 1.1040 - val_accuracy: 0.3056\n",
      "Epoch 4/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 1.0912 - accuracy: 0.3452 - val_loss: 1.1010 - val_accuracy: 0.3056\n",
      "Epoch 5/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 1.0882 - accuracy: 0.3452 - val_loss: 1.0979 - val_accuracy: 0.3056\n",
      "Epoch 6/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 1.0853 - accuracy: 0.3452 - val_loss: 1.0949 - val_accuracy: 0.3056\n",
      "Epoch 7/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 1.0824 - accuracy: 0.3452 - val_loss: 1.0918 - val_accuracy: 0.3056\n",
      "Epoch 8/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 1.0796 - accuracy: 0.3452 - val_loss: 1.0888 - val_accuracy: 0.3056\n",
      "Epoch 9/500\n",
      "84/84 [==============================] - 0s 452us/step - loss: 1.0767 - accuracy: 0.3452 - val_loss: 1.0858 - val_accuracy: 0.3056\n",
      "Epoch 10/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 1.0738 - accuracy: 0.3452 - val_loss: 1.0827 - val_accuracy: 0.3056\n",
      "Epoch 11/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 1.0709 - accuracy: 0.3452 - val_loss: 1.0797 - val_accuracy: 0.3056\n",
      "Epoch 12/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 1.0680 - accuracy: 0.3452 - val_loss: 1.0766 - val_accuracy: 0.3056\n",
      "Epoch 13/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 1.0649 - accuracy: 0.3452 - val_loss: 1.0736 - val_accuracy: 0.3056\n",
      "Epoch 14/500\n",
      "84/84 [==============================] - 0s 560us/step - loss: 1.0618 - accuracy: 0.3452 - val_loss: 1.0705 - val_accuracy: 0.3056\n",
      "Epoch 15/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 1.0589 - accuracy: 0.3452 - val_loss: 1.0674 - val_accuracy: 0.3056\n",
      "Epoch 16/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 1.0557 - accuracy: 0.3452 - val_loss: 1.0643 - val_accuracy: 0.3056\n",
      "Epoch 17/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 1.0528 - accuracy: 0.3452 - val_loss: 1.0611 - val_accuracy: 0.3056\n",
      "Epoch 18/500\n",
      "84/84 [==============================] - 0s 321us/step - loss: 1.0495 - accuracy: 0.3452 - val_loss: 1.0580 - val_accuracy: 0.3056\n",
      "Epoch 19/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 1.0464 - accuracy: 0.3452 - val_loss: 1.0548 - val_accuracy: 0.3056\n",
      "Epoch 20/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 1.0432 - accuracy: 0.3452 - val_loss: 1.0516 - val_accuracy: 0.3056\n",
      "Epoch 21/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 1.0400 - accuracy: 0.3452 - val_loss: 1.0483 - val_accuracy: 0.3056\n",
      "Epoch 22/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 1.0367 - accuracy: 0.3571 - val_loss: 1.0450 - val_accuracy: 0.3056\n",
      "Epoch 23/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 1.0334 - accuracy: 0.3571 - val_loss: 1.0416 - val_accuracy: 0.3056\n",
      "Epoch 24/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 1.0300 - accuracy: 0.3810 - val_loss: 1.0383 - val_accuracy: 0.3056\n",
      "Epoch 25/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 1.0267 - accuracy: 0.4048 - val_loss: 1.0349 - val_accuracy: 0.3056\n",
      "Epoch 26/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 1.0233 - accuracy: 0.4524 - val_loss: 1.0315 - val_accuracy: 0.3333\n",
      "Epoch 27/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 1.0198 - accuracy: 0.5000 - val_loss: 1.0281 - val_accuracy: 0.3611\n",
      "Epoch 28/500\n",
      "84/84 [==============================] - 0s 214us/step - loss: 1.0164 - accuracy: 0.5357 - val_loss: 1.0246 - val_accuracy: 0.3889\n",
      "Epoch 29/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 1.0129 - accuracy: 0.5595 - val_loss: 1.0211 - val_accuracy: 0.4444\n",
      "Epoch 30/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 1.0093 - accuracy: 0.6548 - val_loss: 1.0176 - val_accuracy: 0.5000\n",
      "Epoch 31/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 1.0057 - accuracy: 0.6786 - val_loss: 1.0140 - val_accuracy: 0.5833\n",
      "Epoch 32/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 1.0021 - accuracy: 0.7262 - val_loss: 1.0103 - val_accuracy: 0.6389\n",
      "Epoch 33/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.9987 - accuracy: 0.7500 - val_loss: 1.0067 - val_accuracy: 0.7500\n",
      "Epoch 34/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.9948 - accuracy: 0.7857 - val_loss: 1.0030 - val_accuracy: 0.8056\n",
      "Epoch 35/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.9911 - accuracy: 0.8095 - val_loss: 0.9993 - val_accuracy: 0.8056\n",
      "Epoch 36/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.9874 - accuracy: 0.8452 - val_loss: 0.9956 - val_accuracy: 0.8889\n",
      "Epoch 37/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.9837 - accuracy: 0.9286 - val_loss: 0.9919 - val_accuracy: 0.8889\n",
      "Epoch 38/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.9799 - accuracy: 0.9167 - val_loss: 0.9881 - val_accuracy: 0.9444\n",
      "Epoch 39/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.9759 - accuracy: 0.9286 - val_loss: 0.9843 - val_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.9724 - accuracy: 0.9286 - val_loss: 0.9805 - val_accuracy: 0.9444\n",
      "Epoch 41/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.9683 - accuracy: 0.9048 - val_loss: 0.9767 - val_accuracy: 0.9444\n",
      "Epoch 42/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.9644 - accuracy: 0.8690 - val_loss: 0.9729 - val_accuracy: 0.9167\n",
      "Epoch 43/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.9606 - accuracy: 0.8571 - val_loss: 0.9691 - val_accuracy: 0.8889\n",
      "Epoch 44/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.9567 - accuracy: 0.8452 - val_loss: 0.9652 - val_accuracy: 0.8889\n",
      "Epoch 45/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.9527 - accuracy: 0.8214 - val_loss: 0.9613 - val_accuracy: 0.8889\n",
      "Epoch 46/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.9489 - accuracy: 0.8095 - val_loss: 0.9574 - val_accuracy: 0.8333\n",
      "Epoch 47/500\n",
      "84/84 [==============================] - 0s 1ms/step - loss: 0.9449 - accuracy: 0.8095 - val_loss: 0.9535 - val_accuracy: 0.8333\n",
      "Epoch 48/500\n",
      "84/84 [==============================] - 0s 321us/step - loss: 0.9409 - accuracy: 0.7976 - val_loss: 0.9496 - val_accuracy: 0.8333\n",
      "Epoch 49/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.9368 - accuracy: 0.7976 - val_loss: 0.9456 - val_accuracy: 0.8056\n",
      "Epoch 50/500\n",
      "84/84 [==============================] - 0s 655us/step - loss: 0.9328 - accuracy: 0.7976 - val_loss: 0.9417 - val_accuracy: 0.7222\n",
      "Epoch 51/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.9290 - accuracy: 0.7738 - val_loss: 0.9377 - val_accuracy: 0.7222\n",
      "Epoch 52/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.9248 - accuracy: 0.7500 - val_loss: 0.9338 - val_accuracy: 0.7222\n",
      "Epoch 53/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.9209 - accuracy: 0.7381 - val_loss: 0.9298 - val_accuracy: 0.6944\n",
      "Epoch 54/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.9168 - accuracy: 0.7381 - val_loss: 0.9259 - val_accuracy: 0.6944\n",
      "Epoch 55/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.9128 - accuracy: 0.7381 - val_loss: 0.9220 - val_accuracy: 0.6944\n",
      "Epoch 56/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.9088 - accuracy: 0.7381 - val_loss: 0.9181 - val_accuracy: 0.6667\n",
      "Epoch 57/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.9050 - accuracy: 0.7381 - val_loss: 0.9143 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.9009 - accuracy: 0.7143 - val_loss: 0.9104 - val_accuracy: 0.6667\n",
      "Epoch 59/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.8970 - accuracy: 0.7143 - val_loss: 0.9066 - val_accuracy: 0.6667\n",
      "Epoch 60/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.8932 - accuracy: 0.7024 - val_loss: 0.9029 - val_accuracy: 0.6667\n",
      "Epoch 61/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.8893 - accuracy: 0.7024 - val_loss: 0.8991 - val_accuracy: 0.6667\n",
      "Epoch 62/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.8856 - accuracy: 0.7024 - val_loss: 0.8954 - val_accuracy: 0.6667\n",
      "Epoch 63/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.8818 - accuracy: 0.7024 - val_loss: 0.8917 - val_accuracy: 0.6667\n",
      "Epoch 64/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.8780 - accuracy: 0.7024 - val_loss: 0.8880 - val_accuracy: 0.6667\n",
      "Epoch 65/500\n",
      "84/84 [==============================] - 0s 453us/step - loss: 0.8743 - accuracy: 0.7024 - val_loss: 0.8843 - val_accuracy: 0.6667\n",
      "Epoch 66/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.8709 - accuracy: 0.7024 - val_loss: 0.8808 - val_accuracy: 0.6667\n",
      "Epoch 67/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.8671 - accuracy: 0.7024 - val_loss: 0.8772 - val_accuracy: 0.6667\n",
      "Epoch 68/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.8635 - accuracy: 0.7024 - val_loss: 0.8736 - val_accuracy: 0.6667\n",
      "Epoch 69/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.8600 - accuracy: 0.7024 - val_loss: 0.8700 - val_accuracy: 0.6667\n",
      "Epoch 70/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.8566 - accuracy: 0.7024 - val_loss: 0.8665 - val_accuracy: 0.6667\n",
      "Epoch 71/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.8530 - accuracy: 0.7024 - val_loss: 0.8629 - val_accuracy: 0.6667\n",
      "Epoch 72/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.8496 - accuracy: 0.7024 - val_loss: 0.8594 - val_accuracy: 0.6667\n",
      "Epoch 73/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.8462 - accuracy: 0.7024 - val_loss: 0.8559 - val_accuracy: 0.6667\n",
      "Epoch 74/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.8428 - accuracy: 0.7024 - val_loss: 0.8525 - val_accuracy: 0.6667\n",
      "Epoch 75/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.8394 - accuracy: 0.7024 - val_loss: 0.8491 - val_accuracy: 0.6667\n",
      "Epoch 76/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.8361 - accuracy: 0.7024 - val_loss: 0.8458 - val_accuracy: 0.6667\n",
      "Epoch 77/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.8329 - accuracy: 0.7024 - val_loss: 0.8424 - val_accuracy: 0.6667\n",
      "Epoch 78/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.8295 - accuracy: 0.7143 - val_loss: 0.8392 - val_accuracy: 0.6667\n",
      "Epoch 79/500\n",
      "84/84 [==============================] - 0s 929us/step - loss: 0.8263 - accuracy: 0.7024 - val_loss: 0.8360 - val_accuracy: 0.6667\n",
      "Epoch 80/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.8231 - accuracy: 0.7024 - val_loss: 0.8327 - val_accuracy: 0.6667\n",
      "Epoch 81/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.8200 - accuracy: 0.7024 - val_loss: 0.8295 - val_accuracy: 0.6667\n",
      "Epoch 82/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.8168 - accuracy: 0.7024 - val_loss: 0.8263 - val_accuracy: 0.6667\n",
      "Epoch 83/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.8136 - accuracy: 0.7143 - val_loss: 0.8230 - val_accuracy: 0.6667\n",
      "Epoch 84/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.8104 - accuracy: 0.7143 - val_loss: 0.8197 - val_accuracy: 0.6667\n",
      "Epoch 85/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.8073 - accuracy: 0.7143 - val_loss: 0.8164 - val_accuracy: 0.6944\n",
      "Epoch 86/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.8041 - accuracy: 0.7381 - val_loss: 0.8131 - val_accuracy: 0.6944\n",
      "Epoch 87/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.8010 - accuracy: 0.7381 - val_loss: 0.8099 - val_accuracy: 0.6944\n",
      "Epoch 88/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.7979 - accuracy: 0.7381 - val_loss: 0.8067 - val_accuracy: 0.6944\n",
      "Epoch 89/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.7948 - accuracy: 0.7381 - val_loss: 0.8033 - val_accuracy: 0.6944\n",
      "Epoch 90/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.7916 - accuracy: 0.7381 - val_loss: 0.8000 - val_accuracy: 0.6944\n",
      "Epoch 91/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.7886 - accuracy: 0.7381 - val_loss: 0.7967 - val_accuracy: 0.6944\n",
      "Epoch 92/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.7854 - accuracy: 0.7381 - val_loss: 0.7934 - val_accuracy: 0.7222\n",
      "Epoch 93/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.7824 - accuracy: 0.7381 - val_loss: 0.7902 - val_accuracy: 0.7222\n",
      "Epoch 94/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.7792 - accuracy: 0.7381 - val_loss: 0.7870 - val_accuracy: 0.7222\n",
      "Epoch 95/500\n",
      "84/84 [==============================] - 0s 452us/step - loss: 0.7762 - accuracy: 0.7500 - val_loss: 0.7835 - val_accuracy: 0.7222\n",
      "Epoch 96/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.7729 - accuracy: 0.7500 - val_loss: 0.7802 - val_accuracy: 0.7222\n",
      "Epoch 97/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.7698 - accuracy: 0.7500 - val_loss: 0.7769 - val_accuracy: 0.7222\n",
      "Epoch 98/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.7667 - accuracy: 0.7619 - val_loss: 0.7734 - val_accuracy: 0.7222\n",
      "Epoch 99/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.7635 - accuracy: 0.7738 - val_loss: 0.7700 - val_accuracy: 0.7500\n",
      "Epoch 100/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.7603 - accuracy: 0.7857 - val_loss: 0.7667 - val_accuracy: 0.7500\n",
      "Epoch 101/500\n",
      "84/84 [==============================] - 0s 464us/step - loss: 0.7571 - accuracy: 0.7857 - val_loss: 0.7633 - val_accuracy: 0.7500\n",
      "Epoch 102/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.7540 - accuracy: 0.7857 - val_loss: 0.7599 - val_accuracy: 0.7778\n",
      "Epoch 103/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.7507 - accuracy: 0.7857 - val_loss: 0.7564 - val_accuracy: 0.7778\n",
      "Epoch 104/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.7475 - accuracy: 0.7857 - val_loss: 0.7528 - val_accuracy: 0.7778\n",
      "Epoch 105/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.7442 - accuracy: 0.7857 - val_loss: 0.7493 - val_accuracy: 0.7778\n",
      "Epoch 106/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.7410 - accuracy: 0.7857 - val_loss: 0.7456 - val_accuracy: 0.8056\n",
      "Epoch 107/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.7377 - accuracy: 0.7976 - val_loss: 0.7421 - val_accuracy: 0.8333\n",
      "Epoch 108/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.7344 - accuracy: 0.7976 - val_loss: 0.7384 - val_accuracy: 0.8611\n",
      "Epoch 109/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.7311 - accuracy: 0.8095 - val_loss: 0.7346 - val_accuracy: 0.8611\n",
      "Epoch 110/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.7277 - accuracy: 0.8095 - val_loss: 0.7308 - val_accuracy: 0.8611\n",
      "Epoch 111/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.7246 - accuracy: 0.8095 - val_loss: 0.7271 - val_accuracy: 0.8889\n",
      "Epoch 112/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.7210 - accuracy: 0.8095 - val_loss: 0.7235 - val_accuracy: 0.8889\n",
      "Epoch 113/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.7176 - accuracy: 0.8095 - val_loss: 0.7199 - val_accuracy: 0.8889\n",
      "Epoch 114/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.7142 - accuracy: 0.8095 - val_loss: 0.7162 - val_accuracy: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "84/84 [==============================] - 0s 619us/step - loss: 0.7108 - accuracy: 0.8095 - val_loss: 0.7124 - val_accuracy: 0.8889\n",
      "Epoch 116/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.7073 - accuracy: 0.8095 - val_loss: 0.7087 - val_accuracy: 0.9167\n",
      "Epoch 117/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.7039 - accuracy: 0.8095 - val_loss: 0.7047 - val_accuracy: 0.9167\n",
      "Epoch 118/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.7006 - accuracy: 0.8095 - val_loss: 0.7011 - val_accuracy: 0.9167\n",
      "Epoch 119/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6970 - accuracy: 0.8095 - val_loss: 0.6971 - val_accuracy: 0.9167\n",
      "Epoch 120/500\n",
      "84/84 [==============================] - 0s 536us/step - loss: 0.6935 - accuracy: 0.8214 - val_loss: 0.6931 - val_accuracy: 0.9167\n",
      "Epoch 121/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.6900 - accuracy: 0.8214 - val_loss: 0.6890 - val_accuracy: 0.9444\n",
      "Epoch 122/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.6867 - accuracy: 0.8333 - val_loss: 0.6849 - val_accuracy: 0.9444\n",
      "Epoch 123/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.6832 - accuracy: 0.8690 - val_loss: 0.6809 - val_accuracy: 0.9444\n",
      "Epoch 124/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.6797 - accuracy: 0.8690 - val_loss: 0.6772 - val_accuracy: 0.9444\n",
      "Epoch 125/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.6762 - accuracy: 0.8690 - val_loss: 0.6734 - val_accuracy: 0.9444\n",
      "Epoch 126/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.6727 - accuracy: 0.8690 - val_loss: 0.6695 - val_accuracy: 0.9444\n",
      "Epoch 127/500\n",
      "84/84 [==============================] - 0s 321us/step - loss: 0.6693 - accuracy: 0.8690 - val_loss: 0.6656 - val_accuracy: 0.9444\n",
      "Epoch 128/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.6659 - accuracy: 0.8690 - val_loss: 0.6618 - val_accuracy: 0.9444\n",
      "Epoch 129/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.6625 - accuracy: 0.8690 - val_loss: 0.6580 - val_accuracy: 0.9722\n",
      "Epoch 130/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.6593 - accuracy: 0.8690 - val_loss: 0.6542 - val_accuracy: 0.9722\n",
      "Epoch 131/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.6558 - accuracy: 0.8810 - val_loss: 0.6506 - val_accuracy: 0.9722\n",
      "Epoch 132/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.6525 - accuracy: 0.8690 - val_loss: 0.6470 - val_accuracy: 0.9722\n",
      "Epoch 133/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.6493 - accuracy: 0.8810 - val_loss: 0.6432 - val_accuracy: 0.9722\n",
      "Epoch 134/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.6463 - accuracy: 0.8810 - val_loss: 0.6391 - val_accuracy: 0.9722\n",
      "Epoch 135/500\n",
      "84/84 [==============================] - 0s 452us/step - loss: 0.6428 - accuracy: 0.9048 - val_loss: 0.6354 - val_accuracy: 0.9722\n",
      "Epoch 136/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.6395 - accuracy: 0.9048 - val_loss: 0.6318 - val_accuracy: 0.9722\n",
      "Epoch 137/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.6363 - accuracy: 0.9048 - val_loss: 0.6280 - val_accuracy: 0.9722\n",
      "Epoch 138/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.6334 - accuracy: 0.9048 - val_loss: 0.6245 - val_accuracy: 0.9722\n",
      "Epoch 139/500\n",
      "84/84 [==============================] - 0s 512us/step - loss: 0.6299 - accuracy: 0.9048 - val_loss: 0.6206 - val_accuracy: 0.9722\n",
      "Epoch 140/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.6271 - accuracy: 0.9167 - val_loss: 0.6165 - val_accuracy: 0.9722\n",
      "Epoch 141/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.6239 - accuracy: 0.9167 - val_loss: 0.6127 - val_accuracy: 0.9722\n",
      "Epoch 142/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.6209 - accuracy: 0.9167 - val_loss: 0.6090 - val_accuracy: 0.9722\n",
      "Epoch 143/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.6179 - accuracy: 0.9167 - val_loss: 0.6055 - val_accuracy: 1.0000\n",
      "Epoch 144/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.6148 - accuracy: 0.9167 - val_loss: 0.6021 - val_accuracy: 0.9722\n",
      "Epoch 145/500\n",
      "84/84 [==============================] - 0s 655us/step - loss: 0.6120 - accuracy: 0.9167 - val_loss: 0.5986 - val_accuracy: 1.0000\n",
      "Epoch 146/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.6088 - accuracy: 0.9167 - val_loss: 0.5954 - val_accuracy: 0.9722\n",
      "Epoch 147/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.6060 - accuracy: 0.9167 - val_loss: 0.5922 - val_accuracy: 0.9722\n",
      "Epoch 148/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.6030 - accuracy: 0.9167 - val_loss: 0.5888 - val_accuracy: 0.9722\n",
      "Epoch 149/500\n",
      "84/84 [==============================] - 0s 453us/step - loss: 0.6002 - accuracy: 0.9167 - val_loss: 0.5855 - val_accuracy: 0.9722\n",
      "Epoch 150/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5973 - accuracy: 0.9167 - val_loss: 0.5818 - val_accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5944 - accuracy: 0.9167 - val_loss: 0.5783 - val_accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5915 - accuracy: 0.9167 - val_loss: 0.5749 - val_accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.5888 - accuracy: 0.9167 - val_loss: 0.5715 - val_accuracy: 1.0000\n",
      "Epoch 154/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.6186 - accuracy: 0.84 - 0s 286us/step - loss: 0.5860 - accuracy: 0.9167 - val_loss: 0.5679 - val_accuracy: 1.0000\n",
      "Epoch 155/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5832 - accuracy: 0.9167 - val_loss: 0.5648 - val_accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.5804 - accuracy: 0.9167 - val_loss: 0.5615 - val_accuracy: 1.0000\n",
      "Epoch 157/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.5778 - accuracy: 0.9286 - val_loss: 0.5582 - val_accuracy: 1.0000\n",
      "Epoch 158/500\n",
      "84/84 [==============================] - 0s 631us/step - loss: 0.5748 - accuracy: 0.9286 - val_loss: 0.5552 - val_accuracy: 1.0000\n",
      "Epoch 159/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5721 - accuracy: 0.9286 - val_loss: 0.5521 - val_accuracy: 1.0000\n",
      "Epoch 160/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5695 - accuracy: 0.9286 - val_loss: 0.5490 - val_accuracy: 1.0000\n",
      "Epoch 161/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5668 - accuracy: 0.9286 - val_loss: 0.5460 - val_accuracy: 1.0000\n",
      "Epoch 162/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5642 - accuracy: 0.9286 - val_loss: 0.5425 - val_accuracy: 1.0000\n",
      "Epoch 163/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.5615 - accuracy: 0.9286 - val_loss: 0.5391 - val_accuracy: 1.0000\n",
      "Epoch 164/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5587 - accuracy: 0.9405 - val_loss: 0.5357 - val_accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.5562 - accuracy: 0.9405 - val_loss: 0.5325 - val_accuracy: 1.0000\n",
      "Epoch 166/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5535 - accuracy: 0.9405 - val_loss: 0.5294 - val_accuracy: 1.0000\n",
      "Epoch 167/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.5508 - accuracy: 0.9405 - val_loss: 0.5264 - val_accuracy: 1.0000\n",
      "Epoch 168/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5482 - accuracy: 0.9405 - val_loss: 0.5234 - val_accuracy: 1.0000\n",
      "Epoch 169/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5456 - accuracy: 0.9405 - val_loss: 0.5206 - val_accuracy: 1.0000\n",
      "Epoch 170/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.5431 - accuracy: 0.9405 - val_loss: 0.5179 - val_accuracy: 1.0000\n",
      "Epoch 171/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 333us/step - loss: 0.5407 - accuracy: 0.9286 - val_loss: 0.5149 - val_accuracy: 1.0000\n",
      "Epoch 172/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5385 - accuracy: 0.9405 - val_loss: 0.5115 - val_accuracy: 1.0000\n",
      "Epoch 173/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.5354 - accuracy: 0.9405 - val_loss: 0.5084 - val_accuracy: 1.0000\n",
      "Epoch 174/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5328 - accuracy: 0.9405 - val_loss: 0.5052 - val_accuracy: 1.0000\n",
      "Epoch 175/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5304 - accuracy: 0.9524 - val_loss: 0.5021 - val_accuracy: 1.0000\n",
      "Epoch 176/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.5278 - accuracy: 0.9643 - val_loss: 0.4990 - val_accuracy: 1.0000\n",
      "Epoch 177/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.5252 - accuracy: 0.9643 - val_loss: 0.4961 - val_accuracy: 1.0000\n",
      "Epoch 178/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5228 - accuracy: 0.9643 - val_loss: 0.4932 - val_accuracy: 1.0000\n",
      "Epoch 179/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.5205 - accuracy: 0.9643 - val_loss: 0.4905 - val_accuracy: 1.0000\n",
      "Epoch 180/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5177 - accuracy: 0.9643 - val_loss: 0.4876 - val_accuracy: 1.0000\n",
      "Epoch 181/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5156 - accuracy: 0.9643 - val_loss: 0.4845 - val_accuracy: 1.0000\n",
      "Epoch 182/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5129 - accuracy: 0.9643 - val_loss: 0.4816 - val_accuracy: 1.0000\n",
      "Epoch 183/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.5103 - accuracy: 0.9643 - val_loss: 0.4788 - val_accuracy: 1.0000\n",
      "Epoch 184/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5081 - accuracy: 0.9643 - val_loss: 0.4758 - val_accuracy: 1.0000\n",
      "Epoch 185/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.5055 - accuracy: 0.9643 - val_loss: 0.4731 - val_accuracy: 1.0000\n",
      "Epoch 186/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.5038 - accuracy: 0.9643 - val_loss: 0.4705 - val_accuracy: 1.0000\n",
      "Epoch 187/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.5009 - accuracy: 0.9524 - val_loss: 0.4676 - val_accuracy: 1.0000\n",
      "Epoch 188/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.4985 - accuracy: 0.9643 - val_loss: 0.4647 - val_accuracy: 1.0000\n",
      "Epoch 189/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.4962 - accuracy: 0.9643 - val_loss: 0.4620 - val_accuracy: 1.0000\n",
      "Epoch 190/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.4940 - accuracy: 0.9643 - val_loss: 0.4591 - val_accuracy: 1.0000\n",
      "Epoch 191/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.4913 - accuracy: 0.9643 - val_loss: 0.4564 - val_accuracy: 1.0000\n",
      "Epoch 192/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.4890 - accuracy: 0.9643 - val_loss: 0.4536 - val_accuracy: 1.0000\n",
      "Epoch 193/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.4866 - accuracy: 0.9643 - val_loss: 0.4509 - val_accuracy: 1.0000\n",
      "Epoch 194/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.4843 - accuracy: 0.9643 - val_loss: 0.4483 - val_accuracy: 1.0000\n",
      "Epoch 195/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.4821 - accuracy: 0.9643 - val_loss: 0.4457 - val_accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "84/84 [==============================] - 0s 214us/step - loss: 0.4798 - accuracy: 0.9643 - val_loss: 0.4431 - val_accuracy: 1.0000\n",
      "Epoch 197/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.4777 - accuracy: 0.9643 - val_loss: 0.4404 - val_accuracy: 1.0000\n",
      "Epoch 198/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.4754 - accuracy: 0.9643 - val_loss: 0.4375 - val_accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.4728 - accuracy: 0.9643 - val_loss: 0.4348 - val_accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.4706 - accuracy: 0.9643 - val_loss: 0.4322 - val_accuracy: 1.0000\n",
      "Epoch 201/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.4685 - accuracy: 0.9643 - val_loss: 0.4297 - val_accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.4663 - accuracy: 0.9643 - val_loss: 0.4271 - val_accuracy: 1.0000\n",
      "Epoch 203/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.4641 - accuracy: 0.9643 - val_loss: 0.4245 - val_accuracy: 1.0000\n",
      "Epoch 204/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.4621 - accuracy: 0.9643 - val_loss: 0.4220 - val_accuracy: 1.0000\n",
      "Epoch 205/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.4596 - accuracy: 0.9643 - val_loss: 0.4195 - val_accuracy: 1.0000\n",
      "Epoch 206/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.4574 - accuracy: 0.9643 - val_loss: 0.4170 - val_accuracy: 1.0000\n",
      "Epoch 207/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.4552 - accuracy: 0.9643 - val_loss: 0.4145 - val_accuracy: 1.0000\n",
      "Epoch 208/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.4531 - accuracy: 0.9643 - val_loss: 0.4120 - val_accuracy: 1.0000\n",
      "Epoch 209/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.4509 - accuracy: 0.9643 - val_loss: 0.4095 - val_accuracy: 1.0000\n",
      "Epoch 210/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.4497 - accuracy: 0.9643 - val_loss: 0.4071 - val_accuracy: 1.0000\n",
      "Epoch 211/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.4467 - accuracy: 0.9643 - val_loss: 0.4047 - val_accuracy: 1.0000\n",
      "Epoch 212/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.4447 - accuracy: 0.9643 - val_loss: 0.4023 - val_accuracy: 1.0000\n",
      "Epoch 213/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.4427 - accuracy: 0.9643 - val_loss: 0.3999 - val_accuracy: 1.0000\n",
      "Epoch 214/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.4404 - accuracy: 0.9643 - val_loss: 0.3975 - val_accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.4389 - accuracy: 0.9643 - val_loss: 0.3953 - val_accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.4364 - accuracy: 0.9643 - val_loss: 0.3929 - val_accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.4342 - accuracy: 0.9643 - val_loss: 0.3905 - val_accuracy: 1.0000\n",
      "Epoch 218/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.4324 - accuracy: 0.9643 - val_loss: 0.3882 - val_accuracy: 1.0000\n",
      "Epoch 219/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.4301 - accuracy: 0.9643 - val_loss: 0.3860 - val_accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.4286 - accuracy: 0.9643 - val_loss: 0.3838 - val_accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.4268 - accuracy: 0.9643 - val_loss: 0.3816 - val_accuracy: 1.0000\n",
      "Epoch 222/500\n",
      "84/84 [==============================] - 0s 464us/step - loss: 0.4246 - accuracy: 0.9643 - val_loss: 0.3793 - val_accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.4228 - accuracy: 0.9643 - val_loss: 0.3771 - val_accuracy: 1.0000\n",
      "Epoch 224/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.4205 - accuracy: 0.9643 - val_loss: 0.3750 - val_accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.4186 - accuracy: 0.9643 - val_loss: 0.3729 - val_accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.4165 - accuracy: 0.9643 - val_loss: 0.3710 - val_accuracy: 1.0000\n",
      "Epoch 227/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 310us/step - loss: 0.4149 - accuracy: 0.9643 - val_loss: 0.3690 - val_accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.4132 - accuracy: 0.9643 - val_loss: 0.3667 - val_accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.4110 - accuracy: 0.9643 - val_loss: 0.3645 - val_accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.4102 - accuracy: 0.9643 - val_loss: 0.3627 - val_accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.4076 - accuracy: 0.9643 - val_loss: 0.3602 - val_accuracy: 1.0000\n",
      "Epoch 232/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.4053 - accuracy: 0.9643 - val_loss: 0.3581 - val_accuracy: 1.0000\n",
      "Epoch 233/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.4038 - accuracy: 0.9643 - val_loss: 0.3560 - val_accuracy: 1.0000\n",
      "Epoch 234/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.4022 - accuracy: 0.9643 - val_loss: 0.3540 - val_accuracy: 1.0000\n",
      "Epoch 235/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.4001 - accuracy: 0.9643 - val_loss: 0.3521 - val_accuracy: 1.0000\n",
      "Epoch 236/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.3984 - accuracy: 0.9643 - val_loss: 0.3505 - val_accuracy: 1.0000\n",
      "Epoch 237/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3755 - accuracy: 0.96 - 0s 524us/step - loss: 0.3969 - accuracy: 0.9643 - val_loss: 0.3488 - val_accuracy: 1.0000\n",
      "Epoch 238/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.3947 - accuracy: 0.9643 - val_loss: 0.3466 - val_accuracy: 1.0000\n",
      "Epoch 239/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.3930 - accuracy: 0.9643 - val_loss: 0.3444 - val_accuracy: 1.0000\n",
      "Epoch 240/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.3912 - accuracy: 0.9643 - val_loss: 0.3424 - val_accuracy: 1.0000\n",
      "Epoch 241/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.3896 - accuracy: 0.9643 - val_loss: 0.3404 - val_accuracy: 1.0000\n",
      "Epoch 242/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.3881 - accuracy: 0.9643 - val_loss: 0.3385 - val_accuracy: 1.0000\n",
      "Epoch 243/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.3862 - accuracy: 0.9643 - val_loss: 0.3367 - val_accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.3845 - accuracy: 0.9643 - val_loss: 0.3351 - val_accuracy: 1.0000\n",
      "Epoch 245/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.3827 - accuracy: 0.9643 - val_loss: 0.3336 - val_accuracy: 1.0000\n",
      "Epoch 246/500\n",
      "84/84 [==============================] - 0s 321us/step - loss: 0.3810 - accuracy: 0.9643 - val_loss: 0.3318 - val_accuracy: 1.0000\n",
      "Epoch 247/500\n",
      "84/84 [==============================] - 0s 214us/step - loss: 0.3795 - accuracy: 0.9643 - val_loss: 0.3301 - val_accuracy: 1.0000\n",
      "Epoch 248/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.3779 - accuracy: 0.9643 - val_loss: 0.3281 - val_accuracy: 1.0000\n",
      "Epoch 249/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.3764 - accuracy: 0.9643 - val_loss: 0.3258 - val_accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.3746 - accuracy: 0.9643 - val_loss: 0.3240 - val_accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.3728 - accuracy: 0.9643 - val_loss: 0.3224 - val_accuracy: 1.0000\n",
      "Epoch 252/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.3712 - accuracy: 0.9643 - val_loss: 0.3208 - val_accuracy: 1.0000\n",
      "Epoch 253/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.3703 - accuracy: 0.9643 - val_loss: 0.3198 - val_accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.3686 - accuracy: 0.9762 - val_loss: 0.3179 - val_accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.3671 - accuracy: 0.9643 - val_loss: 0.3164 - val_accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.3651 - accuracy: 0.9643 - val_loss: 0.3141 - val_accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.3636 - accuracy: 0.9643 - val_loss: 0.3121 - val_accuracy: 1.0000\n",
      "Epoch 258/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.3621 - accuracy: 0.9643 - val_loss: 0.3105 - val_accuracy: 1.0000\n",
      "Epoch 259/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.3606 - accuracy: 0.9643 - val_loss: 0.3090 - val_accuracy: 1.0000\n",
      "Epoch 260/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.3587 - accuracy: 0.9643 - val_loss: 0.3079 - val_accuracy: 1.0000\n",
      "Epoch 261/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.3576 - accuracy: 0.9762 - val_loss: 0.3071 - val_accuracy: 1.0000\n",
      "Epoch 262/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.3562 - accuracy: 0.9762 - val_loss: 0.3058 - val_accuracy: 1.0000\n",
      "Epoch 263/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.3549 - accuracy: 0.9762 - val_loss: 0.3038 - val_accuracy: 1.0000\n",
      "Epoch 264/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.3532 - accuracy: 0.9762 - val_loss: 0.3019 - val_accuracy: 1.0000\n",
      "Epoch 265/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.3517 - accuracy: 0.9643 - val_loss: 0.2998 - val_accuracy: 1.0000\n",
      "Epoch 266/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.3502 - accuracy: 0.9643 - val_loss: 0.2980 - val_accuracy: 1.0000\n",
      "Epoch 267/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.3489 - accuracy: 0.9643 - val_loss: 0.2962 - val_accuracy: 1.0000\n",
      "Epoch 268/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.3475 - accuracy: 0.9643 - val_loss: 0.2950 - val_accuracy: 1.0000\n",
      "Epoch 269/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.3460 - accuracy: 0.9643 - val_loss: 0.2935 - val_accuracy: 1.0000\n",
      "Epoch 270/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.3446 - accuracy: 0.9643 - val_loss: 0.2921 - val_accuracy: 1.0000\n",
      "Epoch 271/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.3432 - accuracy: 0.9643 - val_loss: 0.2908 - val_accuracy: 1.0000\n",
      "Epoch 272/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.3418 - accuracy: 0.9643 - val_loss: 0.2892 - val_accuracy: 1.0000\n",
      "Epoch 273/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.3403 - accuracy: 0.9643 - val_loss: 0.2879 - val_accuracy: 1.0000\n",
      "Epoch 274/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.3600 - accuracy: 0.96 - 0s 512us/step - loss: 0.3392 - accuracy: 0.9643 - val_loss: 0.2864 - val_accuracy: 1.0000\n",
      "Epoch 275/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.3378 - accuracy: 0.9643 - val_loss: 0.2848 - val_accuracy: 1.0000\n",
      "Epoch 276/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.3365 - accuracy: 0.9643 - val_loss: 0.2836 - val_accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.3350 - accuracy: 0.9643 - val_loss: 0.2821 - val_accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.3336 - accuracy: 0.9643 - val_loss: 0.2805 - val_accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.3324 - accuracy: 0.9643 - val_loss: 0.2791 - val_accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.3310 - accuracy: 0.9643 - val_loss: 0.2774 - val_accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.3298 - accuracy: 0.9643 - val_loss: 0.2760 - val_accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.3287 - accuracy: 0.9643 - val_loss: 0.2747 - val_accuracy: 1.0000\n",
      "Epoch 283/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 357us/step - loss: 0.3273 - accuracy: 0.9643 - val_loss: 0.2740 - val_accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.3260 - accuracy: 0.9643 - val_loss: 0.2729 - val_accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.3245 - accuracy: 0.9762 - val_loss: 0.2720 - val_accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.3234 - accuracy: 0.9762 - val_loss: 0.2708 - val_accuracy: 1.0000\n",
      "Epoch 287/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.3224 - accuracy: 0.9762 - val_loss: 0.2696 - val_accuracy: 1.0000\n",
      "Epoch 288/500\n",
      "84/84 [==============================] - 0s 512us/step - loss: 0.3216 - accuracy: 0.9643 - val_loss: 0.2674 - val_accuracy: 1.0000\n",
      "Epoch 289/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.3203 - accuracy: 0.9762 - val_loss: 0.2665 - val_accuracy: 1.0000\n",
      "Epoch 290/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.3188 - accuracy: 0.9762 - val_loss: 0.2645 - val_accuracy: 1.0000\n",
      "Epoch 291/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.3173 - accuracy: 0.9643 - val_loss: 0.2632 - val_accuracy: 1.0000\n",
      "Epoch 292/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.3161 - accuracy: 0.9643 - val_loss: 0.2621 - val_accuracy: 1.0000\n",
      "Epoch 293/500\n",
      "84/84 [==============================] - 0s 655us/step - loss: 0.3150 - accuracy: 0.9643 - val_loss: 0.2608 - val_accuracy: 1.0000\n",
      "Epoch 294/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.3136 - accuracy: 0.9643 - val_loss: 0.2592 - val_accuracy: 1.0000\n",
      "Epoch 295/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.3127 - accuracy: 0.9643 - val_loss: 0.2580 - val_accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.3114 - accuracy: 0.9643 - val_loss: 0.2566 - val_accuracy: 1.0000\n",
      "Epoch 297/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.3103 - accuracy: 0.9643 - val_loss: 0.2554 - val_accuracy: 1.0000\n",
      "Epoch 298/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.3092 - accuracy: 0.9643 - val_loss: 0.2542 - val_accuracy: 1.0000\n",
      "Epoch 299/500\n",
      "84/84 [==============================] - 0s 226us/step - loss: 0.3081 - accuracy: 0.9643 - val_loss: 0.2535 - val_accuracy: 1.0000\n",
      "Epoch 300/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.3068 - accuracy: 0.9643 - val_loss: 0.2528 - val_accuracy: 1.0000\n",
      "Epoch 301/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.3055 - accuracy: 0.9643 - val_loss: 0.2519 - val_accuracy: 1.0000\n",
      "Epoch 302/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.3047 - accuracy: 0.9762 - val_loss: 0.2511 - val_accuracy: 1.0000\n",
      "Epoch 303/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.3033 - accuracy: 0.9762 - val_loss: 0.2495 - val_accuracy: 1.0000\n",
      "Epoch 304/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.3024 - accuracy: 0.9643 - val_loss: 0.2480 - val_accuracy: 1.0000\n",
      "Epoch 305/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.3011 - accuracy: 0.9643 - val_loss: 0.2471 - val_accuracy: 1.0000\n",
      "Epoch 306/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.3000 - accuracy: 0.9762 - val_loss: 0.2462 - val_accuracy: 1.0000\n",
      "Epoch 307/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.2989 - accuracy: 0.9762 - val_loss: 0.2451 - val_accuracy: 1.0000\n",
      "Epoch 308/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.2978 - accuracy: 0.9762 - val_loss: 0.2441 - val_accuracy: 1.0000\n",
      "Epoch 309/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.2968 - accuracy: 0.9762 - val_loss: 0.2433 - val_accuracy: 1.0000\n",
      "Epoch 310/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.2964 - accuracy: 0.9643 - val_loss: 0.2415 - val_accuracy: 1.0000\n",
      "Epoch 311/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.2946 - accuracy: 0.9643 - val_loss: 0.2406 - val_accuracy: 1.0000\n",
      "Epoch 312/500\n",
      "84/84 [==============================] - 0s 238us/step - loss: 0.2936 - accuracy: 0.9762 - val_loss: 0.2400 - val_accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.2925 - accuracy: 0.9762 - val_loss: 0.2389 - val_accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.2915 - accuracy: 0.9762 - val_loss: 0.2375 - val_accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.2906 - accuracy: 0.9643 - val_loss: 0.2361 - val_accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.2896 - accuracy: 0.9643 - val_loss: 0.2352 - val_accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.2882 - accuracy: 0.9762 - val_loss: 0.2349 - val_accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.2877 - accuracy: 0.9762 - val_loss: 0.2349 - val_accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.2866 - accuracy: 0.9762 - val_loss: 0.2336 - val_accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.2855 - accuracy: 0.9762 - val_loss: 0.2318 - val_accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.2843 - accuracy: 0.9762 - val_loss: 0.2300 - val_accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "84/84 [==============================] - 0s 560us/step - loss: 0.2838 - accuracy: 0.9762 - val_loss: 0.2283 - val_accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.2825 - accuracy: 0.9643 - val_loss: 0.2274 - val_accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.2814 - accuracy: 0.9643 - val_loss: 0.2271 - val_accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.2805 - accuracy: 0.9762 - val_loss: 0.2263 - val_accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.2795 - accuracy: 0.9762 - val_loss: 0.2261 - val_accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "84/84 [==============================] - 0s 703us/step - loss: 0.2787 - accuracy: 0.9762 - val_loss: 0.2256 - val_accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.2784 - accuracy: 0.9762 - val_loss: 0.2237 - val_accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "84/84 [==============================] - 0s 893us/step - loss: 0.2767 - accuracy: 0.9762 - val_loss: 0.2228 - val_accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "84/84 [==============================] - 0s 857us/step - loss: 0.2760 - accuracy: 0.9762 - val_loss: 0.2220 - val_accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 0.2749 - accuracy: 0.9762 - val_loss: 0.2220 - val_accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "84/84 [==============================] - 0s 607us/step - loss: 0.2739 - accuracy: 0.9762 - val_loss: 0.2209 - val_accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "84/84 [==============================] - 0s 798us/step - loss: 0.2731 - accuracy: 0.9762 - val_loss: 0.2199 - val_accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.2719 - accuracy: 0.9762 - val_loss: 0.2180 - val_accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.2715 - accuracy: 0.9762 - val_loss: 0.2158 - val_accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "84/84 [==============================] - 0s 583us/step - loss: 0.2709 - accuracy: 0.9643 - val_loss: 0.2146 - val_accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "84/84 [==============================] - 0s 583us/step - loss: 0.2699 - accuracy: 0.9643 - val_loss: 0.2143 - val_accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "84/84 [==============================] - 0s 536us/step - loss: 0.2686 - accuracy: 0.9643 - val_loss: 0.2135 - val_accuracy: 1.0000\n",
      "Epoch 339/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 417us/step - loss: 0.2677 - accuracy: 0.9643 - val_loss: 0.2134 - val_accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.2667 - accuracy: 0.9762 - val_loss: 0.2130 - val_accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "84/84 [==============================] - 0s 452us/step - loss: 0.2666 - accuracy: 0.9762 - val_loss: 0.2127 - val_accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "84/84 [==============================] - 0s 595us/step - loss: 0.2649 - accuracy: 0.9762 - val_loss: 0.2108 - val_accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "84/84 [==============================] - 0s 595us/step - loss: 0.2641 - accuracy: 0.9762 - val_loss: 0.2095 - val_accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "84/84 [==============================] - 0s 738us/step - loss: 0.2636 - accuracy: 0.9762 - val_loss: 0.2078 - val_accuracy: 1.0000\n",
      "Epoch 345/500\n",
      "84/84 [==============================] - 0s 762us/step - loss: 0.2627 - accuracy: 0.9643 - val_loss: 0.2071 - val_accuracy: 1.0000\n",
      "Epoch 346/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.2617 - accuracy: 0.9643 - val_loss: 0.2065 - val_accuracy: 1.0000\n",
      "Epoch 347/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.2610 - accuracy: 0.9762 - val_loss: 0.2064 - val_accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.2598 - accuracy: 0.9762 - val_loss: 0.2062 - val_accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.2596 - accuracy: 0.9762 - val_loss: 0.2061 - val_accuracy: 1.0000\n",
      "Epoch 350/500\n",
      "84/84 [==============================] - 0s 560us/step - loss: 0.2583 - accuracy: 0.9762 - val_loss: 0.2048 - val_accuracy: 1.0000\n",
      "Epoch 351/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.2576 - accuracy: 0.9762 - val_loss: 0.2037 - val_accuracy: 1.0000\n",
      "Epoch 352/500\n",
      "84/84 [==============================] - 0s 572us/step - loss: 0.2570 - accuracy: 0.9762 - val_loss: 0.2025 - val_accuracy: 1.0000\n",
      "Epoch 353/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.2561 - accuracy: 0.9762 - val_loss: 0.2024 - val_accuracy: 1.0000\n",
      "Epoch 354/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.2554 - accuracy: 0.9762 - val_loss: 0.2011 - val_accuracy: 1.0000\n",
      "Epoch 355/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.2542 - accuracy: 0.9762 - val_loss: 0.2007 - val_accuracy: 1.0000\n",
      "Epoch 356/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.2534 - accuracy: 0.9762 - val_loss: 0.2002 - val_accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "84/84 [==============================] - 0s 643us/step - loss: 0.2527 - accuracy: 0.9762 - val_loss: 0.1997 - val_accuracy: 1.0000\n",
      "Epoch 358/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.2520 - accuracy: 0.9762 - val_loss: 0.1987 - val_accuracy: 1.0000\n",
      "Epoch 359/500\n",
      "84/84 [==============================] - 0s 595us/step - loss: 0.2512 - accuracy: 0.9762 - val_loss: 0.1983 - val_accuracy: 1.0000\n",
      "Epoch 360/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.2504 - accuracy: 0.9762 - val_loss: 0.1974 - val_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.2501 - accuracy: 0.9762 - val_loss: 0.1956 - val_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.2490 - accuracy: 0.9762 - val_loss: 0.1948 - val_accuracy: 1.0000\n",
      "Epoch 363/500\n",
      "84/84 [==============================] - 0s 321us/step - loss: 0.2480 - accuracy: 0.9762 - val_loss: 0.1944 - val_accuracy: 1.0000\n",
      "Epoch 364/500\n",
      "84/84 [==============================] - 0s 429us/step - loss: 0.2473 - accuracy: 0.9762 - val_loss: 0.1938 - val_accuracy: 1.0000\n",
      "Epoch 365/500\n",
      "84/84 [==============================] - 0s 297us/step - loss: 0.2465 - accuracy: 0.9762 - val_loss: 0.1933 - val_accuracy: 1.0000\n",
      "Epoch 366/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.2458 - accuracy: 0.9762 - val_loss: 0.1930 - val_accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.2453 - accuracy: 0.9762 - val_loss: 0.1930 - val_accuracy: 1.0000\n",
      "Epoch 368/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.2444 - accuracy: 0.9762 - val_loss: 0.1916 - val_accuracy: 1.0000\n",
      "Epoch 369/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2204 - accuracy: 1.00 - 0s 381us/step - loss: 0.2446 - accuracy: 0.9762 - val_loss: 0.1899 - val_accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.2432 - accuracy: 0.9762 - val_loss: 0.1899 - val_accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.2425 - accuracy: 0.9762 - val_loss: 0.1891 - val_accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.2417 - accuracy: 0.9762 - val_loss: 0.1882 - val_accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.2407 - accuracy: 0.9762 - val_loss: 0.1883 - val_accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "84/84 [==============================] - 0s 548us/step - loss: 0.2401 - accuracy: 0.9762 - val_loss: 0.1880 - val_accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.2398 - accuracy: 0.9762 - val_loss: 0.1877 - val_accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.2386 - accuracy: 0.9762 - val_loss: 0.1858 - val_accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "84/84 [==============================] - 0s 321us/step - loss: 0.2382 - accuracy: 0.9762 - val_loss: 0.1839 - val_accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.2373 - accuracy: 0.9762 - val_loss: 0.1831 - val_accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.2368 - accuracy: 0.9762 - val_loss: 0.1823 - val_accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.2363 - accuracy: 0.9762 - val_loss: 0.1819 - val_accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "84/84 [==============================] - 0s 453us/step - loss: 0.2353 - accuracy: 0.9762 - val_loss: 0.1829 - val_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "84/84 [==============================] - 0s 512us/step - loss: 0.2347 - accuracy: 0.9762 - val_loss: 0.1833 - val_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.2340 - accuracy: 0.9762 - val_loss: 0.1825 - val_accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.2334 - accuracy: 0.9762 - val_loss: 0.1819 - val_accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.2329 - accuracy: 0.9762 - val_loss: 0.1809 - val_accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "84/84 [==============================] - 0s 214us/step - loss: 0.2328 - accuracy: 0.9762 - val_loss: 0.1787 - val_accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.2312 - accuracy: 0.9762 - val_loss: 0.1779 - val_accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.2307 - accuracy: 0.9762 - val_loss: 0.1774 - val_accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.2303 - accuracy: 0.9762 - val_loss: 0.1771 - val_accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.2293 - accuracy: 0.9762 - val_loss: 0.1784 - val_accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.2288 - accuracy: 0.9762 - val_loss: 0.1788 - val_accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.2284 - accuracy: 0.9762 - val_loss: 0.1780 - val_accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.2689 - accuracy: 0.96 - 0s 500us/step - loss: 0.2280 - accuracy: 0.9762 - val_loss: 0.1777 - val_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "84/84 [==============================] - 0s 441us/step - loss: 0.2274 - accuracy: 0.9762 - val_loss: 0.1760 - val_accuracy: 1.0000\n",
      "Epoch 395/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 333us/step - loss: 0.2262 - accuracy: 0.9762 - val_loss: 0.1747 - val_accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.2257 - accuracy: 0.9762 - val_loss: 0.1731 - val_accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.2251 - accuracy: 0.9762 - val_loss: 0.1726 - val_accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "84/84 [==============================] - 0s 798us/step - loss: 0.2243 - accuracy: 0.9762 - val_loss: 0.1712 - val_accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "84/84 [==============================] - ETA: 0s - loss: 0.1668 - accuracy: 1.00 - 0s 310us/step - loss: 0.2239 - accuracy: 0.9762 - val_loss: 0.1701 - val_accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.2232 - accuracy: 0.9762 - val_loss: 0.1693 - val_accuracy: 1.0000\n",
      "Epoch 401/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.2226 - accuracy: 0.9762 - val_loss: 0.1692 - val_accuracy: 1.0000\n",
      "Epoch 402/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.2221 - accuracy: 0.9762 - val_loss: 0.1689 - val_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.2215 - accuracy: 0.9762 - val_loss: 0.1684 - val_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.2208 - accuracy: 0.9762 - val_loss: 0.1677 - val_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.2201 - accuracy: 0.9762 - val_loss: 0.1678 - val_accuracy: 1.0000\n",
      "Epoch 406/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.2196 - accuracy: 0.9762 - val_loss: 0.1676 - val_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.2188 - accuracy: 0.9762 - val_loss: 0.1682 - val_accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "84/84 [==============================] - 0s 321us/step - loss: 0.2195 - accuracy: 0.9762 - val_loss: 0.1692 - val_accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.2182 - accuracy: 0.9762 - val_loss: 0.1687 - val_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.2176 - accuracy: 0.9762 - val_loss: 0.1669 - val_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.2168 - accuracy: 0.9762 - val_loss: 0.1655 - val_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.2159 - accuracy: 0.9762 - val_loss: 0.1636 - val_accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.2155 - accuracy: 0.9762 - val_loss: 0.1619 - val_accuracy: 1.0000\n",
      "Epoch 414/500\n",
      "84/84 [==============================] - 0s 512us/step - loss: 0.2151 - accuracy: 0.9762 - val_loss: 0.1608 - val_accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "84/84 [==============================] - 0s 512us/step - loss: 0.2150 - accuracy: 0.9643 - val_loss: 0.1597 - val_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "84/84 [==============================] - 0s 321us/step - loss: 0.2149 - accuracy: 0.9643 - val_loss: 0.1601 - val_accuracy: 1.0000\n",
      "Epoch 417/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.2135 - accuracy: 0.9762 - val_loss: 0.1597 - val_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.2130 - accuracy: 0.9762 - val_loss: 0.1602 - val_accuracy: 1.0000\n",
      "Epoch 419/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.2122 - accuracy: 0.9762 - val_loss: 0.1605 - val_accuracy: 1.0000\n",
      "Epoch 420/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.2117 - accuracy: 0.9762 - val_loss: 0.1613 - val_accuracy: 1.0000\n",
      "Epoch 421/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.2113 - accuracy: 0.9762 - val_loss: 0.1615 - val_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.2106 - accuracy: 0.9762 - val_loss: 0.1607 - val_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.2103 - accuracy: 0.9762 - val_loss: 0.1591 - val_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.2095 - accuracy: 0.9762 - val_loss: 0.1587 - val_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.2090 - accuracy: 0.9762 - val_loss: 0.1579 - val_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.2087 - accuracy: 0.9762 - val_loss: 0.1559 - val_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "84/84 [==============================] - 0s 321us/step - loss: 0.2080 - accuracy: 0.9762 - val_loss: 0.1555 - val_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.2075 - accuracy: 0.9762 - val_loss: 0.1547 - val_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.2074 - accuracy: 0.9762 - val_loss: 0.1550 - val_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.2065 - accuracy: 0.9762 - val_loss: 0.1540 - val_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.2060 - accuracy: 0.9762 - val_loss: 0.1540 - val_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.2056 - accuracy: 0.9762 - val_loss: 0.1540 - val_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.2048 - accuracy: 0.9762 - val_loss: 0.1529 - val_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.2043 - accuracy: 0.9762 - val_loss: 0.1526 - val_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "84/84 [==============================] - 0s 381us/step - loss: 0.2038 - accuracy: 0.9762 - val_loss: 0.1522 - val_accuracy: 1.0000\n",
      "Epoch 436/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.2038 - accuracy: 0.9762 - val_loss: 0.1526 - val_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "84/84 [==============================] - 0s 274us/step - loss: 0.2032 - accuracy: 0.9762 - val_loss: 0.1535 - val_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.2027 - accuracy: 0.9762 - val_loss: 0.1534 - val_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.2021 - accuracy: 0.9762 - val_loss: 0.1520 - val_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.2011 - accuracy: 0.9762 - val_loss: 0.1502 - val_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.2007 - accuracy: 0.9762 - val_loss: 0.1482 - val_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.2005 - accuracy: 0.9762 - val_loss: 0.1471 - val_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.2006 - accuracy: 0.9762 - val_loss: 0.1471 - val_accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.1997 - accuracy: 0.9762 - val_loss: 0.1468 - val_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.1992 - accuracy: 0.9762 - val_loss: 0.1469 - val_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.1989 - accuracy: 0.9762 - val_loss: 0.1475 - val_accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.1986 - accuracy: 0.9762 - val_loss: 0.1478 - val_accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.1975 - accuracy: 0.9762 - val_loss: 0.1470 - val_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.1971 - accuracy: 0.9762 - val_loss: 0.1462 - val_accuracy: 1.0000\n",
      "Epoch 450/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.1972 - accuracy: 0.9762 - val_loss: 0.1453 - val_accuracy: 1.0000\n",
      "Epoch 451/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 0s 345us/step - loss: 0.1961 - accuracy: 0.9762 - val_loss: 0.1456 - val_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "84/84 [==============================] - 0s 297us/step - loss: 0.1957 - accuracy: 0.9762 - val_loss: 0.1467 - val_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "84/84 [==============================] - 0s 321us/step - loss: 0.1953 - accuracy: 0.9762 - val_loss: 0.1470 - val_accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "84/84 [==============================] - 0s 345us/step - loss: 0.1949 - accuracy: 0.9762 - val_loss: 0.1463 - val_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "84/84 [==============================] - 0s 488us/step - loss: 0.1944 - accuracy: 0.9762 - val_loss: 0.1458 - val_accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.1938 - accuracy: 0.9762 - val_loss: 0.1447 - val_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.1935 - accuracy: 0.9762 - val_loss: 0.1436 - val_accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.1935 - accuracy: 0.9762 - val_loss: 0.1422 - val_accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "84/84 [==============================] - 0s 452us/step - loss: 0.1926 - accuracy: 0.9762 - val_loss: 0.1424 - val_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.1921 - accuracy: 0.9762 - val_loss: 0.1423 - val_accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.1916 - accuracy: 0.9762 - val_loss: 0.1429 - val_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.1913 - accuracy: 0.9762 - val_loss: 0.1426 - val_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.1911 - accuracy: 0.9762 - val_loss: 0.1433 - val_accuracy: 1.0000\n",
      "Epoch 464/500\n",
      "84/84 [==============================] - 0s 405us/step - loss: 0.1905 - accuracy: 0.9762 - val_loss: 0.1427 - val_accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.1905 - accuracy: 0.9762 - val_loss: 0.1406 - val_accuracy: 1.0000\n",
      "Epoch 466/500\n",
      "84/84 [==============================] - 0s 369us/step - loss: 0.1895 - accuracy: 0.9762 - val_loss: 0.1401 - val_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.1892 - accuracy: 0.9762 - val_loss: 0.1391 - val_accuracy: 1.0000\n",
      "Epoch 468/500\n",
      "84/84 [==============================] - 0s 393us/step - loss: 0.1887 - accuracy: 0.9762 - val_loss: 0.1391 - val_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.1884 - accuracy: 0.9762 - val_loss: 0.1391 - val_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.1880 - accuracy: 0.9762 - val_loss: 0.1380 - val_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.1876 - accuracy: 0.9762 - val_loss: 0.1373 - val_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.1872 - accuracy: 0.9762 - val_loss: 0.1381 - val_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "84/84 [==============================] - 0s 321us/step - loss: 0.1867 - accuracy: 0.9762 - val_loss: 0.1376 - val_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "84/84 [==============================] - 0s 357us/step - loss: 0.1861 - accuracy: 0.9762 - val_loss: 0.1382 - val_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.1859 - accuracy: 0.9762 - val_loss: 0.1387 - val_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "84/84 [==============================] - 0s 476us/step - loss: 0.1858 - accuracy: 0.9762 - val_loss: 0.1385 - val_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "84/84 [==============================] - 0s 250us/step - loss: 0.1854 - accuracy: 0.9762 - val_loss: 0.1362 - val_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.1847 - accuracy: 0.9762 - val_loss: 0.1348 - val_accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.1842 - accuracy: 0.9762 - val_loss: 0.1346 - val_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "84/84 [==============================] - 0s 667us/step - loss: 0.1838 - accuracy: 0.9762 - val_loss: 0.1347 - val_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.1835 - accuracy: 0.9762 - val_loss: 0.1354 - val_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "84/84 [==============================] - 0s 464us/step - loss: 0.1832 - accuracy: 0.9762 - val_loss: 0.1350 - val_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "84/84 [==============================] - 0s 322us/step - loss: 0.1827 - accuracy: 0.9762 - val_loss: 0.1357 - val_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.1826 - accuracy: 0.9762 - val_loss: 0.1364 - val_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "84/84 [==============================] - 0s 333us/step - loss: 0.1819 - accuracy: 0.9762 - val_loss: 0.1352 - val_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "84/84 [==============================] - 0s 453us/step - loss: 0.1816 - accuracy: 0.9762 - val_loss: 0.1336 - val_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "84/84 [==============================] - 0s 643us/step - loss: 0.1812 - accuracy: 0.9762 - val_loss: 0.1321 - val_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "84/84 [==============================] - 0s 726us/step - loss: 0.1810 - accuracy: 0.9762 - val_loss: 0.1321 - val_accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "84/84 [==============================] - 0s 583us/step - loss: 0.1814 - accuracy: 0.9762 - val_loss: 0.1301 - val_accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "84/84 [==============================] - 0s 524us/step - loss: 0.1802 - accuracy: 0.9762 - val_loss: 0.1309 - val_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "84/84 [==============================] - 0s 679us/step - loss: 0.1796 - accuracy: 0.9762 - val_loss: 0.1312 - val_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "84/84 [==============================] - 0s 619us/step - loss: 0.1793 - accuracy: 0.9762 - val_loss: 0.1310 - val_accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "84/84 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.9762 - val_loss: 0.1316 - val_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "84/84 [==============================] - 0s 417us/step - loss: 0.1784 - accuracy: 0.9762 - val_loss: 0.1333 - val_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "84/84 [==============================] - 0s 500us/step - loss: 0.1786 - accuracy: 0.9762 - val_loss: 0.1351 - val_accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "84/84 [==============================] - 0s 310us/step - loss: 0.1783 - accuracy: 0.9762 - val_loss: 0.1341 - val_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "84/84 [==============================] - 0s 286us/step - loss: 0.1779 - accuracy: 0.9762 - val_loss: 0.1336 - val_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "84/84 [==============================] - 0s 298us/step - loss: 0.1771 - accuracy: 0.9762 - val_loss: 0.1311 - val_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.1766 - accuracy: 0.9762 - val_loss: 0.1287 - val_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "84/84 [==============================] - 0s 262us/step - loss: 0.1776 - accuracy: 0.9762 - val_loss: 0.1265 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21b1f8f6588>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,epochs=500,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 1 Neuron\n",
      "[[-3.9987524 -5.0789557 -2.2721539]]\n",
      "2. 2 Neuron:\n",
      "[[0.41606846 0.3471314  0.23680013]]\n",
      "3. Train\n",
      "[[0.9061072  0.05650232 0.0373905 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"1. 1 Neuron\")\n",
    "print(az)\n",
    "print(\"2. 2 Neuron:\")\n",
    "print(aza)\n",
    "print(\"3. Train\")\n",
    "print(model.predict(np.array([[5.1,5.3,1.4,0.2]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 142us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16.1, 98.3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss, train_accuracy=model.evaluate(X_train, y_train)\n",
    "round(train_loss*100,1), round(train_accuracy*100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "30/30 [==============================] - 0s 67us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15.0, 100.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_accuracy=model.evaluate(X_test, y_test)\n",
    "round(test_loss*100,1), round(test_accuracy*100,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOW TO:\n",
    "Using This Iris Framework (Data in MM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9061072  0.05650232 0.0373905 ]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(np.array([[5.1,5.3,1.4,0.2]])))#RANGE: SEPAL LENGHT, SEPAL WIDTH,PETAL LENGHT, PETAL WIDTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Vergleich mit ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "Xy=iris.data\n",
    "yy=iris.data\n",
    "Xy_sepal_lenght=Xy[:,0]\n",
    "Xy_sepal_width=Xy[:,1]\n",
    "Xy_petal_lenght=Xy[:,2]\n",
    "Xy_petal_width=Xy[:,3]\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xy_train, Xy_test, yy_train, yy_test=train_test_split(X,y,test_size=0.4)\n",
    "#USING NEAREST NEIGHBORS\n",
    "from sklearn import neighbors\n",
    "clf=neighbors.KNeighborsClassifier(1)\n",
    "clf.fit(Xy_train,yy_train)\n",
    "print(clf.score(Xy_train,yy_train))\n",
    "print(clf.score(Xy_test,yy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vergleich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learning:\n",
      "Probability for zero in percent\n",
      "3.1\n",
      "Probability for one in percent\n",
      "9.6\n",
      "Probability for two in percent\n",
      "87.4\n"
     ]
    }
   ],
   "source": [
    "print(\"Deep Learning:\")\n",
    "deplearn=model.predict(np.array([[6.3,2.7,5.5,1.5]]))\n",
    "print(\"Probability for zero in percent\")\n",
    "print(round(deplearn[0][0]*100,1))\n",
    "print(\"Probability for one in percent\")\n",
    "print(round(deplearn[0][1]*100,1))\n",
    "print(\"Probability for two in percent\")\n",
    "print(round(deplearn[0][2]*100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"ML:\")\n",
    "clf.predict([[6.3,2.7,5.5,1.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distribution of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.JointGrid at 0x21b20360c88>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(Xy_sepal_lenght, Xy_petal_lenght)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.JointGrid at 0x21b2067e608>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.jointplot(Xy_sepal_width, Xy_petal_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
